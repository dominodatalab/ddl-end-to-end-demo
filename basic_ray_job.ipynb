{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1336f048-16eb-441b-9c12-74309c613578",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-29 19:02:49,785\tINFO util.py:154 -- Outdated packages:\n",
      "  ipywidgets==7.7.5 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-08-29 19:02:49,925\tINFO util.py:154 -- Outdated packages:\n",
      "  ipywidgets==7.7.5 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "from ray.air.integrations.mlflow import MLflowLoggerCallback\n",
    "import mlflow.xgboost as mlflow_xgb\n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee47f96-3ab0-4cd0-aee1-7be47c073dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ensure_mlflow_experiment(experiment_name: str) -> int:\n",
    "    \"\"\"\n",
    "    Ensure an MLflow experiment exists and set it as current.\n",
    "\n",
    "    If an experiment with `experiment_name` does not exist, create it. In both cases,\n",
    "    set the active experiment so subsequent runs attach correctly.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    experiment_name : str\n",
    "        The MLflow experiment name.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The experiment ID.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    RuntimeError\n",
    "        If the experiment lookup/creation fails.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - The MLflow tracking URI and token are pre-configured in Domino\n",
    "    \"\"\"\n",
    "    try:\n",
    "        exp = mlflow.get_experiment_by_name(experiment_name)\n",
    "        if exp is None:\n",
    "            exp_id = mlflow.create_experiment(\n",
    "                experiment_name\n",
    "            )\n",
    "        else:\n",
    "            exp_id = exp.experiment_id\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "        return exp_id\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to ensure experiment {experiment_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8af9bda-73fe-4dde-b2b5-c9c6e54ee9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load dataset\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "df = data.frame.rename(columns={\"MedHouseVal\": \"median_house_value\"})\n",
    "\n",
    "# Split\n",
    "train, tmp = train_test_split(df, test_size=0.3, random_state=42)\n",
    "val, test  = train_test_split(tmp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Save locally\n",
    "train.to_parquet(\"/tmp/train.parquet\", index=False)\n",
    "val.to_parquet(\"/tmp/val.parquet\", index=False)\n",
    "test.to_parquet(\"/tmp/test.parquet\", index=False)\n",
    "\n",
    "# Push to S3\n",
    "#!aws s3 cp /tmp/train.parquet s3://ADD_BUCKET/navy/california/train/\n",
    "#!aws s3 cp /tmp/val.parquet   s3://ADD_BUCKET/navy/california/val/\n",
    "#!aws s3 cp /tmp/test.parquet  s3://ADD_BUCKET/navy/california/test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51c056b-bb40-4f25-a415-af89f5f70931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.air import RunConfig, ScalingConfig\n",
    "from ray.data import read_parquet\n",
    "from ray.train.xgboost import XGBoostTrainer\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "try:\n",
    "    from ray.tune.callback import Callback      # Ray >= 2.6\n",
    "except ImportError:\n",
    "    from ray.tune.callbacks import Callback     # Older Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1adda697-3841-450e-98f4-bed31db79159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.xgboost as mlflow_xgb\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.air import RunConfig, ScalingConfig\n",
    "from ray.data import read_parquet\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.air.integrations.mlflow import MLflowLoggerCallback\n",
    "from ray.train.xgboost import XGBoostTrainer\n",
    "\n",
    "import xgboost as xgb\n",
    "import pyarrow.dataset as pds\n",
    "import pyarrow as pa\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "os.environ[\"TUNE_DISABLE_AUTO_CALLBACK_LOGGERS\"] = \"1\"\n",
    "\n",
    "def _s3p(root: str, sub: str) -> str:\n",
    "    \"\"\"Safe join for S3/posix URIs.\"\"\"\n",
    "    return f\"{root.rstrip('/')}/{sub.lstrip('/')}\"\n",
    "\n",
    "\n",
    "def read_parquet_to_pandas(uri: str, columns=None, limit: int | None = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Robust Parquetâ†’pandas loader that bypasses Ray Data.\n",
    "    Works with local paths and s3:// (PyArrow uses AWS_* env vars / IRSA).\n",
    "    \"\"\"\n",
    "    ds = pds.dataset(uri.rstrip(\"/\"), format=\"parquet\")\n",
    "    if limit is None:\n",
    "        return ds.to_table(columns=columns).to_pandas()\n",
    "\n",
    "    # Respect limit across files/row groups\n",
    "    scanner = pds.Scanner.from_dataset(ds, columns=columns)\n",
    "    batches, rows = [], 0\n",
    "    for b in scanner.to_batches():\n",
    "        batches.append(b)\n",
    "        rows += len(b)\n",
    "        if rows >= limit:\n",
    "            return pa.Table.from_batches(batches)[:limit].to_pandas()\n",
    "    return pa.Table.from_batches(batches).to_pandas()\n",
    "\n",
    "\n",
    "def main(data_dir: str, num_workers: int = 4, cpus_per_worker: int = 1, experiment_name:str, DEV_FAST: bool = False):\n",
    "    \"\"\"\n",
    "    Quick knobs:\n",
    "      - num_workers * cpus_per_worker = CPUs per trial.\n",
    "      - trainer_resources={\"CPU\":0} so the driver doesn't steal a core.\n",
    "      - PACK placement to keep trials tight.\n",
    "      - max_concurrent_trials caps parallel trials.\n",
    "      - num_boost_round / early_stopping_rounds control trial length.\n",
    "      - nthread = cpus_per_worker to avoid oversubscription.\n",
    "    \"\"\"\n",
    "\n",
    "    _ensure_experiment(experiment_name)\n",
    "    \n",
    "    # Storage: local for dev, S3/your env otherwise\n",
    "    RUN_STORAGE = os.environ.get(\"RAY_AIR_STORAGE\", \"s3://ddl-wadkars/navy/air/xgb\")\n",
    "    TUNER_STORAGE = \"/tmp/air-dev\" if DEV_FAST else RUN_STORAGE\n",
    "    FINAL_STORAGE = \"/mnt/data/ddl-end-to-end-demo/air/final_fit\" if DEV_FAST else RUN_STORAGE\n",
    "\n",
    "    # Sanity: workers see IRSA env?\n",
    "    @ray.remote\n",
    "    def _peek():\n",
    "        import os\n",
    "        return {\n",
    "            \"ROLE\": bool(os.environ.get(\"AWS_ROLE_ARN\")),\n",
    "            \"TOKEN_FILE\": os.environ.get(\"AWS_WEB_IDENTITY_TOKEN_FILE\"),\n",
    "            \"REGION\": os.environ.get(\"AWS_REGION\"),\n",
    "        }\n",
    "    print(\"Worker env peek:\", ray.get(_peek.remote()))\n",
    "\n",
    "    # MLflow (experiment + parent run)\n",
    "    CLUSTER_TRACKING_URI = os.environ[\"CLUSTER_MLFLOW_TRACKING_URI\"]\n",
    "    \n",
    "    \n",
    "    client = MlflowClient()\n",
    "    exp = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "    EXPERIMENT_ID = exp.experiment_id \n",
    "\n",
    "    parent = client.create_run(\n",
    "        experiment_id=EXPERIMENT_ID,\n",
    "        tags={\"mlflow.runName\": \"xgb_parent\", \"role\": \"tune_parent\"},\n",
    "    )\n",
    "    PARENT_RUN_ID = parent.info.run_id\n",
    "    print(\"Parent run id:\", PARENT_RUN_ID)\n",
    "\n",
    "    # Data (Ray Datasets for training/val)\n",
    "    train_ds = read_parquet(_s3p(data_dir, \"train\"), parallelism=num_workers)\n",
    "    val_ds   = read_parquet(_s3p(data_dir, \"val\"),   parallelism=num_workers)\n",
    "    test_ds  = read_parquet(_s3p(data_dir, \"test\"),  parallelism=num_workers)\n",
    "    print(\"Schema:\", train_ds.schema())\n",
    "\n",
    "    # Label + features\n",
    "    label_col = \"median_house_value\"\n",
    "    feature_cols = [c for c in train_ds.schema().names if c != label_col]\n",
    "    keep = feature_cols + [label_col]\n",
    "    train_ds = train_ds.select_columns(keep)\n",
    "    val_ds   = val_ds.select_columns(keep)\n",
    "\n",
    "    # DEV: trim Ray Datasets used for training; eval will bypass Ray entirely\n",
    "    if DEV_FAST:\n",
    "        train_ds = train_ds.limit(5_000)\n",
    "        val_ds   = val_ds.limit(2_000)\n",
    "\n",
    "    # --- Build test DataFrame without Ray (avoids 'Global node is not initialized') ---\n",
    "    test_uri = _s3p(data_dir, \"test\")\n",
    "    test_pdf = read_parquet_to_pandas(\n",
    "        test_uri, columns=keep, limit=2_000 if DEV_FAST else None\n",
    "    )\n",
    "\n",
    "    # Search space\n",
    "    param_space = {\n",
    "        \"params\": {\n",
    "            \"objective\": \"reg:squarederror\",\n",
    "            \"tree_method\": \"hist\",\n",
    "            \"eval_metric\": \"rmse\",\n",
    "            \"eta\": tune.loguniform(1e-3, 3e-1),\n",
    "            \"max_depth\": tune.randint(4, 12),\n",
    "            \"min_child_weight\": tune.loguniform(1e-2, 10),\n",
    "            \"subsample\": tune.uniform(0.6, 1.0),\n",
    "            \"colsample_bytree\": tune.uniform(0.6, 1.0),\n",
    "            \"lambda\": tune.loguniform(1e-3, 10),\n",
    "            \"alpha\": tune.loguniform(1e-3, 10),\n",
    "        },\n",
    "        \"num_boost_round\": 300,\n",
    "        \"early_stopping_rounds\": 20,\n",
    "    }\n",
    "\n",
    "    # Dev shortcuts\n",
    "    if DEV_FAST:\n",
    "        param_space[\"num_boost_round\"] = 20\n",
    "        param_space[\"early_stopping_rounds\"] = 5\n",
    "        num_workers = 1\n",
    "        cpus_per_worker = 1\n",
    "        NUM_SAMPLES = 5\n",
    "        MAX_CONCURRENT = 3\n",
    "        SAVE_ARTIFACTS = True\n",
    "    else:\n",
    "        NUM_SAMPLES = 30\n",
    "        MAX_CONCURRENT = 3\n",
    "        SAVE_ARTIFACTS = True\n",
    "\n",
    "    # Threads per worker\n",
    "    param_space[\"params\"][\"nthread\"] = cpus_per_worker\n",
    "    print(\"Per-trial CPUs =\", num_workers * cpus_per_worker)\n",
    "\n",
    "    # Scaling / placement\n",
    "    scaling = ScalingConfig(\n",
    "        num_workers=num_workers,\n",
    "        use_gpu=False,\n",
    "        resources_per_worker={\"CPU\": cpus_per_worker},\n",
    "        trainer_resources={\"CPU\": 0},\n",
    "        placement_strategy=\"PACK\",\n",
    "    )\n",
    "\n",
    "    # Trainable\n",
    "    trainer = XGBoostTrainer(\n",
    "        label_column=label_col,\n",
    "        params=param_space[\"params\"],\n",
    "        datasets={\"train\": train_ds, \"valid\": val_ds},\n",
    "        num_boost_round=param_space[\"num_boost_round\"],\n",
    "        scaling_config=scaling,\n",
    "    )\n",
    "\n",
    "    # Search + scheduler\n",
    "    MAX_T = int(param_space[\"num_boost_round\"])\n",
    "    GRACE = int(min(param_space.get(\"early_stopping_rounds\", 1), MAX_T))\n",
    "    algo = HyperOptSearch(metric=\"valid-rmse\", mode=\"min\")\n",
    "    scheduler = ASHAScheduler(max_t=MAX_T, grace_period=GRACE, reduction_factor=3)\n",
    "\n",
    "    # MLflow callback (child runs)\n",
    "    mlflow_cb = MLflowLoggerCallback(\n",
    "        tracking_uri=CLUSTER_TRACKING_URI,\n",
    "        experiment_name=EXPERIMENT_NAME,\n",
    "        save_artifact=SAVE_ARTIFACTS,\n",
    "        tags={\"mlflow.parentRunId\": PARENT_RUN_ID},\n",
    "    )\n",
    "\n",
    "    # Tuner\n",
    "    tuner = tune.Tuner(\n",
    "        trainer.as_trainable(),\n",
    "        run_config=RunConfig(\n",
    "            name=\"xgb_from_s3_irsa\",\n",
    "            storage_path=TUNER_STORAGE,\n",
    "            callbacks=[mlflow_cb],\n",
    "        ),\n",
    "        tune_config=tune.TuneConfig(\n",
    "            search_alg=algo,\n",
    "            scheduler=scheduler,\n",
    "            metric=\"valid-rmse\",\n",
    "            mode=\"min\",\n",
    "            num_samples=NUM_SAMPLES,\n",
    "            max_concurrent_trials=MAX_CONCURRENT,\n",
    "        ),\n",
    "        param_space={\"params\": param_space[\"params\"]},\n",
    "    )\n",
    "\n",
    "    # Tune\n",
    "    results = tuner.fit()\n",
    "    best = results.get_best_result(metric=\"valid-rmse\", mode=\"min\")\n",
    "    print(\"Best config:\", best.config)\n",
    "    print(\"Best valid RMSE:\", best.metrics.get(\"valid-rmse\"))\n",
    "\n",
    "    # Final fit (train + val)\n",
    "    merged = train_ds.union(val_ds)\n",
    "    final_trainer = XGBoostTrainer(\n",
    "        label_column=label_col,\n",
    "        params=best.config[\"params\"],\n",
    "        datasets={\"train\": merged},\n",
    "        num_boost_round=param_space[\"num_boost_round\"],\n",
    "        scaling_config=scaling,\n",
    "        run_config=RunConfig(name=\"final_fit\", storage_path=FINAL_STORAGE),\n",
    "    )\n",
    "    final_result = final_trainer.fit()\n",
    "    final_ckpt = final_result.checkpoint\n",
    "\n",
    "    # Load Booster from checkpoint\n",
    "    with final_ckpt.as_directory() as ckpt_dir:\n",
    "        print(\"Checkpoint dir:\", ckpt_dir, \"files:\", os.listdir(ckpt_dir))\n",
    "        candidates = [\"model.json\", \"model.ubj\", \"model.xgb\", \"xgboost_model.json\", \"model\"]\n",
    "        model_path = next(\n",
    "            (os.path.join(ckpt_dir, f) for f in candidates if os.path.exists(os.path.join(ckpt_dir, f))),\n",
    "            None,\n",
    "        )\n",
    "        if not model_path:\n",
    "            raise FileNotFoundError(f\"No XGBoost model file found in checkpoint dir: {ckpt_dir}\")\n",
    "        booster = xgb.Booster()\n",
    "        booster.load_model(model_path)\n",
    "\n",
    "    # Driver-side eval (no Ray dependency)\n",
    "    X_test = test_pdf.drop(columns=[label_col])\n",
    "    \n",
    "    dmat = xgb.DMatrix(X_test)\n",
    "    y_pred = booster.predict(dmat)\n",
    "    rmse = math.sqrt(((test_pdf[label_col].to_numpy() - y_pred) ** 2).mean())\n",
    "    print(f\"Test RMSE: {rmse:.4f}\")\n",
    "\n",
    "    \n",
    "    # Log final under parent\n",
    "\n",
    "    with mlflow.start_run(run_id=PARENT_RUN_ID):\n",
    "        X_example = X_test.head(5).copy()  \n",
    "        y_example = booster.predict(xgb.DMatrix(X_example))\n",
    "        sig = infer_signature(X_example, y_example)\n",
    "        with mlflow.start_run(run_name=\"final_fit\", nested=True):\n",
    "            mlflow.log_params(best.config.get(\"params\", {}))\n",
    "            mlflow.log_dict({\"label\": label_col, \"features\": feature_cols}, \"features.json\")\n",
    "            mlflow.log_metric(\"valid_rmse_best\", float(best.metrics.get(\"valid-rmse\")))\n",
    "            mlflow.log_metric(\"test_rmse\", float(rmse))\n",
    "            mlflow_xgb.log_model(booster, artifact_path=\"model\",signature=sig,input_example=X_example)\n",
    "    run = client.get_run(PARENT_RUN_ID)\n",
    "    if run.info.status == \"RUNNING\":\n",
    "        client.set_terminated(PARENT_RUN_ID, \"FINISHED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "daaca126-a443-402f-8b44-1c5f9a3f2447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "def _ensure_ray_connected(ray_envs: Dict[str,str], ray_ns:str):\n",
    "    if ray.is_initialized():\n",
    "        return\n",
    "    # Reconnect to the running cluster (prefers ray:// if present)\n",
    "    addr = None\n",
    "    if \"RAY_HEAD_SERVICE_HOST\" in os.environ and \"RAY_HEAD_SERVICE_PORT\" in os.environ:\n",
    "        addr = f\"ray://{os.environ['RAY_HEAD_SERVICE_HOST']}:{os.environ['RAY_HEAD_SERVICE_PORT']}\"\n",
    "    ray.init(\n",
    "        address=addr or \"auto\",\n",
    "        runtime_env={\"env_vars\": ray_envs},   # same env you used earlier\n",
    "        namespace=ray_ns,\n",
    "        ignore_reinit_error=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88455b7c-0a37-4a34-90c3-28b376b15d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "domino_user_name = \"-\"+os.environ['DOMINO_STARTING_USER']\n",
    "env_prefix = \"-dev\"\n",
    "experiment_name=f\"ray-xgb{env_prefix}{domino_user_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fbea44-aaf1-4295-b041-c1351268766a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:07:07] [24]\ttrain-rmse:0.49320\tvalid-rmse:0.53827\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.514 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.499 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9121, ip=100.64.35.74)\u001b[0m [12:07:08] [53]\ttrain-rmse:1.09316\tvalid-rmse:1.08318\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:07:10] [25]\ttrain-rmse:0.49123\tvalid-rmse:0.53793\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.497 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.482 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.483 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.483 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.483 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9121, ip=100.64.35.74)\u001b[0m [12:07:11] [54]\ttrain-rmse:1.09216\tvalid-rmse:1.08228\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:07:13] [26]\ttrain-rmse:0.48892\tvalid-rmse:0.53707\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.499 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.507 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:07:14] [56]\ttrain-rmse:0.26775\tvalid-rmse:0.48577\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.500 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:07:16] [57]\ttrain-rmse:0.26534\tvalid-rmse:0.48567\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:07:17] [27]\ttrain-rmse:0.48332\tvalid-rmse:0.53221\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.504 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial status: 3 RUNNING | 1 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current time: 2025-08-29 12:07:19. Total running time: 4min 7s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current best trial: 946e81ea with valid-rmse=0.48577464059992065 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.12372102335862595, 'max_depth': 8, 'min_child_weight': 0.05312265152593065, 'subsample': 0.9848787891831414, 'colsample_bytree': 0.9496429603242498, 'lambda': 0.002729148416240024, 'alpha': 0.0016047175175163718, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_946e81ea   RUNNING         0.123721                     8                0.0531227             0.984879                 0.949643        0.00272915       0.00160472       57            5.59335       0.267748       0.485775 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_42d76290   RUNNING         0.0014152                    9                0.0178108             0.687814                 0.85763         0.0019692        0.00609112       55            3.92236       1.09216        1.08228  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_40f91dcb   RUNNING         0.158069                     5                4.35899               0.792105                 0.966918        0.800316         0.0164134        26            5.4856        0.491226       0.537933 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_65691eb2   TERMINATED      0.0166576                    5                0.0230802             0.885428                 0.784438        0.0153656        0.0139486        20            4.02765       0.968565       0.96315  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.501 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9121, ip=100.64.35.74)\u001b[0m [12:07:19] [55]\ttrain-rmse:1.09102\tvalid-rmse:1.08123\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:07:20] [58]\ttrain-rmse:0.26329\tvalid-rmse:0.48476\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.494 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9121, ip=100.64.35.74)\u001b[0m [12:07:22] [56]\ttrain-rmse:1.08987\tvalid-rmse:1.08022\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.480 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.481 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.481 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.481 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.486 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:07:23] [59]\ttrain-rmse:0.26178\tvalid-rmse:0.48446\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.502 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:07:25] [28]\ttrain-rmse:0.48134\tvalid-rmse:0.53057\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.484 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.484 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.484 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.484 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:07:26] [29]\ttrain-rmse:0.47857\tvalid-rmse:0.52948\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:07:28] [60]\ttrain-rmse:0.25938\tvalid-rmse:0.48402\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.492 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:07:29] [30]\ttrain-rmse:0.47615\tvalid-rmse:0.52940\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.484 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.485 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.485 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.485 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:07:31] [61]\ttrain-rmse:0.25775\tvalid-rmse:0.48367\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.484 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.484 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.484 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.484 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:07:32] [31]\ttrain-rmse:0.47365\tvalid-rmse:0.52805\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.484 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.485 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.485 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.485 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:07:34] [62]\ttrain-rmse:0.25490\tvalid-rmse:0.48344\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.498 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.506 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9121, ip=100.64.35.74)\u001b[0m [12:07:35] [57]\ttrain-rmse:1.08879\tvalid-rmse:1.07930\n",
      "\u001b[36m(XGBoostTrainer pid=9121, ip=100.64.35.74)\u001b[0m [12:07:37] [58]\ttrain-rmse:1.08766\tvalid-rmse:1.07828\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.512 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.513 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:07:38] [32]\ttrain-rmse:0.47184\tvalid-rmse:0.52718\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.516 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.517 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.517 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.517 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.496 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9121, ip=100.64.35.74)\u001b[0m [12:07:40] [59]\ttrain-rmse:1.08652\tvalid-rmse:1.07727\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.533 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.533 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.533 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.533 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:07:41] [33]\ttrain-rmse:0.46911\tvalid-rmse:0.52521\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.479 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.479 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.480 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.480 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:07:43] [63]\ttrain-rmse:0.25300\tvalid-rmse:0.48303\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.497 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m ğŸƒ View run XGBoostTrainer_42d76290 at: http://ray-68b1b0be9652633ae57e1b88-ray-proxy:8765/#/experiments/257/runs/54beca1f6d484f69b761dcb088bafe76\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m ğŸ§ª View experiment at: http://ray-68b1b0be9652633ae57e1b88-ray-proxy:8765/#/experiments/257\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial XGBoostTrainer_42d76290 completed after 60 iterations at 2025-08-29 12:07:45. Total running time: 4min 33s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial XGBoostTrainer_42d76290 result             â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ checkpoint_dir_name                              â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ time_this_iter_s                         0.00273 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ time_total_s                             3.93633 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ training_iteration                            60 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ train-rmse                               1.08652 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ valid-rmse                               1.07727 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:07:46] [64]\ttrain-rmse:0.25097\tvalid-rmse:0.48266\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.490 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.503 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:07:48] [65]\ttrain-rmse:0.24920\tvalid-rmse:0.48207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial XGBoostTrainer_3e9fda17 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial XGBoostTrainer_3e9fda17 config                           â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/alpha                               0.05162231447301766 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/colsample_bytree                     0.8398847429247148 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/eta                               0.0012920987325098767 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/eval_metric                                        rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/lambda                              0.09055362809620855 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/max_depth                                             9 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/min_child_weight                   0.010980489740233915 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/nthread                                               1 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/objective                              reg:squarederror â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/subsample                            0.8672777877934488 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/tree_method                                        hist â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=9801, ip=100.64.7.216)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=9801, ip=100.64.7.216)\u001b[0m - (node_id=9212372711d6417a3d6338c92f31be45ef97cdcf4ce252eb19b5435a, ip=100.64.7.216, pid=9847) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=9801, ip=100.64.7.216)\u001b[0m - (node_id=9212372711d6417a3d6338c92f31be45ef97cdcf4ce252eb19b5435a, ip=100.64.7.216, pid=9848) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=9801, ip=100.64.7.216)\u001b[0m - (node_id=9212372711d6417a3d6338c92f31be45ef97cdcf4ce252eb19b5435a, ip=100.64.7.216, pid=9849) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=9801, ip=100.64.7.216)\u001b[0m - (node_id=9212372711d6417a3d6338c92f31be45ef97cdcf4ce252eb19b5435a, ip=100.64.7.216, pid=9850) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:07:51] [66]\ttrain-rmse:0.24728\tvalid-rmse:0.48183\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.635 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.636 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.636 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.636 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial status: 3 RUNNING | 2 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current time: 2025-08-29 12:07:51. Total running time: 4min 38s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current best trial: 946e81ea with valid-rmse=0.4820727854627422 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.12372102335862595, 'max_depth': 8, 'min_child_weight': 0.05312265152593065, 'subsample': 0.9848787891831414, 'colsample_bytree': 0.9496429603242498, 'lambda': 0.002729148416240024, 'alpha': 0.0016047175175163718, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_946e81ea   RUNNING         0.123721                     8                0.0531227             0.984879                 0.949643        0.00272915       0.00160472       66            5.61859       0.249204       0.482073 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_40f91dcb   RUNNING         0.158069                     5                4.35899               0.792105                 0.966918        0.800316         0.0164134        32            5.50345       0.473648       0.52805  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_3e9fda17   RUNNING         0.0012921                    9                0.0109805             0.867278                 0.839885        0.0905536        0.0516223                                                            â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_65691eb2   TERMINATED      0.0166576                    5                0.0230802             0.885428                 0.784438        0.0153656        0.0139486        20            4.02765       0.968565       0.96315  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_42d76290   TERMINATED      0.0014152                    9                0.0178108             0.687814                 0.85763         0.0019692        0.00609112       60            3.93633       1.08652        1.07727  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=9850, ip=100.64.7.216)\u001b[0m [12:07:51] Task [xgboost.ray-rank=00000003]:3b6ae177338a6a2631cd2e7d24000000 got rank 3\n",
      "\u001b[36m(RayTrainWorker pid=9848, ip=100.64.7.216)\u001b[0m [12:07:51] Task [xgboost.ray-rank=00000001]:97c205bf2eaa51799c1fc6a724000000 got rank 1\n",
      "\u001b[36m(RayTrainWorker pid=9849, ip=100.64.7.216)\u001b[0m [12:07:51] Task [xgboost.ray-rank=00000002]:d8c49c329ddda264f6c5b82b24000000 got rank 2\n",
      "\u001b[36m(RayTrainWorker pid=9847, ip=100.64.7.216)\u001b[0m [12:07:51] Task [xgboost.ray-rank=00000000]:9af2a4363a6bcd5f577e940424000000 got rank 0\n",
      "\u001b[36m(SplitCoordinator pid=10011, ip=100.64.7.216)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-08-29_06-53-11_170260_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=10011, ip=100.64.7.216)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:07:52] [34]\ttrain-rmse:0.46704\tvalid-rmse:0.52384\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.487 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.495 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:07:54] [67]\ttrain-rmse:0.24514\tvalid-rmse:0.48199\n",
      "\u001b[36m(SplitCoordinator pid=10012, ip=100.64.7.216)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-08-29_06-53-11_170260_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=10012, ip=100.64.7.216)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=9801, ip=100.64.7.216)\u001b[0m [12:07:54] [0]\ttrain-rmse:1.15632\tvalid-rmse:1.14038\n",
      "\u001b[36m(XGBoostTrainer pid=9801, ip=100.64.7.216)\u001b[0m [12:07:54] [1]\ttrain-rmse:1.15519\tvalid-rmse:1.13933\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.506 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:07:55] [35]\ttrain-rmse:0.46574\tvalid-rmse:0.52336\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.471 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.471 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.472 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.472 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:07:57] [68]\ttrain-rmse:0.24333\tvalid-rmse:0.48143\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.455 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.455 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.455 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.455 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9801, ip=100.64.7.216)\u001b[0m [12:07:58] [2]\ttrain-rmse:1.15405\tvalid-rmse:1.13828\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:08:00] [69]\ttrain-rmse:0.24163\tvalid-rmse:0.48140\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.478 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.479 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.479 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.479 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.498 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9801, ip=100.64.7.216)\u001b[0m [12:08:01] [3]\ttrain-rmse:1.15293\tvalid-rmse:1.13727\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:08:03] [70]\ttrain-rmse:0.23945\tvalid-rmse:0.48085\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.490 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.497 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9801, ip=100.64.7.216)\u001b[0m [12:08:04] [4]\ttrain-rmse:1.15177\tvalid-rmse:1.13623\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:08:05] [71]\ttrain-rmse:0.23808\tvalid-rmse:0.48082\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.488 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.491 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.492 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9801, ip=100.64.7.216)\u001b[0m [12:08:07] [5]\ttrain-rmse:1.15066\tvalid-rmse:1.13519\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:08:08] [72]\ttrain-rmse:0.23625\tvalid-rmse:0.48076\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.497 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.507 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9801, ip=100.64.7.216)\u001b[0m [12:08:10] [6]\ttrain-rmse:1.14953\tvalid-rmse:1.13419\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.524 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.524 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.524 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.524 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:08:12] [36]\ttrain-rmse:0.46377\tvalid-rmse:0.52166\n",
      "\u001b[36m(XGBoostTrainer pid=9801, ip=100.64.7.216)\u001b[0m [12:08:13] [7]\ttrain-rmse:1.14835\tvalid-rmse:1.13311\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.514 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.512 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.512 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.512 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.512 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:08:15] [73]\ttrain-rmse:0.23460\tvalid-rmse:0.48061\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.487 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:08:16] [37]\ttrain-rmse:0.46119\tvalid-rmse:0.51973\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.488 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:08:18] [74]\ttrain-rmse:0.23250\tvalid-rmse:0.48040\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.510 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:08:19] [38]\ttrain-rmse:0.45962\tvalid-rmse:0.51870\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.494 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:08:21] [75]\ttrain-rmse:0.23077\tvalid-rmse:0.48003\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:08:22] [39]\ttrain-rmse:0.45738\tvalid-rmse:0.51740\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.493 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial status: 3 RUNNING | 2 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current time: 2025-08-29 12:08:22. Total running time: 5min 10s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current best trial: 946e81ea with valid-rmse=0.48040049291008247 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.12372102335862595, 'max_depth': 8, 'min_child_weight': 0.05312265152593065, 'subsample': 0.9848787891831414, 'colsample_bytree': 0.9496429603242498, 'lambda': 0.002729148416240024, 'alpha': 0.0016047175175163718, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_946e81ea   RUNNING         0.123721                     8                0.0531227             0.984879                 0.949643        0.00272915       0.00160472       75            5.6444        0.232499        0.4804  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_40f91dcb   RUNNING         0.158069                     5                4.35899               0.792105                 0.966918        0.800316         0.0164134        38            5.52045       0.461194        0.51973 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_3e9fda17   RUNNING         0.0012921                    9                0.0109805             0.867278                 0.839885        0.0905536        0.0516223         6            5.48522       1.15066         1.13519 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_65691eb2   TERMINATED      0.0166576                    5                0.0230802             0.885428                 0.784438        0.0153656        0.0139486        20            4.02765       0.968565        0.96315 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_42d76290   TERMINATED      0.0014152                    9                0.0178108             0.687814                 0.85763         0.0019692        0.00609112       60            3.93633       1.08652         1.07727 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.499 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:08:24] [76]\ttrain-rmse:0.22930\tvalid-rmse:0.47966\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:08:25] [40]\ttrain-rmse:0.45414\tvalid-rmse:0.51439\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.507 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.486 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9801, ip=100.64.7.216)\u001b[0m [12:08:27] [8]\ttrain-rmse:1.14720\tvalid-rmse:1.13206\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:08:28] [41]\ttrain-rmse:0.45192\tvalid-rmse:0.51315\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.495 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.489 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.490 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:08:30] [42]\ttrain-rmse:0.45051\tvalid-rmse:0.51257\n",
      "\u001b[36m(XGBoostTrainer pid=9801, ip=100.64.7.216)\u001b[0m [12:08:31] [9]\ttrain-rmse:1.14601\tvalid-rmse:1.13097\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.501 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.519 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.520 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.520 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.520 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:08:33] [43]\ttrain-rmse:0.44924\tvalid-rmse:0.51185\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.508 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9801, ip=100.64.7.216)\u001b[0m [12:08:34] [10]\ttrain-rmse:1.14490\tvalid-rmse:1.12997\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:08:36] [44]\ttrain-rmse:0.44748\tvalid-rmse:0.51066\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.489 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.489 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.489 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.489 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.497 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9801, ip=100.64.7.216)\u001b[0m [12:08:37] [11]\ttrain-rmse:1.14377\tvalid-rmse:1.12897\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:08:39] [77]\ttrain-rmse:0.22717\tvalid-rmse:0.47926\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.495 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.498 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9801, ip=100.64.7.216)\u001b[0m [12:08:40] [12]\ttrain-rmse:1.14272\tvalid-rmse:1.12807\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:08:42] [78]\ttrain-rmse:0.22511\tvalid-rmse:0.47948\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.472 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.473 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.473 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.473 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.496 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9801, ip=100.64.7.216)\u001b[0m [12:08:43] [13]\ttrain-rmse:1.14162\tvalid-rmse:1.12707\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:08:45] [79]\ttrain-rmse:0.22322\tvalid-rmse:0.47908\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.507 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.497 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9801, ip=100.64.7.216)\u001b[0m [12:08:46] [14]\ttrain-rmse:1.14050\tvalid-rmse:1.12603\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:08:48] [80]\ttrain-rmse:0.22116\tvalid-rmse:0.47910\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.497 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.500 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9801, ip=100.64.7.216)\u001b[0m [12:08:49] [15]\ttrain-rmse:1.13933\tvalid-rmse:1.12495\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:08:51] [81]\ttrain-rmse:0.21925\tvalid-rmse:0.47897\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.498 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.498 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9801, ip=100.64.7.216)\u001b[0m [12:08:52] [16]\ttrain-rmse:1.13815\tvalid-rmse:1.12387\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:08:54] [82]\ttrain-rmse:0.21762\tvalid-rmse:0.47864\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.484 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.485 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.485 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.485 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial status: 3 RUNNING | 2 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current time: 2025-08-29 12:08:54. Total running time: 5min 41s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current best trial: 946e81ea with valid-rmse=0.4789663910418861 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.12372102335862595, 'max_depth': 8, 'min_child_weight': 0.05312265152593065, 'subsample': 0.9848787891831414, 'colsample_bytree': 0.9496429603242498, 'lambda': 0.002729148416240024, 'alpha': 0.0016047175175163718, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_946e81ea   RUNNING         0.123721                     8                0.0531227             0.984879                 0.949643        0.00272915       0.00160472       82            5.66379       0.219247       0.478966 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_40f91dcb   RUNNING         0.158069                     5                4.35899               0.792105                 0.966918        0.800316         0.0164134        43            5.586         0.450513       0.512574 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_3e9fda17   RUNNING         0.0012921                    9                0.0109805             0.867278                 0.839885        0.0905536        0.0516223        15            5.5118        1.1405         1.12603  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_65691eb2   TERMINATED      0.0166576                    5                0.0230802             0.885428                 0.784438        0.0153656        0.0139486        20            4.02765       0.968565       0.96315  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_42d76290   TERMINATED      0.0014152                    9                0.0178108             0.687814                 0.85763         0.0019692        0.00609112       60            3.93633       1.08652        1.07727  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.501 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9801, ip=100.64.7.216)\u001b[0m [12:08:55] [17]\ttrain-rmse:1.13725\tvalid-rmse:1.12307\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.511 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.511 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.511 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.511 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:08:57] [45]\ttrain-rmse:0.44568\tvalid-rmse:0.50900\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:08:58] [83]\ttrain-rmse:0.21600\tvalid-rmse:0.47857\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.509 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.523 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.523 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.523 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.523 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9801, ip=100.64.7.216)\u001b[0m [12:09:00] [18]\ttrain-rmse:1.13616\tvalid-rmse:1.12210\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.651 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.652 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.652 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.652 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:09:01] [46]\ttrain-rmse:0.44402\tvalid-rmse:0.50869\n",
      "\u001b[36m(XGBoostTrainer pid=9801, ip=100.64.7.216)\u001b[0m [12:09:03] [19]\ttrain-rmse:1.13500\tvalid-rmse:1.12104\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.496 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.477 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.477 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.477 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.477 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:09:04] [84]\ttrain-rmse:0.21460\tvalid-rmse:0.47825\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:09:06] [47]\ttrain-rmse:0.44275\tvalid-rmse:0.50870\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.504 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.496 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:09:07] [85]\ttrain-rmse:0.21359\tvalid-rmse:0.47820\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.497 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9801, ip=100.64.7.216)\u001b[0m [12:09:09] [20]\ttrain-rmse:1.13390\tvalid-rmse:1.12006\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.485 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.485 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.485 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.485 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:09:10] [86]\ttrain-rmse:0.21213\tvalid-rmse:0.47801\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.491 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.492 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m ğŸƒ View run XGBoostTrainer_3e9fda17 at: http://ray-68b1b0be9652633ae57e1b88-ray-proxy:8765/#/experiments/257/runs/29bdc52ad2004e00b407d4a622ee10a5\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m ğŸ§ª View experiment at: http://ray-68b1b0be9652633ae57e1b88-ray-proxy:8765/#/experiments/257\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial XGBoostTrainer_3e9fda17 completed after 20 iterations at 2025-08-29 12:09:12. Total running time: 6min 0s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial XGBoostTrainer_3e9fda17 result             â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ checkpoint_dir_name                              â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ time_this_iter_s                         0.00301 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ time_total_s                             5.52629 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ training_iteration                            20 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ train-rmse                                 1.135 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ valid-rmse                               1.12104 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.494 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:09:14] [87]\ttrain-rmse:0.21033\tvalid-rmse:0.47809\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:09:15] [48]\ttrain-rmse:0.44185\tvalid-rmse:0.50799\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.480 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.480 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.480 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.480 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial XGBoostTrainer_5793bdb6 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial XGBoostTrainer_5793bdb6 config                           â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/alpha                                3.6737606933636524 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/colsample_bytree                     0.8286080882544015 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/eta                                0.008365528150805872 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/eval_metric                                        rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/lambda                            0.0010715598636487848 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/max_depth                                             9 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/min_child_weight                    0.03745052742803742 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/nthread                                               1 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/objective                              reg:squarederror â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/subsample                            0.6073794211713953 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/tree_method                                        hist â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=9672, ip=100.64.35.74)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=9672, ip=100.64.35.74)\u001b[0m - (node_id=1241d9436b2265d61f4f92a4765fc79e6ca8d250507ff92e1ea3419e, ip=100.64.35.74, pid=9718) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=9672, ip=100.64.35.74)\u001b[0m - (node_id=1241d9436b2265d61f4f92a4765fc79e6ca8d250507ff92e1ea3419e, ip=100.64.35.74, pid=9719) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=9672, ip=100.64.35.74)\u001b[0m - (node_id=1241d9436b2265d61f4f92a4765fc79e6ca8d250507ff92e1ea3419e, ip=100.64.35.74, pid=9720) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=9672, ip=100.64.35.74)\u001b[0m - (node_id=1241d9436b2265d61f4f92a4765fc79e6ca8d250507ff92e1ea3419e, ip=100.64.35.74, pid=9721) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.480 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.480 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.480 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.480 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:09:18] [88]\ttrain-rmse:0.20911\tvalid-rmse:0.47794\n",
      "\u001b[36m(RayTrainWorker pid=9720, ip=100.64.35.74)\u001b[0m [12:09:18] Task [xgboost.ray-rank=00000002]:a0c3f3de46f7807d91ae584b24000000 got rank 2\n",
      "\u001b[36m(RayTrainWorker pid=9721, ip=100.64.35.74)\u001b[0m [12:09:18] Task [xgboost.ray-rank=00000003]:97556ddff76f17b9e4b6b32724000000 got rank 3\n",
      "\u001b[36m(RayTrainWorker pid=9719, ip=100.64.35.74)\u001b[0m [12:09:18] Task [xgboost.ray-rank=00000001]:c3454aaec92e753253a61d3224000000 got rank 1\n",
      "\u001b[36m(RayTrainWorker pid=9718, ip=100.64.35.74)\u001b[0m [12:09:18] Task [xgboost.ray-rank=00000000]:9233bc69d67dd9c40258ca3d24000000 got rank 0\n",
      "\u001b[36m(SplitCoordinator pid=9882, ip=100.64.35.74)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-08-29_06-53-11_170260_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=9882, ip=100.64.35.74)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:09:19] [49]\ttrain-rmse:0.44096\tvalid-rmse:0.50744\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.487 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:09:21] [89]\ttrain-rmse:0.20765\tvalid-rmse:0.47742\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.488 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(SplitCoordinator pid=9883, ip=100.64.35.74)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-08-29_06-53-11_170260_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=9883, ip=100.64.35.74)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=9672, ip=100.64.35.74)\u001b[0m [12:09:22] [0]\ttrain-rmse:1.15066\tvalid-rmse:1.13515\n",
      "\u001b[36m(XGBoostTrainer pid=9672, ip=100.64.35.74)\u001b[0m [12:09:22] [1]\ttrain-rmse:1.14408\tvalid-rmse:1.12887\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:09:22] [50]\ttrain-rmse:0.43953\tvalid-rmse:0.50726\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.504 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9672, ip=100.64.35.74)\u001b[0m [12:09:24] [2]\ttrain-rmse:1.13754\tvalid-rmse:1.12259\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.452 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.452 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.452 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.452 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial status: 3 RUNNING | 3 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current time: 2025-08-29 12:09:24. Total running time: 6min 11s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current best trial: 946e81ea with valid-rmse=0.47794214340676366 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.12372102335862595, 'max_depth': 8, 'min_child_weight': 0.05312265152593065, 'subsample': 0.9848787891831414, 'colsample_bytree': 0.9496429603242498, 'lambda': 0.002729148416240024, 'alpha': 0.0016047175175163718, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_946e81ea   RUNNING        0.123721                      8                0.0531227             0.984879                 0.949643        0.00272915       0.00160472       89            5.683         0.209113       0.477942 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_40f91dcb   RUNNING        0.158069                      5                4.35899               0.792105                 0.966918        0.800316         0.0164134        49            5.60274       0.441849       0.507994 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5793bdb6   RUNNING        0.00836553                    9                0.0374505             0.607379                 0.828608        0.00107156       3.67376           1            5.40112       1.15066        1.13515  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_65691eb2   TERMINATED     0.0166576                     5                0.0230802             0.885428                 0.784438        0.0153656        0.0139486        20            4.02765       0.968565       0.96315  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_42d76290   TERMINATED     0.0014152                     9                0.0178108             0.687814                 0.85763         0.0019692        0.00609112       60            3.93633       1.08652        1.07727  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_3e9fda17   TERMINATED     0.0012921                     9                0.0109805             0.867278                 0.839885        0.0905536        0.0516223        20            5.52629       1.135          1.12104  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.487 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:09:25] [90]\ttrain-rmse:0.20624\tvalid-rmse:0.47739\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.490 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9672, ip=100.64.35.74)\u001b[0m Worker 3 has failed.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:09:28] [51]\ttrain-rmse:0.43812\tvalid-rmse:0.50693\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.496 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial task failed for trial XGBoostTrainer_5793bdb6\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m     result = ray.get(future)\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/_private/worker.py\", line 2664, in get\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/_private/worker.py\", line 871, in get_objects\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m ray.exceptions.RayTaskError(ActorDiedError): \u001b[36mray::TrainTrainable.train_buffered()\u001b[39m (pid=9672, ip=100.64.35.74, actor_id=a3bc3baa2b84649ce6dab54a24000000, repr=XGBoostTrainer)\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 272, in train_buffered\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m     result = self.train()\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m     raise skipped from exception_cause(skipped)\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/air/_internal/util.py\", line 98, in run\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m     self._ret = self._target(*self._args, **self._kwargs)\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m     training_func=lambda: self._trainable_func(self.config),\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/train/base_trainer.py\", line 799, in _trainable_func\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 250, in _trainable_func\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/base_trainer.py\", line 107, in _train_coordinator_fn\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m     trainer.training_loop()\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/data_parallel_trainer.py\", line 471, in training_loop\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m     self._run_training(training_iterator)\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/data_parallel_trainer.py\", line 370, in _run_training\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m     for training_results in training_iterator:\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/trainer.py\", line 124, in __next__\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m     next_results = self._run_with_error_handling(self._fetch_next_result)\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/trainer.py\", line 89, in _run_with_error_handling\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m     return func()\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/trainer.py\", line 156, in _fetch_next_result\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m     results = self._backend_executor.get_next_results()\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/_internal/backend_executor.py\", line 606, in get_next_results\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m     results = self.get_with_failure_handling(futures)\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/_internal/backend_executor.py\", line 706, in get_with_failure_handling\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m     self._increment_failures()\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/_internal/backend_executor.py\", line 768, in _increment_failures\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m     raise failure\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/_internal/utils.py\", line 53, in check_for_failure\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m     ray.get(object_ref)\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \tclass_name: RayTrainWorker\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \tactor_id: 97556ddff76f17b9e4b6b32724000000\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \tpid: 9721\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \tnamespace: xgb-eval\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \tip: 100.64.35.74\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The actor is dead because all references to the actor were removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m ğŸƒ View run XGBoostTrainer_5793bdb6 at: http://ray-68b1b0be9652633ae57e1b88-ray-proxy:8765/#/experiments/257/runs/c96dbf3cac3b4f57a6f400984dcddf24\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m ğŸ§ª View experiment at: http://ray-68b1b0be9652633ae57e1b88-ray-proxy:8765/#/experiments/257\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial XGBoostTrainer_5793bdb6 errored after 2 iterations at 2025-08-29 12:09:29. Total running time: 6min 17s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Error file: /tmp/ray/session_2025-08-29_06-53-11_170260_1/artifacts/2025-08-29_12-03-12/xgb_from_s3_irsa/driver_artifacts/XGBoostTrainer_5793bdb6_6_alpha=3.6738,colsample_bytree=0.8286,eta=0.0084,eval_metric=rmse,lambda=0.0011,max_depth=9,min_child_wei_2025-08-29_12-09-12/error.txt\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial XGBoostTrainer_5793bdb6 result             â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ checkpoint_dir_name                              â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ time_this_iter_s                         0.00283 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ time_total_s                             5.40395 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ training_iteration                             2 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ train-rmse                               1.14408 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ valid-rmse                               1.12887 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.498 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:09:30] [91]\ttrain-rmse:0.20513\tvalid-rmse:0.47745\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.496 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:09:32] [52]\ttrain-rmse:0.43590\tvalid-rmse:0.50508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial XGBoostTrainer_2941d575 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial XGBoostTrainer_2941d575 config                         â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/alpha                              0.9283150753296506 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/colsample_bytree                   0.9592347912661334 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/eta                               0.03693961982196962 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/eval_metric                                      rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/lambda                             0.8943366023360291 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/max_depth                                           8 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/min_child_weight                  0.06449734783114569 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/nthread                                             1 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/objective                            reg:squarederror â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/subsample                          0.7517871816427439 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/tree_method                                      hist â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=10074, ip=100.64.35.74)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=10074, ip=100.64.35.74)\u001b[0m - (node_id=1241d9436b2265d61f4f92a4765fc79e6ca8d250507ff92e1ea3419e, ip=100.64.35.74, pid=10120) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=10074, ip=100.64.35.74)\u001b[0m - (node_id=1241d9436b2265d61f4f92a4765fc79e6ca8d250507ff92e1ea3419e, ip=100.64.35.74, pid=10121) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=10074, ip=100.64.35.74)\u001b[0m - (node_id=1241d9436b2265d61f4f92a4765fc79e6ca8d250507ff92e1ea3419e, ip=100.64.35.74, pid=10122) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=10074, ip=100.64.35.74)\u001b[0m - (node_id=1241d9436b2265d61f4f92a4765fc79e6ca8d250507ff92e1ea3419e, ip=100.64.35.74, pid=10123) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.496 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:09:34] [53]\ttrain-rmse:0.43460\tvalid-rmse:0.50428\n",
      "\u001b[36m(RayTrainWorker pid=10122, ip=100.64.35.74)\u001b[0m [12:09:35] Task [xgboost.ray-rank=00000002]:0f91b9bc9e1231a845ba857724000000 got rank 2\n",
      "\u001b[36m(RayTrainWorker pid=10123, ip=100.64.35.74)\u001b[0m [12:09:35] Task [xgboost.ray-rank=00000003]:89ceb993f0b9cb6e516b36e524000000 got rank 3\n",
      "\u001b[36m(RayTrainWorker pid=10120, ip=100.64.35.74)\u001b[0m [12:09:35] Task [xgboost.ray-rank=00000000]:efae595d95394cc7b9168ebf24000000 got rank 0\n",
      "\u001b[36m(RayTrainWorker pid=10121, ip=100.64.35.74)\u001b[0m [12:09:35] Task [xgboost.ray-rank=00000001]:a5f510f25d7925dfbe7f61f324000000 got rank 1\n",
      "\u001b[36m(SplitCoordinator pid=10284, ip=100.64.35.74)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-08-29_06-53-11_170260_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=10284, ip=100.64.35.74)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:09:36] [92]\ttrain-rmse:0.20367\tvalid-rmse:0.47705\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.478 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.479 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.479 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.479 s, which may be a performance bottleneck.\n",
      "\u001b[36m(SplitCoordinator pid=10285, ip=100.64.35.74)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-08-29_06-53-11_170260_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=10285, ip=100.64.35.74)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=10074, ip=100.64.35.74)\u001b[0m [12:09:37] [0]\ttrain-rmse:1.12743\tvalid-rmse:1.11373\n",
      "\u001b[36m(XGBoostTrainer pid=10074, ip=100.64.35.74)\u001b[0m [12:09:37] [1]\ttrain-rmse:1.09753\tvalid-rmse:1.08597\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.484 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.484 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.485 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.485 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:09:37] [54]\ttrain-rmse:0.43365\tvalid-rmse:0.50439\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.452 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.452 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.452 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.452 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10074, ip=100.64.35.74)\u001b[0m [12:09:39] [2]\ttrain-rmse:1.06854\tvalid-rmse:1.05879\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:09:40] [55]\ttrain-rmse:0.43330\tvalid-rmse:0.50409\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.479 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.479 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.479 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.479 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.502 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10074, ip=100.64.35.74)\u001b[0m [12:09:42] [3]\ttrain-rmse:1.04205\tvalid-rmse:1.03431\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:09:43] [56]\ttrain-rmse:0.43192\tvalid-rmse:0.50346\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.516 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.517 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.517 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.517 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.481 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.481 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.481 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.481 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:09:45] [57]\ttrain-rmse:0.43088\tvalid-rmse:0.50310\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:09:46] [93]\ttrain-rmse:0.20215\tvalid-rmse:0.47710\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.484 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.485 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.485 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.485 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:09:48] [58]\ttrain-rmse:0.42838\tvalid-rmse:0.50084\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.471 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.472 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.472 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.472 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.501 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:09:49] [94]\ttrain-rmse:0.20019\tvalid-rmse:0.47634\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.495 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:09:51] [59]\ttrain-rmse:0.42737\tvalid-rmse:0.50062\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:09:52] [95]\ttrain-rmse:0.19908\tvalid-rmse:0.47621\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.507 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial status: 3 RUNNING | 3 TERMINATED | 1 ERROR\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current time: 2025-08-29 12:09:54. Total running time: 6min 42s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current best trial: 946e81ea with valid-rmse=0.4763422373671862 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.12372102335862595, 'max_depth': 8, 'min_child_weight': 0.05312265152593065, 'subsample': 0.9848787891831414, 'colsample_bytree': 0.9496429603242498, 'lambda': 0.002729148416240024, 'alpha': 0.0016047175175163718, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_946e81ea   RUNNING        0.123721                      8                0.0531227             0.984879                 0.949643        0.00272915       0.00160472       95            5.69997       0.200193       0.476342 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_40f91dcb   RUNNING        0.158069                      5                4.35899               0.792105                 0.966918        0.800316         0.0164134        59            5.63042       0.428377       0.500839 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_2941d575   RUNNING        0.0369396                     8                0.0644973             0.751787                 0.959235        0.894337         0.928315          2            3.79842       1.09753        1.08597  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_65691eb2   TERMINATED     0.0166576                     5                0.0230802             0.885428                 0.784438        0.0153656        0.0139486        20            4.02765       0.968565       0.96315  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_42d76290   TERMINATED     0.0014152                     9                0.0178108             0.687814                 0.85763         0.0019692        0.00609112       60            3.93633       1.08652        1.07727  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_3e9fda17   TERMINATED     0.0012921                     9                0.0109805             0.867278                 0.839885        0.0905536        0.0516223        20            5.52629       1.135          1.12104  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5793bdb6   ERROR          0.00836553                    9                0.0374505             0.607379                 0.828608        0.00107156       3.67376           2            5.40395       1.14408        1.12887  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.502 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:09:54] [60]\ttrain-rmse:0.42612\tvalid-rmse:0.50001\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.512 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.513 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:09:55] [61]\ttrain-rmse:0.42552\tvalid-rmse:0.49967\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.486 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:09:57] [96]\ttrain-rmse:0.19821\tvalid-rmse:0.47619\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:09:58] [62]\ttrain-rmse:0.42476\tvalid-rmse:0.49929\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.488 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.489 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.485 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.485 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.486 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:10:00] [97]\ttrain-rmse:0.19690\tvalid-rmse:0.47592\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.491 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.491 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.491 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.491 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10074, ip=100.64.35.74)\u001b[0m [12:10:01] [4]\ttrain-rmse:1.01625\tvalid-rmse:1.01053\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.487 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:10:03] [63]\ttrain-rmse:0.42365\tvalid-rmse:0.49848\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.481 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.482 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.482 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.482 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10074, ip=100.64.35.74)\u001b[0m [12:10:04] [5]\ttrain-rmse:0.99102\tvalid-rmse:0.98725\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.497 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10074, ip=100.64.35.74)\u001b[0m [12:10:06] [6]\ttrain-rmse:0.96791\tvalid-rmse:0.96694\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.483 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.484 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.484 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.484 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:10:07] [98]\ttrain-rmse:0.19569\tvalid-rmse:0.47547\n",
      "\u001b[36m(XGBoostTrainer pid=10074, ip=100.64.35.74)\u001b[0m [12:10:09] [7]\ttrain-rmse:0.94436\tvalid-rmse:0.94504\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.497 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.488 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.489 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:10:10] [99]\ttrain-rmse:0.19412\tvalid-rmse:0.47533\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.518 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.518 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.518 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.518 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10074, ip=100.64.35.74)\u001b[0m [12:10:12] [8]\ttrain-rmse:0.92250\tvalid-rmse:0.92552\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.647 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.647 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.647 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.647 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:10:13] [100]\ttrain-rmse:0.19309\tvalid-rmse:0.47534\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.497 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:10:15] [64]\ttrain-rmse:0.42240\tvalid-rmse:0.49744\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.500 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:10:16] [101]\ttrain-rmse:0.19243\tvalid-rmse:0.47497\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:10:18] [65]\ttrain-rmse:0.42129\tvalid-rmse:0.49669\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.509 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.518 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.518 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.518 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.518 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:10:19] [102]\ttrain-rmse:0.19144\tvalid-rmse:0.47512\n",
      "\u001b[36m(XGBoostTrainer pid=10074, ip=100.64.35.74)\u001b[0m [12:10:21] [9]\ttrain-rmse:0.90022\tvalid-rmse:0.90548\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.491 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.491 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.491 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.482 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.482 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.482 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.483 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:10:22] [103]\ttrain-rmse:0.19043\tvalid-rmse:0.47515\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:10:24] [66]\ttrain-rmse:0.41983\tvalid-rmse:0.49532\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.495 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial status: 3 RUNNING | 3 TERMINATED | 1 ERROR\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current time: 2025-08-29 12:10:24. Total running time: 7min 12s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current best trial: 946e81ea with valid-rmse=0.4751223896928393 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.12372102335862595, 'max_depth': 8, 'min_child_weight': 0.05312265152593065, 'subsample': 0.9848787891831414, 'colsample_bytree': 0.9496429603242498, 'lambda': 0.002729148416240024, 'alpha': 0.0016047175175163718, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_946e81ea   RUNNING        0.123721                      8                0.0531227             0.984879                 0.949643        0.00272915       0.00160472      103            5.72186       0.191439       0.475122 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_40f91dcb   RUNNING        0.158069                      5                4.35899               0.792105                 0.966918        0.800316         0.0164134        65            5.64696       0.422402       0.497437 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_2941d575   RUNNING        0.0369396                     8                0.0644973             0.751787                 0.959235        0.894337         0.928315          8            3.81476       0.944357       0.945044 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_65691eb2   TERMINATED     0.0166576                     5                0.0230802             0.885428                 0.784438        0.0153656        0.0139486        20            4.02765       0.968565       0.96315  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_42d76290   TERMINATED     0.0014152                     9                0.0178108             0.687814                 0.85763         0.0019692        0.00609112       60            3.93633       1.08652        1.07727  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_3e9fda17   TERMINATED     0.0012921                     9                0.0109805             0.867278                 0.839885        0.0905536        0.0516223        20            5.52629       1.135          1.12104  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5793bdb6   ERROR          0.00836553                    9                0.0374505             0.607379                 0.828608        0.00107156       3.67376           2            5.40395       1.14408        1.12887  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.511 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.511 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.511 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.511 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:10:25] [104]\ttrain-rmse:0.18948\tvalid-rmse:0.47505\n",
      "\u001b[36m(XGBoostTrainer pid=10074, ip=100.64.35.74)\u001b[0m [12:10:27] [10]\ttrain-rmse:0.88058\tvalid-rmse:0.88805\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.493 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.481 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.482 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.482 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.482 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:10:28] [105]\ttrain-rmse:0.18822\tvalid-rmse:0.47513\n",
      "\u001b[36m(XGBoostTrainer pid=10074, ip=100.64.35.74)\u001b[0m [12:10:30] [11]\ttrain-rmse:0.86021\tvalid-rmse:0.86989\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.488 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.500 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:10:31] [106]\ttrain-rmse:0.18749\tvalid-rmse:0.47514\n",
      "\u001b[36m(XGBoostTrainer pid=10074, ip=100.64.35.74)\u001b[0m [12:10:33] [12]\ttrain-rmse:0.84208\tvalid-rmse:0.85408\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.491 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.492 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.496 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:10:34] [107]\ttrain-rmse:0.18639\tvalid-rmse:0.47533\n",
      "\u001b[36m(XGBoostTrainer pid=10074, ip=100.64.35.74)\u001b[0m [12:10:36] [13]\ttrain-rmse:0.82490\tvalid-rmse:0.83934\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.509 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.498 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10074, ip=100.64.35.74)\u001b[0m [12:10:37] [14]\ttrain-rmse:0.80701\tvalid-rmse:0.82292\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:10:39] [67]\ttrain-rmse:0.41899\tvalid-rmse:0.49551\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.482 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.482 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.483 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.483 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10074, ip=100.64.35.74)\u001b[0m [12:10:40] [15]\ttrain-rmse:0.78927\tvalid-rmse:0.80725\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.475 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.475 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.475 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.475 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:10:42] [108]\ttrain-rmse:0.18569\tvalid-rmse:0.47523\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.499 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.501 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10074, ip=100.64.35.74)\u001b[0m [12:10:43] [16]\ttrain-rmse:0.77299\tvalid-rmse:0.79278\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:10:45] [109]\ttrain-rmse:0.18454\tvalid-rmse:0.47520\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.497 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10074, ip=100.64.35.74)\u001b[0m [12:10:46] [17]\ttrain-rmse:0.75754\tvalid-rmse:0.77885\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.491 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.491 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.491 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10074, ip=100.64.35.74)\u001b[0m [12:10:48] [18]\ttrain-rmse:0.74363\tvalid-rmse:0.76745\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.517 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.517 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.517 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.517 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.478 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.479 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.479 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.479 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:10:49] [68]\ttrain-rmse:0.41849\tvalid-rmse:0.49533\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:10:51] [110]\ttrain-rmse:0.18406\tvalid-rmse:0.47500\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.497 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.508 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10074, ip=100.64.35.74)\u001b[0m [12:10:52] [19]\ttrain-rmse:0.72907\tvalid-rmse:0.75489\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.522 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.523 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.523 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.523 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:10:54] [111]\ttrain-rmse:0.18296\tvalid-rmse:0.47498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial status: 3 RUNNING | 3 TERMINATED | 1 ERROR\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current time: 2025-08-29 12:10:55. Total running time: 7min 43s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current best trial: 946e81ea with valid-rmse=0.4749950528630406 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.12372102335862595, 'max_depth': 8, 'min_child_weight': 0.05312265152593065, 'subsample': 0.9848787891831414, 'colsample_bytree': 0.9496429603242498, 'lambda': 0.002729148416240024, 'alpha': 0.0016047175175163718, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_946e81ea   RUNNING        0.123721                      8                0.0531227             0.984879                 0.949643        0.00272915       0.00160472      111            5.74356       0.184057       0.474995 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_40f91dcb   RUNNING        0.158069                      5                4.35899               0.792105                 0.966918        0.800316         0.0164134        67            5.65273       0.41983        0.495323 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_2941d575   RUNNING        0.0369396                     8                0.0644973             0.751787                 0.959235        0.894337         0.928315         19            3.84562       0.74363        0.767445 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_65691eb2   TERMINATED     0.0166576                     5                0.0230802             0.885428                 0.784438        0.0153656        0.0139486        20            4.02765       0.968565       0.96315  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_42d76290   TERMINATED     0.0014152                     9                0.0178108             0.687814                 0.85763         0.0019692        0.00609112       60            3.93633       1.08652        1.07727  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_3e9fda17   TERMINATED     0.0012921                     9                0.0109805             0.867278                 0.839885        0.0905536        0.0516223        20            5.52629       1.135          1.12104  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5793bdb6   ERROR          0.00836553                    9                0.0374505             0.607379                 0.828608        0.00107156       3.67376           2            5.40395       1.14408        1.12887  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.506 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10074, ip=100.64.35.74)\u001b[0m [12:10:55] [20]\ttrain-rmse:0.71586\tvalid-rmse:0.74383\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.504 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:10:57] [69]\ttrain-rmse:0.41737\tvalid-rmse:0.49501\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:10:58] [70]\ttrain-rmse:0.41542\tvalid-rmse:0.49313\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.499 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:11:00] [112]\ttrain-rmse:0.18228\tvalid-rmse:0.47509\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.505 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.515 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.515 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:11:01] [71]\ttrain-rmse:0.41459\tvalid-rmse:0.49286\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:11:03] [113]\ttrain-rmse:0.18177\tvalid-rmse:0.47494\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.518 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.518 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.518 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.518 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:11:04] [72]\ttrain-rmse:0.41385\tvalid-rmse:0.49265\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.524 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.524 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.524 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.524 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.508 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:11:06] [114]\ttrain-rmse:0.18010\tvalid-rmse:0.47477\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.504 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:11:08] [73]\ttrain-rmse:0.41243\tvalid-rmse:0.49167\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:11:09] [115]\ttrain-rmse:0.17950\tvalid-rmse:0.47497\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.507 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.510 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m ğŸƒ View run XGBoostTrainer_2941d575 at: http://ray-68b1b0be9652633ae57e1b88-ray-proxy:8765/#/experiments/257/runs/a48beefa39ff4e2f8bb92a0700d5e13d\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m ğŸ§ª View experiment at: http://ray-68b1b0be9652633ae57e1b88-ray-proxy:8765/#/experiments/257\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial XGBoostTrainer_2941d575 completed after 20 iterations at 2025-08-29 12:11:11. Total running time: 7min 59s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial XGBoostTrainer_2941d575 result             â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ checkpoint_dir_name                              â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ time_this_iter_s                         0.00293 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ time_total_s                             3.84855 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ training_iteration                            20 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ train-rmse                               0.72907 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ valid-rmse                               0.75489 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:11:13] [116]\ttrain-rmse:0.17841\tvalid-rmse:0.47483\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.514 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.487 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:11:14] [74]\ttrain-rmse:0.41156\tvalid-rmse:0.49084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial XGBoostTrainer_5f5ae774 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial XGBoostTrainer_5f5ae774 config                          â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/alpha                             0.008733921098088394 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/colsample_bytree                    0.9288414527244133 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/eta                               0.004448758536856311 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/eval_metric                                       rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/lambda                                2.25626392317382 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/max_depth                                            5 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/min_child_weight                    1.0455730141281068 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/nthread                                              1 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/objective                             reg:squarederror â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/subsample                           0.8764130248738984 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/tree_method                                       hist â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=10354, ip=100.64.7.216)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=10354, ip=100.64.7.216)\u001b[0m - (node_id=9212372711d6417a3d6338c92f31be45ef97cdcf4ce252eb19b5435a, ip=100.64.7.216, pid=10400) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=10354, ip=100.64.7.216)\u001b[0m - (node_id=9212372711d6417a3d6338c92f31be45ef97cdcf4ce252eb19b5435a, ip=100.64.7.216, pid=10401) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=10354, ip=100.64.7.216)\u001b[0m - (node_id=9212372711d6417a3d6338c92f31be45ef97cdcf4ce252eb19b5435a, ip=100.64.7.216, pid=10402) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=10354, ip=100.64.7.216)\u001b[0m - (node_id=9212372711d6417a3d6338c92f31be45ef97cdcf4ce252eb19b5435a, ip=100.64.7.216, pid=10403) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:11:17] [117]\ttrain-rmse:0.17757\tvalid-rmse:0.47488\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.497 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(RayTrainWorker pid=10402, ip=100.64.7.216)\u001b[0m [12:11:17] Task [xgboost.ray-rank=00000002]:47f6148f3f3824c3668eef9424000000 got rank 2\n",
      "\u001b[36m(RayTrainWorker pid=10401, ip=100.64.7.216)\u001b[0m [12:11:17] Task [xgboost.ray-rank=00000001]:3c6cfd79653d8792c76d7a5f24000000 got rank 1\n",
      "\u001b[36m(RayTrainWorker pid=10403, ip=100.64.7.216)\u001b[0m [12:11:17] Task [xgboost.ray-rank=00000003]:5265df0344a6d26fdbcf193e24000000 got rank 3\n",
      "\u001b[36m(RayTrainWorker pid=10400, ip=100.64.7.216)\u001b[0m [12:11:17] Task [xgboost.ray-rank=00000000]:47f7109186e318da0fce85b624000000 got rank 0\n",
      "\u001b[36m(SplitCoordinator pid=10564, ip=100.64.7.216)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-08-29_06-53-11_170260_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=10564, ip=100.64.7.216)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.505 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:11:18] [75]\ttrain-rmse:0.40952\tvalid-rmse:0.48903\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.501 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(SplitCoordinator pid=10565, ip=100.64.7.216)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-08-29_06-53-11_170260_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=10565, ip=100.64.7.216)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:11:20] [118]\ttrain-rmse:0.17663\tvalid-rmse:0.47446\n",
      "\u001b[36m(XGBoostTrainer pid=10354, ip=100.64.7.216)\u001b[0m [12:11:21] [0]\ttrain-rmse:1.15426\tvalid-rmse:1.13835\n",
      "\u001b[36m(XGBoostTrainer pid=10354, ip=100.64.7.216)\u001b[0m [12:11:21] [1]\ttrain-rmse:1.15107\tvalid-rmse:1.13531\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:11:21] [76]\ttrain-rmse:0.40840\tvalid-rmse:0.48882\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.508 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.475 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.475 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.475 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.475 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10354, ip=100.64.7.216)\u001b[0m [12:11:23] [2]\ttrain-rmse:1.14788\tvalid-rmse:1.13227\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:11:24] [77]\ttrain-rmse:0.40750\tvalid-rmse:0.48869\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.511 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.511 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.511 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial status: 3 RUNNING | 4 TERMINATED | 1 ERROR\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current time: 2025-08-29 12:11:26. Total running time: 8min 14s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current best trial: 946e81ea with valid-rmse=0.4748802954870651 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.12372102335862595, 'max_depth': 8, 'min_child_weight': 0.05312265152593065, 'subsample': 0.9848787891831414, 'colsample_bytree': 0.9496429603242498, 'lambda': 0.002729148416240024, 'alpha': 0.0016047175175163718, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_946e81ea   RUNNING        0.123721                      8                0.0531227             0.984879                 0.949643        0.00272915       0.00160472      118            5.76279       0.177572       0.47488  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_40f91dcb   RUNNING        0.158069                      5                4.35899               0.792105                 0.966918        0.800316         0.0164134        76            5.67811       0.409516       0.489033 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5f5ae774   RUNNING        0.00444876                    5                1.04557               0.876413                 0.928841        2.25626          0.00873392        2            5.27355       1.15107        1.13531  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_65691eb2   TERMINATED     0.0166576                     5                0.0230802             0.885428                 0.784438        0.0153656        0.0139486        20            4.02765       0.968565       0.96315  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_42d76290   TERMINATED     0.0014152                     9                0.0178108             0.687814                 0.85763         0.0019692        0.00609112       60            3.93633       1.08652        1.07727  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_3e9fda17   TERMINATED     0.0012921                     9                0.0109805             0.867278                 0.839885        0.0905536        0.0516223        20            5.52629       1.135          1.12104  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_2941d575   TERMINATED     0.0369396                     8                0.0644973             0.751787                 0.959235        0.894337         0.928315         20            3.84855       0.729068       0.75489  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5793bdb6   ERROR          0.00836553                    9                0.0374505             0.607379                 0.828608        0.00107156       3.67376           2            5.40395       1.14408        1.12887  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.682 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.683 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.683 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.683 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10354, ip=100.64.7.216)\u001b[0m [12:11:26] [3]\ttrain-rmse:1.14471\tvalid-rmse:1.12927\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:11:27] [78]\ttrain-rmse:0.40626\tvalid-rmse:0.48846\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.502 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10354, ip=100.64.7.216)\u001b[0m [12:11:29] [4]\ttrain-rmse:1.14158\tvalid-rmse:1.12630\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.482 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.482 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.482 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.482 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.487 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:11:30] [79]\ttrain-rmse:0.40530\tvalid-rmse:0.48808\n",
      "\u001b[36m(XGBoostTrainer pid=10354, ip=100.64.7.216)\u001b[0m [12:11:32] [5]\ttrain-rmse:1.13850\tvalid-rmse:1.12340\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.491 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.492 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.492 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:11:33] [80]\ttrain-rmse:0.40446\tvalid-rmse:0.48772\n",
      "\u001b[36m(XGBoostTrainer pid=10354, ip=100.64.7.216)\u001b[0m [12:11:35] [6]\ttrain-rmse:1.13538\tvalid-rmse:1.12047\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.506 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.483 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.484 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.484 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.484 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:11:36] [81]\ttrain-rmse:0.40376\tvalid-rmse:0.48745\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.523 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.523 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.523 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.523 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:11:38] [119]\ttrain-rmse:0.17566\tvalid-rmse:0.47453\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.512 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.513 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:11:39] [82]\ttrain-rmse:0.40323\tvalid-rmse:0.48718\n",
      "\u001b[36m(XGBoostTrainer pid=10354, ip=100.64.7.216)\u001b[0m [12:11:41] [7]\ttrain-rmse:1.13226\tvalid-rmse:1.11748\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.497 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:11:42] [120]\ttrain-rmse:0.17500\tvalid-rmse:0.47441\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.494 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.505 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10354, ip=100.64.7.216)\u001b[0m [12:11:44] [8]\ttrain-rmse:1.12937\tvalid-rmse:1.11480\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:11:45] [121]\ttrain-rmse:0.17437\tvalid-rmse:0.47437\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.500 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.497 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10354, ip=100.64.7.216)\u001b[0m [12:11:47] [9]\ttrain-rmse:1.12634\tvalid-rmse:1.11198\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:11:48] [83]\ttrain-rmse:0.40241\tvalid-rmse:0.48712\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.480 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.481 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.481 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.481 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.488 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:11:50] [122]\ttrain-rmse:0.17354\tvalid-rmse:0.47438\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.523 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.523 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.523 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.523 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10354, ip=100.64.7.216)\u001b[0m [12:11:52] [10]\ttrain-rmse:1.12329\tvalid-rmse:1.10909\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.492 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:11:53] [84]\ttrain-rmse:0.40142\tvalid-rmse:0.48729\n",
      "\u001b[36m(XGBoostTrainer pid=10354, ip=100.64.7.216)\u001b[0m [12:11:54] [11]\ttrain-rmse:1.12026\tvalid-rmse:1.10618\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.488 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.489 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.500 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:11:56] [85]\ttrain-rmse:0.40022\tvalid-rmse:0.48704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial status: 3 RUNNING | 4 TERMINATED | 1 ERROR\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current time: 2025-08-29 12:11:57. Total running time: 8min 45s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current best trial: 946e81ea with valid-rmse=0.47437349638102877 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.12372102335862595, 'max_depth': 8, 'min_child_weight': 0.05312265152593065, 'subsample': 0.9848787891831414, 'colsample_bytree': 0.9496429603242498, 'lambda': 0.002729148416240024, 'alpha': 0.0016047175175163718, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_946e81ea   RUNNING        0.123721                      8                0.0531227             0.984879                 0.949643        0.00272915       0.00160472      122            5.77404       0.174371       0.474373 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_40f91dcb   RUNNING        0.158069                      5                4.35899               0.792105                 0.966918        0.800316         0.0164134        84            5.69978       0.402414       0.487124 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5f5ae774   RUNNING        0.00444876                    5                1.04557               0.876413                 0.928841        2.25626          0.00873392       11            5.2997        1.12329        1.10909  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_65691eb2   TERMINATED     0.0166576                     5                0.0230802             0.885428                 0.784438        0.0153656        0.0139486        20            4.02765       0.968565       0.96315  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_42d76290   TERMINATED     0.0014152                     9                0.0178108             0.687814                 0.85763         0.0019692        0.00609112       60            3.93633       1.08652        1.07727  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_3e9fda17   TERMINATED     0.0012921                     9                0.0109805             0.867278                 0.839885        0.0905536        0.0516223        20            5.52629       1.135          1.12104  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_2941d575   TERMINATED     0.0369396                     8                0.0644973             0.751787                 0.959235        0.894337         0.928315         20            3.84855       0.729068       0.75489  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5793bdb6   ERROR          0.00836553                    9                0.0374505             0.607379                 0.828608        0.00107156       3.67376           2            5.40395       1.14408        1.12887  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.491 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.492 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10354, ip=100.64.7.216)\u001b[0m [12:11:57] [12]\ttrain-rmse:1.11725\tvalid-rmse:1.10334\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:11:59] [86]\ttrain-rmse:0.39918\tvalid-rmse:0.48678\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.496 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10354, ip=100.64.7.216)\u001b[0m [12:12:00] [13]\ttrain-rmse:1.11427\tvalid-rmse:1.10051\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.492 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.502 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:12:02] [87]\ttrain-rmse:0.39842\tvalid-rmse:0.48652\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.509 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:12:03] [123]\ttrain-rmse:0.17216\tvalid-rmse:0.47435\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.496 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:12:05] [88]\ttrain-rmse:0.39785\tvalid-rmse:0.48633\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.510 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:12:06] [124]\ttrain-rmse:0.17133\tvalid-rmse:0.47440\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:12:08] [89]\ttrain-rmse:0.39694\tvalid-rmse:0.48600\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.502 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.507 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10354, ip=100.64.7.216)\u001b[0m [12:12:10] [14]\ttrain-rmse:1.11208\tvalid-rmse:1.09841\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.494 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:12:11] [90]\ttrain-rmse:0.39599\tvalid-rmse:0.48570\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.508 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10354, ip=100.64.7.216)\u001b[0m [12:12:13] [15]\ttrain-rmse:1.10912\tvalid-rmse:1.09557\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.494 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:12:14] [91]\ttrain-rmse:0.39455\tvalid-rmse:0.48475\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.522 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.522 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.522 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.522 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10354, ip=100.64.7.216)\u001b[0m [12:12:16] [16]\ttrain-rmse:1.10617\tvalid-rmse:1.09279\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:12:17] [92]\ttrain-rmse:0.39417\tvalid-rmse:0.48472\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.500 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10354, ip=100.64.7.216)\u001b[0m [12:12:19] [17]\ttrain-rmse:1.10399\tvalid-rmse:1.09070\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.508 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.507 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:12:20] [93]\ttrain-rmse:0.39322\tvalid-rmse:0.48450\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.512 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.513 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10354, ip=100.64.7.216)\u001b[0m [12:12:22] [18]\ttrain-rmse:1.10107\tvalid-rmse:1.08794\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:12:23] [94]\ttrain-rmse:0.39212\tvalid-rmse:0.48398\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.520 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.520 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.520 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.521 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.490 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:12:25] [125]\ttrain-rmse:0.17021\tvalid-rmse:0.47431\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.495 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:12:26] [95]\ttrain-rmse:0.39132\tvalid-rmse:0.48382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial status: 3 RUNNING | 4 TERMINATED | 1 ERROR\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current time: 2025-08-29 12:12:28. Total running time: 9min 15s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current best trial: 946e81ea with valid-rmse=0.474310402729052 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.12372102335862595, 'max_depth': 8, 'min_child_weight': 0.05312265152593065, 'subsample': 0.9848787891831414, 'colsample_bytree': 0.9496429603242498, 'lambda': 0.002729148416240024, 'alpha': 0.0016047175175163718, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_946e81ea   RUNNING        0.123721                      8                0.0531227             0.984879                 0.949643        0.00272915       0.00160472      126            5.78547       0.170214       0.47431  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_40f91dcb   RUNNING        0.158069                      5                4.35899               0.792105                 0.966918        0.800316         0.0164134        94            5.72888       0.393221       0.484502 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5f5ae774   RUNNING        0.00444876                    5                1.04557               0.876413                 0.928841        2.25626          0.00873392       17            5.31656       1.10617        1.09279  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_65691eb2   TERMINATED     0.0166576                     5                0.0230802             0.885428                 0.784438        0.0153656        0.0139486        20            4.02765       0.968565       0.96315  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_42d76290   TERMINATED     0.0014152                     9                0.0178108             0.687814                 0.85763         0.0019692        0.00609112       60            3.93633       1.08652        1.07727  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_3e9fda17   TERMINATED     0.0012921                     9                0.0109805             0.867278                 0.839885        0.0905536        0.0516223        20            5.52629       1.135          1.12104  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_2941d575   TERMINATED     0.0369396                     8                0.0644973             0.751787                 0.959235        0.894337         0.928315         20            3.84855       0.729068       0.75489  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5793bdb6   ERROR          0.00836553                    9                0.0374505             0.607379                 0.828608        0.00107156       3.67376           2            5.40395       1.14408        1.12887  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.497 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:12:28] [126]\ttrain-rmse:0.16932\tvalid-rmse:0.47420\n",
      "\u001b[36m(XGBoostTrainer pid=10354, ip=100.64.7.216)\u001b[0m [12:12:29] [19]\ttrain-rmse:1.09812\tvalid-rmse:1.08513\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.499 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.499 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:12:31] [127]\ttrain-rmse:0.16842\tvalid-rmse:0.47411\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.514 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10354, ip=100.64.7.216)\u001b[0m [12:12:32] [20]\ttrain-rmse:1.09524\tvalid-rmse:1.08239\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.543 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.543 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.543 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.543 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m ğŸƒ View run XGBoostTrainer_5f5ae774 at: http://ray-68b1b0be9652633ae57e1b88-ray-proxy:8765/#/experiments/257/runs/1723f09d87a248b79297528886d309fe\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m ğŸ§ª View experiment at: http://ray-68b1b0be9652633ae57e1b88-ray-proxy:8765/#/experiments/257\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial XGBoostTrainer_5f5ae774 completed after 20 iterations at 2025-08-29 12:12:34. Total running time: 9min 22s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial XGBoostTrainer_5f5ae774 result             â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ checkpoint_dir_name                              â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ time_this_iter_s                         0.00289 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ time_total_s                             5.32517 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ training_iteration                            20 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ train-rmse                               1.09812 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ valid-rmse                               1.08513 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.673 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.673 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.673 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.673 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:12:36] [128]\ttrain-rmse:0.16745\tvalid-rmse:0.47399\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.512 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.512 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.512 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.512 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:12:37] [96]\ttrain-rmse:0.39011\tvalid-rmse:0.48346\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.493 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:12:39] [129]\ttrain-rmse:0.16702\tvalid-rmse:0.47405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial XGBoostTrainer_727dbcd3 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial XGBoostTrainer_727dbcd3 config                          â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/alpha                              0.06652496912600056 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/colsample_bytree                    0.9904877263788023 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/eta                               0.009376077930013646 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/eval_metric                                       rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/lambda                               8.925067194619192 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/max_depth                                            6 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/min_child_weight                    0.2965845214852923 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/nthread                                              1 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/objective                             reg:squarederror â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/subsample                           0.6306408315171389 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/tree_method                                       hist â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=10623, ip=100.64.35.74)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=10623, ip=100.64.35.74)\u001b[0m - (node_id=1241d9436b2265d61f4f92a4765fc79e6ca8d250507ff92e1ea3419e, ip=100.64.35.74, pid=10669) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=10623, ip=100.64.35.74)\u001b[0m - (node_id=1241d9436b2265d61f4f92a4765fc79e6ca8d250507ff92e1ea3419e, ip=100.64.35.74, pid=10670) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=10623, ip=100.64.35.74)\u001b[0m - (node_id=1241d9436b2265d61f4f92a4765fc79e6ca8d250507ff92e1ea3419e, ip=100.64.35.74, pid=10671) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=10623, ip=100.64.35.74)\u001b[0m - (node_id=1241d9436b2265d61f4f92a4765fc79e6ca8d250507ff92e1ea3419e, ip=100.64.35.74, pid=10672) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.525 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.526 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.526 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.526 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:12:41] [97]\ttrain-rmse:0.38942\tvalid-rmse:0.48322\n",
      "\u001b[36m(RayTrainWorker pid=10671, ip=100.64.35.74)\u001b[0m [12:12:42] Task [xgboost.ray-rank=00000002]:358fca4e3f44db81251ce3ea24000000 got rank 2\n",
      "\u001b[36m(RayTrainWorker pid=10672, ip=100.64.35.74)\u001b[0m [12:12:42] Task [xgboost.ray-rank=00000003]:3e5717847625fd6ea9c0d29724000000 got rank 3\n",
      "\u001b[36m(RayTrainWorker pid=10670, ip=100.64.35.74)\u001b[0m [12:12:42] Task [xgboost.ray-rank=00000001]:5112508ca76494790f8f889a24000000 got rank 1\n",
      "\u001b[36m(RayTrainWorker pid=10669, ip=100.64.35.74)\u001b[0m [12:12:42] Task [xgboost.ray-rank=00000000]:800ddf7c32bfc1c46d7bb8db24000000 got rank 0\n",
      "\u001b[36m(SplitCoordinator pid=10833, ip=100.64.35.74)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-08-29_06-53-11_170260_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=10833, ip=100.64.35.74)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.506 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:12:43] [130]\ttrain-rmse:0.16631\tvalid-rmse:0.47407\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.497 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:12:44] [98]\ttrain-rmse:0.38865\tvalid-rmse:0.48291\n",
      "\u001b[36m(SplitCoordinator pid=10834, ip=100.64.35.74)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-08-29_06-53-11_170260_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=10834, ip=100.64.35.74)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=10623, ip=100.64.35.74)\u001b[0m [12:12:46] [0]\ttrain-rmse:1.15055\tvalid-rmse:1.13491\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.519 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.519 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.519 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.519 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:12:46] [131]\ttrain-rmse:0.16552\tvalid-rmse:0.47419\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:12:47] [99]\ttrain-rmse:0.38753\tvalid-rmse:0.48269\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.500 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.464 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.465 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.465 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.465 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10623, ip=100.64.35.74)\u001b[0m [12:12:49] [1]\ttrain-rmse:1.14370\tvalid-rmse:1.12846\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:12:50] [100]\ttrain-rmse:0.38616\tvalid-rmse:0.48214\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.494 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:12:52] [132]\ttrain-rmse:0.16469\tvalid-rmse:0.47403\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.510 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10623, ip=100.64.35.74)\u001b[0m [12:12:53] [2]\ttrain-rmse:1.13674\tvalid-rmse:1.12182\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.500 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.506 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10623, ip=100.64.35.74)\u001b[0m [12:12:55] [3]\ttrain-rmse:1.13012\tvalid-rmse:1.11549\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:12:56] [101]\ttrain-rmse:0.38552\tvalid-rmse:0.48209\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.491 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.492 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10623, ip=100.64.35.74)\u001b[0m [12:12:58] [4]\ttrain-rmse:1.12337\tvalid-rmse:1.10907\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.501 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED | 1 ERROR\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current time: 2025-08-29 12:12:58. Total running time: 9min 46s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current best trial: 946e81ea with valid-rmse=0.47419394675277854 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.12372102335862595, 'max_depth': 8, 'min_child_weight': 0.05312265152593065, 'subsample': 0.9848787891831414, 'colsample_bytree': 0.9496429603242498, 'lambda': 0.002729148416240024, 'alpha': 0.0016047175175163718, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_946e81ea   RUNNING        0.123721                      8                0.0531227             0.984879                 0.949643        0.00272915       0.00160472      132            5.80144       0.16552        0.474194 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_40f91dcb   RUNNING        0.158069                      5                4.35899               0.792105                 0.966918        0.800316         0.0164134       100            5.74557       0.387535       0.48269  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_727dbcd3   RUNNING        0.00937608                    6                0.296585              0.630641                 0.990488        8.92507          0.066525          4            5.6274        1.13012        1.11549  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_65691eb2   TERMINATED     0.0166576                     5                0.0230802             0.885428                 0.784438        0.0153656        0.0139486        20            4.02765       0.968565       0.96315  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_42d76290   TERMINATED     0.0014152                     9                0.0178108             0.687814                 0.85763         0.0019692        0.00609112       60            3.93633       1.08652        1.07727  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_3e9fda17   TERMINATED     0.0012921                     9                0.0109805             0.867278                 0.839885        0.0905536        0.0516223        20            5.52629       1.135          1.12104  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_2941d575   TERMINATED     0.0369396                     8                0.0644973             0.751787                 0.959235        0.894337         0.928315         20            3.84855       0.729068       0.75489  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5f5ae774   TERMINATED     0.00444876                    5                1.04557               0.876413                 0.928841        2.25626          0.00873392       20            5.32517       1.09812        1.08513  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5793bdb6   ERROR          0.00836553                    9                0.0374505             0.607379                 0.828608        0.00107156       3.67376           2            5.40395       1.14408        1.12887  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.497 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:12:59] [102]\ttrain-rmse:0.38454\tvalid-rmse:0.48224\n",
      "\u001b[36m(XGBoostTrainer pid=10623, ip=100.64.35.74)\u001b[0m [12:13:01] [5]\ttrain-rmse:1.11692\tvalid-rmse:1.10299\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.536 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.536 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.536 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.536 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.502 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:13:02] [103]\ttrain-rmse:0.38362\tvalid-rmse:0.48176\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.511 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.511 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.511 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10623, ip=100.64.35.74)\u001b[0m [12:13:04] [6]\ttrain-rmse:1.11055\tvalid-rmse:1.09702\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.501 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:13:06] [104]\ttrain-rmse:0.38235\tvalid-rmse:0.48094\n",
      "\u001b[36m(XGBoostTrainer pid=10623, ip=100.64.35.74)\u001b[0m [12:13:07] [7]\ttrain-rmse:1.10407\tvalid-rmse:1.09082\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.492 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.488 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:13:08] [105]\ttrain-rmse:0.38170\tvalid-rmse:0.48099\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.497 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10623, ip=100.64.35.74)\u001b[0m [12:13:10] [8]\ttrain-rmse:1.09817\tvalid-rmse:1.08537\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.499 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:13:11] [133]\ttrain-rmse:0.16333\tvalid-rmse:0.47402\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:13:13] [106]\ttrain-rmse:0.38123\tvalid-rmse:0.48071\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.487 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10623, ip=100.64.35.74)\u001b[0m [12:13:14] [9]\ttrain-rmse:1.09180\tvalid-rmse:1.07944\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.487 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.489 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.490 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:13:16] [134]\ttrain-rmse:0.16257\tvalid-rmse:0.47381\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:13:17] [107]\ttrain-rmse:0.38063\tvalid-rmse:0.48065\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.515 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.515 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.515 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.515 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.488 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:13:19] [135]\ttrain-rmse:0.16179\tvalid-rmse:0.47374\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.496 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10623, ip=100.64.35.74)\u001b[0m [12:13:20] [10]\ttrain-rmse:1.08564\tvalid-rmse:1.07362\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.503 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:13:22] [136]\ttrain-rmse:0.16055\tvalid-rmse:0.47348\n",
      "\u001b[36m(XGBoostTrainer pid=10623, ip=100.64.35.74)\u001b[0m [12:13:23] [11]\ttrain-rmse:1.07943\tvalid-rmse:1.06770\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.503 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.504 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:13:25] [137]\ttrain-rmse:0.16027\tvalid-rmse:0.47343\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.510 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10623, ip=100.64.35.74)\u001b[0m [12:13:26] [12]\ttrain-rmse:1.07340\tvalid-rmse:1.06208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED | 1 ERROR\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current time: 2025-08-29 12:13:28. Total running time: 10min 16s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current best trial: 946e81ea with valid-rmse=0.47343404024698765 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.12372102335862595, 'max_depth': 8, 'min_child_weight': 0.05312265152593065, 'subsample': 0.9848787891831414, 'colsample_bytree': 0.9496429603242498, 'lambda': 0.002729148416240024, 'alpha': 0.0016047175175163718, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_946e81ea   RUNNING        0.123721                      8                0.0531227             0.984879                 0.949643        0.00272915       0.00160472      138            5.81801       0.16027        0.473434 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_40f91dcb   RUNNING        0.158069                      5                4.35899               0.792105                 0.966918        0.800316         0.0164134       106            5.76262       0.381699       0.48099  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_727dbcd3   RUNNING        0.00937608                    6                0.296585              0.630641                 0.990488        8.92507          0.066525         12            5.64938       1.07943        1.0677   â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_65691eb2   TERMINATED     0.0166576                     5                0.0230802             0.885428                 0.784438        0.0153656        0.0139486        20            4.02765       0.968565       0.96315  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_42d76290   TERMINATED     0.0014152                     9                0.0178108             0.687814                 0.85763         0.0019692        0.00609112       60            3.93633       1.08652        1.07727  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_3e9fda17   TERMINATED     0.0012921                     9                0.0109805             0.867278                 0.839885        0.0905536        0.0516223        20            5.52629       1.135          1.12104  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_2941d575   TERMINATED     0.0369396                     8                0.0644973             0.751787                 0.959235        0.894337         0.928315         20            3.84855       0.729068       0.75489  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5f5ae774   TERMINATED     0.00444876                    5                1.04557               0.876413                 0.928841        2.25626          0.00873392       20            5.32517       1.09812        1.08513  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5793bdb6   ERROR          0.00836553                    9                0.0374505             0.607379                 0.828608        0.00107156       3.67376           2            5.40395       1.14408        1.12887  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.501 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:13:28] [138]\ttrain-rmse:0.15950\tvalid-rmse:0.47351\n",
      "\u001b[36m(XGBoostTrainer pid=10623, ip=100.64.35.74)\u001b[0m [12:13:29] [13]\ttrain-rmse:1.06744\tvalid-rmse:1.05649\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.489 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.489 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.489 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.489 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:13:31] [139]\ttrain-rmse:0.15900\tvalid-rmse:0.47350\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.487 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.501 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10623, ip=100.64.35.74)\u001b[0m [12:13:32] [14]\ttrain-rmse:1.06268\tvalid-rmse:1.05197\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:13:34] [108]\ttrain-rmse:0.37982\tvalid-rmse:0.48043\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.518 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.519 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.519 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.519 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10623, ip=100.64.35.74)\u001b[0m [12:13:35] [15]\ttrain-rmse:1.05681\tvalid-rmse:1.04645\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.498 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:13:37] [109]\ttrain-rmse:0.37932\tvalid-rmse:0.48041\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.487 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.504 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10623, ip=100.64.35.74)\u001b[0m [12:13:38] [16]\ttrain-rmse:1.05106\tvalid-rmse:1.04102\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.505 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:13:40] [140]\ttrain-rmse:0.15875\tvalid-rmse:0.47342\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.506 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10623, ip=100.64.35.74)\u001b[0m [12:13:41] [17]\ttrain-rmse:1.04622\tvalid-rmse:1.03648\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.494 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:13:43] [141]\ttrain-rmse:0.15815\tvalid-rmse:0.47343\n",
      "\u001b[36m(XGBoostTrainer pid=10623, ip=100.64.35.74)\u001b[0m [12:13:45] [18]\ttrain-rmse:1.04054\tvalid-rmse:1.03112\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.514 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.515 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.496 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:13:46] [142]\ttrain-rmse:0.15769\tvalid-rmse:0.47347\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.642 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.642 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.642 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.642 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:13:48] [110]\ttrain-rmse:0.37885\tvalid-rmse:0.48034\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.487 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10623, ip=100.64.35.74)\u001b[0m [12:13:49] [19]\ttrain-rmse:1.03477\tvalid-rmse:1.02561\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.505 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:13:51] [111]\ttrain-rmse:0.37777\tvalid-rmse:0.47983\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.494 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m ğŸƒ View run XGBoostTrainer_727dbcd3 at: http://ray-68b1b0be9652633ae57e1b88-ray-proxy:8765/#/experiments/257/runs/d11b84eea4de491ebb728eed1e13bb82\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m ğŸ§ª View experiment at: http://ray-68b1b0be9652633ae57e1b88-ray-proxy:8765/#/experiments/257\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial XGBoostTrainer_727dbcd3 completed after 20 iterations at 2025-08-29 12:13:53. Total running time: 10min 40s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial XGBoostTrainer_727dbcd3 result             â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ checkpoint_dir_name                              â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ time_this_iter_s                         0.00267 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ time_total_s                             5.67205 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ training_iteration                            20 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ train-rmse                               1.03477 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ valid-rmse                               1.02561 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.501 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:13:54] [112]\ttrain-rmse:0.37712\tvalid-rmse:0.47957\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.530 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.530 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.530 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.530 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:13:56] [143]\ttrain-rmse:0.15706\tvalid-rmse:0.47349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial XGBoostTrainer_e6359ef3 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial XGBoostTrainer_e6359ef3 config                          â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/alpha                             0.003828999870553427 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/colsample_bytree                    0.8237277648870049 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/eta                               0.004052464105908757 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/eval_metric                                       rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/lambda                              1.5008344227750547 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/max_depth                                            8 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/min_child_weight                     6.275166792494397 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/nthread                                              1 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/objective                             reg:squarederror â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/subsample                           0.9314695681746815 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/tree_method                                       hist â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=10904, ip=100.64.7.216)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=10904, ip=100.64.7.216)\u001b[0m - (node_id=9212372711d6417a3d6338c92f31be45ef97cdcf4ce252eb19b5435a, ip=100.64.7.216, pid=10950) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=10904, ip=100.64.7.216)\u001b[0m - (node_id=9212372711d6417a3d6338c92f31be45ef97cdcf4ce252eb19b5435a, ip=100.64.7.216, pid=10951) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=10904, ip=100.64.7.216)\u001b[0m - (node_id=9212372711d6417a3d6338c92f31be45ef97cdcf4ce252eb19b5435a, ip=100.64.7.216, pid=10952) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=10904, ip=100.64.7.216)\u001b[0m - (node_id=9212372711d6417a3d6338c92f31be45ef97cdcf4ce252eb19b5435a, ip=100.64.7.216, pid=10953) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:13:58] [113]\ttrain-rmse:0.37624\tvalid-rmse:0.47987\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.491 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.491 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.492 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial status: 3 RUNNING | 6 TERMINATED | 1 ERROR\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current time: 2025-08-29 12:13:58. Total running time: 10min 46s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Logical resource usage: 16.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current best trial: 946e81ea with valid-rmse=0.4734745119596723 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.12372102335862595, 'max_depth': 8, 'min_child_weight': 0.05312265152593065, 'subsample': 0.9848787891831414, 'colsample_bytree': 0.9496429603242498, 'lambda': 0.002729148416240024, 'alpha': 0.0016047175175163718, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_946e81ea   RUNNING        0.123721                      8                0.0531227             0.984879                 0.949643        0.00272915       0.00160472      143            5.83219       0.15769        0.473475 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_40f91dcb   RUNNING        0.158069                      5                4.35899               0.792105                 0.966918        0.800316         0.0164134       112            5.7797        0.377774       0.47983  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_e6359ef3   RUNNING        0.00405246                    8                6.27517               0.93147                  0.823728        1.50083          0.003829                                                             â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_65691eb2   TERMINATED     0.0166576                     5                0.0230802             0.885428                 0.784438        0.0153656        0.0139486        20            4.02765       0.968565       0.96315  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_42d76290   TERMINATED     0.0014152                     9                0.0178108             0.687814                 0.85763         0.0019692        0.00609112       60            3.93633       1.08652        1.07727  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_3e9fda17   TERMINATED     0.0012921                     9                0.0109805             0.867278                 0.839885        0.0905536        0.0516223        20            5.52629       1.135          1.12104  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_2941d575   TERMINATED     0.0369396                     8                0.0644973             0.751787                 0.959235        0.894337         0.928315         20            3.84855       0.729068       0.75489  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5f5ae774   TERMINATED     0.00444876                    5                1.04557               0.876413                 0.928841        2.25626          0.00873392       20            5.32517       1.09812        1.08513  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_727dbcd3   TERMINATED     0.00937608                    6                0.296585              0.630641                 0.990488        8.92507          0.066525         20            5.67205       1.03477        1.02561  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5793bdb6   ERROR          0.00836553                    9                0.0374505             0.607379                 0.828608        0.00107156       3.67376           2            5.40395       1.14408        1.12887  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=10951, ip=100.64.7.216)\u001b[0m [12:13:59] Task [xgboost.ray-rank=00000001]:2323b6b39c0f11ad9f77aa5424000000 got rank 1\n",
      "\u001b[36m(RayTrainWorker pid=10953, ip=100.64.7.216)\u001b[0m [12:13:59] Task [xgboost.ray-rank=00000003]:265652e9e1b4ae8aad6f7a7f24000000 got rank 3\n",
      "\u001b[36m(RayTrainWorker pid=10952, ip=100.64.7.216)\u001b[0m [12:13:59] Task [xgboost.ray-rank=00000002]:99fe589d9a413c84aeff99c724000000 got rank 2\n",
      "\u001b[36m(RayTrainWorker pid=10950, ip=100.64.7.216)\u001b[0m [12:13:59] Task [xgboost.ray-rank=00000000]:a59d7f53320aff13df1ca08c24000000 got rank 0\n",
      "\u001b[36m(SplitCoordinator pid=11114, ip=100.64.7.216)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-08-29_06-53-11_170260_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=11114, ip=100.64.7.216)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.491 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.491 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.491 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.491 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:14:00] [144]\ttrain-rmse:0.15655\tvalid-rmse:0.47352\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:14:01] [114]\ttrain-rmse:0.37524\tvalid-rmse:0.47942\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.495 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(autoscaler +11m6s)\u001b[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
      "\u001b[33m(autoscaler +11m6s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.508 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:14:03] [145]\ttrain-rmse:0.15543\tvalid-rmse:0.47350\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.493 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:14:04] [115]\ttrain-rmse:0.37487\tvalid-rmse:0.47915\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.495 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:14:06] [146]\ttrain-rmse:0.15472\tvalid-rmse:0.47365\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.498 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:14:07] [116]\ttrain-rmse:0.37427\tvalid-rmse:0.47908\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.522 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.523 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.523 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.523 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:14:09] [147]\ttrain-rmse:0.15402\tvalid-rmse:0.47372\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.507 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:14:10] [117]\ttrain-rmse:0.37363\tvalid-rmse:0.47899\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.472 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.473 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.473 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.473 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:14:12] [148]\ttrain-rmse:0.15294\tvalid-rmse:0.47377\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:14:13] [118]\ttrain-rmse:0.37319\tvalid-rmse:0.47888\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.500 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.496 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:14:15] [149]\ttrain-rmse:0.15229\tvalid-rmse:0.47374\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:14:16] [119]\ttrain-rmse:0.37236\tvalid-rmse:0.47850\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.572 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.573 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.573 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.573 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:14:18] [150]\ttrain-rmse:0.15171\tvalid-rmse:0.47365\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.504 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(SplitCoordinator pid=11117, ip=100.64.7.216)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-08-29_06-53-11_170260_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=11117, ip=100.64.7.216)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.511 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.512 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.512 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.512 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:14:19] [120]\ttrain-rmse:0.37203\tvalid-rmse:0.47839\n",
      "\u001b[36m(XGBoostTrainer pid=10904, ip=100.64.7.216)\u001b[0m [12:14:20] [0]\ttrain-rmse:1.15411\tvalid-rmse:1.13828\n",
      "\u001b[36m(XGBoostTrainer pid=10904, ip=100.64.7.216)\u001b[0m [12:14:20] [1]\ttrain-rmse:1.15095\tvalid-rmse:1.13531\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.501 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:14:21] [151]\ttrain-rmse:0.15120\tvalid-rmse:0.47362\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.514 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:14:22] [121]\ttrain-rmse:0.37145\tvalid-rmse:0.47814\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.498 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:14:24] [152]\ttrain-rmse:0.15073\tvalid-rmse:0.47361\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.447 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.447 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.447 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.447 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10904, ip=100.64.7.216)\u001b[0m [12:14:25] [2]\ttrain-rmse:1.14772\tvalid-rmse:1.13230\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.502 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:14:27] [153]\ttrain-rmse:0.14986\tvalid-rmse:0.47359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial status: 3 RUNNING | 6 TERMINATED | 1 ERROR\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current time: 2025-08-29 12:14:28. Total running time: 11min 16s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current best trial: 946e81ea with valid-rmse=0.47360916448536894 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.12372102335862595, 'max_depth': 8, 'min_child_weight': 0.05312265152593065, 'subsample': 0.9848787891831414, 'colsample_bytree': 0.9496429603242498, 'lambda': 0.002729148416240024, 'alpha': 0.0016047175175163718, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_946e81ea   RUNNING        0.123721                      8                0.0531227             0.984879                 0.949643        0.00272915       0.00160472      153            5.86086       0.150733       0.473609 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_40f91dcb   RUNNING        0.158069                      5                4.35899               0.792105                 0.966918        0.800316         0.0164134       121            5.80462       0.37203        0.478394 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_e6359ef3   RUNNING        0.00405246                    8                6.27517               0.93147                  0.823728        1.50083          0.003829          1           22.7649        1.15411        1.13828  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_65691eb2   TERMINATED     0.0166576                     5                0.0230802             0.885428                 0.784438        0.0153656        0.0139486        20            4.02765       0.968565       0.96315  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_42d76290   TERMINATED     0.0014152                     9                0.0178108             0.687814                 0.85763         0.0019692        0.00609112       60            3.93633       1.08652        1.07727  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_3e9fda17   TERMINATED     0.0012921                     9                0.0109805             0.867278                 0.839885        0.0905536        0.0516223        20            5.52629       1.135          1.12104  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_2941d575   TERMINATED     0.0369396                     8                0.0644973             0.751787                 0.959235        0.894337         0.928315         20            3.84855       0.729068       0.75489  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5f5ae774   TERMINATED     0.00444876                    5                1.04557               0.876413                 0.928841        2.25626          0.00873392       20            5.32517       1.09812        1.08513  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_727dbcd3   TERMINATED     0.00937608                    6                0.296585              0.630641                 0.990488        8.92507          0.066525         20            5.67205       1.03477        1.02561  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5793bdb6   ERROR          0.00836553                    9                0.0374505             0.607379                 0.828608        0.00107156       3.67376           2            5.40395       1.14408        1.12887  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.506 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:14:28] [122]\ttrain-rmse:0.37086\tvalid-rmse:0.47804\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.515 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.515 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.515 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.515 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:14:30] [154]\ttrain-rmse:0.14926\tvalid-rmse:0.47342\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.498 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10904, ip=100.64.7.216)\u001b[0m [12:14:31] [3]\ttrain-rmse:1.14443\tvalid-rmse:1.12927\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.493 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:14:33] [155]\ttrain-rmse:0.14803\tvalid-rmse:0.47340\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.494 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10904, ip=100.64.7.216)\u001b[0m [12:14:34] [4]\ttrain-rmse:1.14108\tvalid-rmse:1.12617\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:14:36] [123]\ttrain-rmse:0.36997\tvalid-rmse:0.47822\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.499 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.512 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.513 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10904, ip=100.64.7.216)\u001b[0m [12:14:37] [5]\ttrain-rmse:1.13794\tvalid-rmse:1.12325\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.489 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.489 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.489 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.489 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:14:39] [156]\ttrain-rmse:0.14758\tvalid-rmse:0.47338\n",
      "\u001b[36m(XGBoostTrainer pid=10904, ip=100.64.7.216)\u001b[0m [12:14:40] [6]\ttrain-rmse:1.13476\tvalid-rmse:1.12033\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.474 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.474 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.474 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.474 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.493 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:14:42] [157]\ttrain-rmse:0.14694\tvalid-rmse:0.47331\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.504 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:14:43] [124]\ttrain-rmse:0.36931\tvalid-rmse:0.47802\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.511 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.512 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.512 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.512 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10904, ip=100.64.7.216)\u001b[0m [12:14:45] [7]\ttrain-rmse:1.13135\tvalid-rmse:1.11715\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.501 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:14:46] [125]\ttrain-rmse:0.36863\tvalid-rmse:0.47812\n",
      "\u001b[36m(XGBoostTrainer pid=10904, ip=100.64.7.216)\u001b[0m [12:14:48] [8]\ttrain-rmse:1.12810\tvalid-rmse:1.11414\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.494 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:14:49] [126]\ttrain-rmse:0.36782\tvalid-rmse:0.47769\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.514 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.483 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.484 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.484 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.484 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:14:51] [158]\ttrain-rmse:0.14599\tvalid-rmse:0.47321\n",
      "\u001b[36m(XGBoostTrainer pid=10904, ip=100.64.7.216)\u001b[0m [12:14:52] [9]\ttrain-rmse:1.12471\tvalid-rmse:1.11096\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.492 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.494 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:14:54] [159]\ttrain-rmse:0.14505\tvalid-rmse:0.47324\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.484 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.485 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.485 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.485 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10904, ip=100.64.7.216)\u001b[0m [12:14:55] [10]\ttrain-rmse:1.12154\tvalid-rmse:1.10802\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.489 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.489 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.489 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.489 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:14:57] [160]\ttrain-rmse:0.14393\tvalid-rmse:0.47340\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.498 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10904, ip=100.64.7.216)\u001b[0m [12:14:58] [11]\ttrain-rmse:1.11840\tvalid-rmse:1.10513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial status: 3 RUNNING | 6 TERMINATED | 1 ERROR\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current time: 2025-08-29 12:15:00. Total running time: 11min 48s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current best trial: 946e81ea with valid-rmse=0.47340215003918534 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.12372102335862595, 'max_depth': 8, 'min_child_weight': 0.05312265152593065, 'subsample': 0.9848787891831414, 'colsample_bytree': 0.9496429603242498, 'lambda': 0.002729148416240024, 'alpha': 0.0016047175175163718, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_946e81ea   RUNNING        0.123721                      8                0.0531227             0.984879                 0.949643        0.00272915       0.00160472      161            5.88302       0.143928       0.473402 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_40f91dcb   RUNNING        0.158069                      5                4.35899               0.792105                 0.966918        0.800316         0.0164134       125            5.81544       0.369312       0.478017 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_e6359ef3   RUNNING        0.00405246                    8                6.27517               0.93147                  0.823728        1.50083          0.003829         10           22.791         1.12471        1.11096  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_65691eb2   TERMINATED     0.0166576                     5                0.0230802             0.885428                 0.784438        0.0153656        0.0139486        20            4.02765       0.968565       0.96315  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_42d76290   TERMINATED     0.0014152                     9                0.0178108             0.687814                 0.85763         0.0019692        0.00609112       60            3.93633       1.08652        1.07727  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_3e9fda17   TERMINATED     0.0012921                     9                0.0109805             0.867278                 0.839885        0.0905536        0.0516223        20            5.52629       1.135          1.12104  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_2941d575   TERMINATED     0.0369396                     8                0.0644973             0.751787                 0.959235        0.894337         0.928315         20            3.84855       0.729068       0.75489  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5f5ae774   TERMINATED     0.00444876                    5                1.04557               0.876413                 0.928841        2.25626          0.00873392       20            5.32517       1.09812        1.08513  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_727dbcd3   TERMINATED     0.00937608                    6                0.296585              0.630641                 0.990488        8.92507          0.066525         20            5.67205       1.03477        1.02561  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5793bdb6   ERROR          0.00836553                    9                0.0374505             0.607379                 0.828608        0.00107156       3.67376           2            5.40395       1.14408        1.12887  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.625 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.625 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.625 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.625 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:15:00] [161]\ttrain-rmse:0.14346\tvalid-rmse:0.47347\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:15:02] [127]\ttrain-rmse:0.36706\tvalid-rmse:0.47742\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.483 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.483 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.483 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.483 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10904, ip=100.64.7.216)\u001b[0m [12:15:03] [12]\ttrain-rmse:1.11547\tvalid-rmse:1.10248\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.504 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.502 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:15:05] [128]\ttrain-rmse:0.36679\tvalid-rmse:0.47749\n",
      "\u001b[36m(XGBoostTrainer pid=10904, ip=100.64.7.216)\u001b[0m [12:15:06] [13]\ttrain-rmse:1.11233\tvalid-rmse:1.09955\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.511 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.511 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.487 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:15:08] [162]\ttrain-rmse:0.14290\tvalid-rmse:0.47352\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.505 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:15:09] [129]\ttrain-rmse:0.36615\tvalid-rmse:0.47722\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.472 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.472 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.472 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.472 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10904, ip=100.64.7.216)\u001b[0m [12:15:11] [14]\ttrain-rmse:1.10925\tvalid-rmse:1.09666\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:15:12] [163]\ttrain-rmse:0.14192\tvalid-rmse:0.47334\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.521 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.521 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.521 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.521 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:15:14] [130]\ttrain-rmse:0.36565\tvalid-rmse:0.47719\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.495 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:15:15] [164]\ttrain-rmse:0.14110\tvalid-rmse:0.47331\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.498 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:15:17] [131]\ttrain-rmse:0.36516\tvalid-rmse:0.47713\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.523 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.523 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.523 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.523 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.508 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10904, ip=100.64.7.216)\u001b[0m [12:15:18] [15]\ttrain-rmse:1.10597\tvalid-rmse:1.09355\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:15:20] [132]\ttrain-rmse:0.36470\tvalid-rmse:0.47745\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.491 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.492 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.505 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10904, ip=100.64.7.216)\u001b[0m [12:15:21] [16]\ttrain-rmse:1.10269\tvalid-rmse:1.09048\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:15:23] [165]\ttrain-rmse:0.14055\tvalid-rmse:0.47339\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.505 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.497 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10904, ip=100.64.7.216)\u001b[0m [12:15:24] [17]\ttrain-rmse:1.10026\tvalid-rmse:1.08823\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.515 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.515 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.515 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:15:26] [166]\ttrain-rmse:0.14000\tvalid-rmse:0.47333\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:15:27] [133]\ttrain-rmse:0.36396\tvalid-rmse:0.47714\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.496 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.498 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10904, ip=100.64.7.216)\u001b[0m [12:15:29] [18]\ttrain-rmse:1.09723\tvalid-rmse:1.08542\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:15:30] [134]\ttrain-rmse:0.36360\tvalid-rmse:0.47694\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.492 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial status: 3 RUNNING | 6 TERMINATED | 1 ERROR\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current time: 2025-08-29 12:15:30. Total running time: 12min 18s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current best trial: 946e81ea with valid-rmse=0.4733924144539459 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.12372102335862595, 'max_depth': 8, 'min_child_weight': 0.05312265152593065, 'subsample': 0.9848787891831414, 'colsample_bytree': 0.9496429603242498, 'lambda': 0.002729148416240024, 'alpha': 0.0016047175175163718, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_946e81ea   RUNNING        0.123721                      8                0.0531227             0.984879                 0.949643        0.00272915       0.00160472      166            5.89705       0.140549       0.473392 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_40f91dcb   RUNNING        0.158069                      5                4.35899               0.792105                 0.966918        0.800316         0.0164134       133            5.83794       0.364698       0.47745  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_e6359ef3   RUNNING        0.00405246                    8                6.27517               0.93147                  0.823728        1.50083          0.003829         17           22.8117        1.10269        1.09048  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_65691eb2   TERMINATED     0.0166576                     5                0.0230802             0.885428                 0.784438        0.0153656        0.0139486        20            4.02765       0.968565       0.96315  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_42d76290   TERMINATED     0.0014152                     9                0.0178108             0.687814                 0.85763         0.0019692        0.00609112       60            3.93633       1.08652        1.07727  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_3e9fda17   TERMINATED     0.0012921                     9                0.0109805             0.867278                 0.839885        0.0905536        0.0516223        20            5.52629       1.135          1.12104  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_2941d575   TERMINATED     0.0369396                     8                0.0644973             0.751787                 0.959235        0.894337         0.928315         20            3.84855       0.729068       0.75489  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5f5ae774   TERMINATED     0.00444876                    5                1.04557               0.876413                 0.928841        2.25626          0.00873392       20            5.32517       1.09812        1.08513  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_727dbcd3   TERMINATED     0.00937608                    6                0.296585              0.630641                 0.990488        8.92507          0.066525         20            5.67205       1.03477        1.02561  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5793bdb6   ERROR          0.00836553                    9                0.0374505             0.607379                 0.828608        0.00107156       3.67376           2            5.40395       1.14408        1.12887  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.489 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.489 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.489 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.489 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:15:32] [167]\ttrain-rmse:0.13889\tvalid-rmse:0.47306\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.514 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10904, ip=100.64.7.216)\u001b[0m [12:15:33] [19]\ttrain-rmse:1.09407\tvalid-rmse:1.08250\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.491 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.491 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.491 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:15:35] [168]\ttrain-rmse:0.13833\tvalid-rmse:0.47302\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.503 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:15:36] [135]\ttrain-rmse:0.36321\tvalid-rmse:0.47692\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:15:38] [169]\ttrain-rmse:0.13808\tvalid-rmse:0.47296\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.512 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.512 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.512 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.512 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.514 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:15:39] [136]\ttrain-rmse:0.36243\tvalid-rmse:0.47680\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:15:41] [170]\ttrain-rmse:0.13764\tvalid-rmse:0.47295\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.498 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:15:42] [137]\ttrain-rmse:0.36177\tvalid-rmse:0.47638\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.504 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:15:44] [171]\ttrain-rmse:0.13690\tvalid-rmse:0.47295\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.504 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=10904, ip=100.64.7.216)\u001b[0m [12:15:45] [20]\ttrain-rmse:1.09102\tvalid-rmse:1.07970\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.517 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.517 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.517 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.518 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.494 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:15:47] [172]\ttrain-rmse:0.13652\tvalid-rmse:0.47310\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.519 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.520 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.520 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.520 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m ğŸƒ View run XGBoostTrainer_e6359ef3 at: http://ray-68b1b0be9652633ae57e1b88-ray-proxy:8765/#/experiments/257/runs/4337af610c39482fb594916cd6e77d2a\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m ğŸ§ª View experiment at: http://ray-68b1b0be9652633ae57e1b88-ray-proxy:8765/#/experiments/257\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial XGBoostTrainer_e6359ef3 completed after 20 iterations at 2025-08-29 12:15:49. Total running time: 12min 36s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial XGBoostTrainer_e6359ef3 result             â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ checkpoint_dir_name                              â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ time_this_iter_s                         0.00284 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ time_total_s                             22.8202 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ training_iteration                            20 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ train-rmse                               1.09407 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ valid-rmse                                1.0825 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.505 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:15:50] [173]\ttrain-rmse:0.13580\tvalid-rmse:0.47303\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.507 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:15:52] [138]\ttrain-rmse:0.36110\tvalid-rmse:0.47618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial XGBoostTrainer_d5c4cf09 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial XGBoostTrainer_d5c4cf09 config                           â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/alpha                                 1.111825021654889 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/colsample_bytree                     0.6672977060053037 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/eta                               0.0019134347640482022 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/eval_metric                                        rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/lambda                             0.001209042145945814 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/max_depth                                             5 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/min_child_weight                   0.026165753937880676 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/nthread                                               1 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/objective                              reg:squarederror â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/subsample                            0.9208978735198781 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/tree_method                                        hist â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=11172, ip=100.64.35.74)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=11172, ip=100.64.35.74)\u001b[0m - (node_id=1241d9436b2265d61f4f92a4765fc79e6ca8d250507ff92e1ea3419e, ip=100.64.35.74, pid=11218) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=11172, ip=100.64.35.74)\u001b[0m - (node_id=1241d9436b2265d61f4f92a4765fc79e6ca8d250507ff92e1ea3419e, ip=100.64.35.74, pid=11219) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=11172, ip=100.64.35.74)\u001b[0m - (node_id=1241d9436b2265d61f4f92a4765fc79e6ca8d250507ff92e1ea3419e, ip=100.64.35.74, pid=11220) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=11172, ip=100.64.35.74)\u001b[0m - (node_id=1241d9436b2265d61f4f92a4765fc79e6ca8d250507ff92e1ea3419e, ip=100.64.35.74, pid=11221) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.518 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.519 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.519 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.519 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:15:54] [139]\ttrain-rmse:0.36048\tvalid-rmse:0.47598\n",
      "\u001b[36m(RayTrainWorker pid=11219, ip=100.64.35.74)\u001b[0m [12:15:55] Task [xgboost.ray-rank=00000001]:62bf838cdf0fab4d81660c0124000000 got rank 1\n",
      "\u001b[36m(RayTrainWorker pid=11218, ip=100.64.35.74)\u001b[0m [12:15:55] Task [xgboost.ray-rank=00000000]:6a3c69ba11047b171ba261d024000000 got rank 0\n",
      "\u001b[36m(RayTrainWorker pid=11221, ip=100.64.35.74)\u001b[0m [12:15:55] Task [xgboost.ray-rank=00000003]:ce580e6dbb5844bda698ceeb24000000 got rank 3\n",
      "\u001b[36m(RayTrainWorker pid=11220, ip=100.64.35.74)\u001b[0m [12:15:55] Task [xgboost.ray-rank=00000002]:714bbbffca2ce1fe8f639fc024000000 got rank 2\n",
      "\u001b[36m(SplitCoordinator pid=11384, ip=100.64.35.74)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-08-29_06-53-11_170260_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=11384, ip=100.64.35.74)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:15:56] [174]\ttrain-rmse:0.13503\tvalid-rmse:0.47301\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.497 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.504 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:15:57] [140]\ttrain-rmse:0.35970\tvalid-rmse:0.47580\n",
      "\u001b[36m(SplitCoordinator pid=11385, ip=100.64.35.74)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-08-29_06-53-11_170260_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=11385, ip=100.64.35.74)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=11172, ip=100.64.35.74)\u001b[0m [12:15:58] [0]\ttrain-rmse:1.15607\tvalid-rmse:1.14008\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.496 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:15:59] [175]\ttrain-rmse:0.13448\tvalid-rmse:0.47310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial status: 3 RUNNING | 7 TERMINATED | 1 ERROR\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current time: 2025-08-29 12:16:00. Total running time: 12min 48s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current best trial: 946e81ea with valid-rmse=0.4730142124486723 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.12372102335862595, 'max_depth': 8, 'min_child_weight': 0.05312265152593065, 'subsample': 0.9848787891831414, 'colsample_bytree': 0.9496429603242498, 'lambda': 0.002729148416240024, 'alpha': 0.0016047175175163718, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_946e81ea   RUNNING        0.123721                      8                0.0531227             0.984879                 0.949643        0.00272915       0.00160472      175            5.92198       0.135031       0.473014 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_40f91dcb   RUNNING        0.158069                      5                4.35899               0.792105                 0.966918        0.800316         0.0164134       140            5.85778       0.360485       0.475983 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_d5c4cf09   RUNNING        0.00191343                    5                0.0261658             0.920898                 0.667298        0.00120904       1.11183                                                              â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_65691eb2   TERMINATED     0.0166576                     5                0.0230802             0.885428                 0.784438        0.0153656        0.0139486        20            4.02765       0.968565       0.96315  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_42d76290   TERMINATED     0.0014152                     9                0.0178108             0.687814                 0.85763         0.0019692        0.00609112       60            3.93633       1.08652        1.07727  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_3e9fda17   TERMINATED     0.0012921                     9                0.0109805             0.867278                 0.839885        0.0905536        0.0516223        20            5.52629       1.135          1.12104  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_2941d575   TERMINATED     0.0369396                     8                0.0644973             0.751787                 0.959235        0.894337         0.928315         20            3.84855       0.729068       0.75489  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5f5ae774   TERMINATED     0.00444876                    5                1.04557               0.876413                 0.928841        2.25626          0.00873392       20            5.32517       1.09812        1.08513  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_727dbcd3   TERMINATED     0.00937608                    6                0.296585              0.630641                 0.990488        8.92507          0.066525         20            5.67205       1.03477        1.02561  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_e6359ef3   TERMINATED     0.00405246                    8                6.27517               0.93147                  0.823728        1.50083          0.003829         20           22.8202        1.09407        1.0825   â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5793bdb6   ERROR          0.00836553                    9                0.0374505             0.607379                 0.828608        0.00107156       3.67376           2            5.40395       1.14408        1.12887  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.487 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:16:00] [141]\ttrain-rmse:0.35897\tvalid-rmse:0.47605\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.457 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.457 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.457 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.457 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11172, ip=100.64.35.74)\u001b[0m [12:16:02] [1]\ttrain-rmse:1.15524\tvalid-rmse:1.13930\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:16:03] [142]\ttrain-rmse:0.35830\tvalid-rmse:0.47571\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.502 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.491 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.491 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.491 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.491 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:16:05] [143]\ttrain-rmse:0.35811\tvalid-rmse:0.47555\n",
      "\u001b[36m(XGBoostTrainer pid=11172, ip=100.64.35.74)\u001b[0m [12:16:06] [2]\ttrain-rmse:1.15434\tvalid-rmse:1.13845\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.499 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:16:08] [144]\ttrain-rmse:0.35757\tvalid-rmse:0.47537\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.511 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.511 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.511 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.511 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.486 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:16:09] [176]\ttrain-rmse:0.13374\tvalid-rmse:0.47304\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.672 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.673 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.673 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.673 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:16:11] [145]\ttrain-rmse:0.35683\tvalid-rmse:0.47551\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.503 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:16:12] [177]\ttrain-rmse:0.13326\tvalid-rmse:0.47303\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:16:14] [146]\ttrain-rmse:0.35654\tvalid-rmse:0.47573\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.514 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.515 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.516 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.516 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.516 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:16:15] [178]\ttrain-rmse:0.13253\tvalid-rmse:0.47293\n",
      "\u001b[36m(XGBoostTrainer pid=11172, ip=100.64.35.74)\u001b[0m [12:16:17] [3]\ttrain-rmse:1.15340\tvalid-rmse:1.13755\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.501 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:16:18] [179]\ttrain-rmse:0.13210\tvalid-rmse:0.47295\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.504 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.518 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.518 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.518 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.518 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11172, ip=100.64.35.74)\u001b[0m [12:16:20] [4]\ttrain-rmse:1.15200\tvalid-rmse:1.13620\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:16:22] [180]\ttrain-rmse:0.13150\tvalid-rmse:0.47287\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.516 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.516 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.516 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.516 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11172, ip=100.64.35.74)\u001b[0m [12:16:23] [5]\ttrain-rmse:1.15120\tvalid-rmse:1.13543\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.507 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.490 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:16:25] [181]\ttrain-rmse:0.13088\tvalid-rmse:0.47286\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.493 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:16:26] [147]\ttrain-rmse:0.35602\tvalid-rmse:0.47546\n",
      "\u001b[36m(XGBoostTrainer pid=11172, ip=100.64.35.74)\u001b[0m [12:16:28] [6]\ttrain-rmse:1.14984\tvalid-rmse:1.13417\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.487 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.488 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:16:29] [148]\ttrain-rmse:0.35547\tvalid-rmse:0.47564\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:16:30] [182]\ttrain-rmse:0.13055\tvalid-rmse:0.47281\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.474 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.475 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.475 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.475 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial status: 3 RUNNING | 7 TERMINATED | 1 ERROR\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current time: 2025-08-29 12:16:30. Total running time: 13min 18s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current best trial: 946e81ea with valid-rmse=0.47286292912064354 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.12372102335862595, 'max_depth': 8, 'min_child_weight': 0.05312265152593065, 'subsample': 0.9848787891831414, 'colsample_bytree': 0.9496429603242498, 'lambda': 0.002729148416240024, 'alpha': 0.0016047175175163718, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_946e81ea   RUNNING        0.123721                      8                0.0531227             0.984879                 0.949643        0.00272915       0.00160472      182            5.94161       0.130881       0.472863 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_40f91dcb   RUNNING        0.158069                      5                4.35899               0.792105                 0.966918        0.800316         0.0164134       147            5.87723       0.35654        0.475732 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_d5c4cf09   RUNNING        0.00191343                    5                0.0261658             0.920898                 0.667298        0.00120904       1.11183           6            5.67513       1.1512         1.13543  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_65691eb2   TERMINATED     0.0166576                     5                0.0230802             0.885428                 0.784438        0.0153656        0.0139486        20            4.02765       0.968565       0.96315  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_42d76290   TERMINATED     0.0014152                     9                0.0178108             0.687814                 0.85763         0.0019692        0.00609112       60            3.93633       1.08652        1.07727  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_3e9fda17   TERMINATED     0.0012921                     9                0.0109805             0.867278                 0.839885        0.0905536        0.0516223        20            5.52629       1.135          1.12104  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_2941d575   TERMINATED     0.0369396                     8                0.0644973             0.751787                 0.959235        0.894337         0.928315         20            3.84855       0.729068       0.75489  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5f5ae774   TERMINATED     0.00444876                    5                1.04557               0.876413                 0.928841        2.25626          0.00873392       20            5.32517       1.09812        1.08513  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_727dbcd3   TERMINATED     0.00937608                    6                0.296585              0.630641                 0.990488        8.92507          0.066525         20            5.67205       1.03477        1.02561  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_e6359ef3   TERMINATED     0.00405246                    8                6.27517               0.93147                  0.823728        1.50083          0.003829         20           22.8202        1.09407        1.0825   â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5793bdb6   ERROR          0.00836553                    9                0.0374505             0.607379                 0.828608        0.00107156       3.67376           2            5.40395       1.14408        1.12887  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.496 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11172, ip=100.64.35.74)\u001b[0m [12:16:32] [7]\ttrain-rmse:1.14904\tvalid-rmse:1.13340\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:16:33] [183]\ttrain-rmse:0.12996\tvalid-rmse:0.47290\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.481 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.481 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.481 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.481 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.486 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:16:35] [149]\ttrain-rmse:0.35492\tvalid-rmse:0.47526\n",
      "\u001b[36m(XGBoostTrainer pid=11172, ip=100.64.35.74)\u001b[0m [12:16:36] [8]\ttrain-rmse:1.14772\tvalid-rmse:1.13216\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.511 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.511 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.511 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.511 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.498 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:16:38] [150]\ttrain-rmse:0.35444\tvalid-rmse:0.47506\n",
      "\u001b[36m(XGBoostTrainer pid=11172, ip=100.64.35.74)\u001b[0m [12:16:39] [9]\ttrain-rmse:1.14691\tvalid-rmse:1.13138\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.466 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.466 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.466 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.466 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:16:41] [151]\ttrain-rmse:0.35376\tvalid-rmse:0.47512\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.467 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.467 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.467 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.467 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11172, ip=100.64.35.74)\u001b[0m [12:16:42] [10]\ttrain-rmse:1.14556\tvalid-rmse:1.13013\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.505 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:16:44] [184]\ttrain-rmse:0.12966\tvalid-rmse:0.47292\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.497 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.490 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11172, ip=100.64.35.74)\u001b[0m [12:16:45] [11]\ttrain-rmse:1.14424\tvalid-rmse:1.12888\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:16:47] [185]\ttrain-rmse:0.12895\tvalid-rmse:0.47290\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.477 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.477 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.477 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.478 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.490 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:16:48] [152]\ttrain-rmse:0.35327\tvalid-rmse:0.47473\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:16:50] [186]\ttrain-rmse:0.12830\tvalid-rmse:0.47289\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.508 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11172, ip=100.64.35.74)\u001b[0m [12:16:51] [12]\ttrain-rmse:1.14300\tvalid-rmse:1.12775\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.518 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.518 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.518 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.518 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.495 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:16:53] [153]\ttrain-rmse:0.35262\tvalid-rmse:0.47460\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:16:54] [187]\ttrain-rmse:0.12789\tvalid-rmse:0.47287\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.500 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.496 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:16:56] [154]\ttrain-rmse:0.35185\tvalid-rmse:0.47467\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.483 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.484 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.484 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.484 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:16:57] [188]\ttrain-rmse:0.12722\tvalid-rmse:0.47281\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.510 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11172, ip=100.64.35.74)\u001b[0m [12:16:59] [13]\ttrain-rmse:1.14164\tvalid-rmse:1.12646\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.498 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:17:00] [189]\ttrain-rmse:0.12637\tvalid-rmse:0.47279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial status: 3 RUNNING | 7 TERMINATED | 1 ERROR\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current time: 2025-08-29 12:17:02. Total running time: 13min 50s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current best trial: 946e81ea with valid-rmse=0.4728098737408551 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.12372102335862595, 'max_depth': 8, 'min_child_weight': 0.05312265152593065, 'subsample': 0.9848787891831414, 'colsample_bytree': 0.9496429603242498, 'lambda': 0.002729148416240024, 'alpha': 0.0016047175175163718, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_946e81ea   RUNNING        0.123721                      8                0.0531227             0.984879                 0.949643        0.00272915       0.00160472      189            5.96143       0.127219       0.47281  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_40f91dcb   RUNNING        0.158069                      5                4.35899               0.792105                 0.966918        0.800316         0.0164134       153            5.89413       0.35327        0.474732 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_d5c4cf09   RUNNING        0.00191343                    5                0.0261658             0.920898                 0.667298        0.00120904       1.11183          14            5.69759       1.14164        1.12646  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_65691eb2   TERMINATED     0.0166576                     5                0.0230802             0.885428                 0.784438        0.0153656        0.0139486        20            4.02765       0.968565       0.96315  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_42d76290   TERMINATED     0.0014152                     9                0.0178108             0.687814                 0.85763         0.0019692        0.00609112       60            3.93633       1.08652        1.07727  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_3e9fda17   TERMINATED     0.0012921                     9                0.0109805             0.867278                 0.839885        0.0905536        0.0516223        20            5.52629       1.135          1.12104  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_2941d575   TERMINATED     0.0369396                     8                0.0644973             0.751787                 0.959235        0.894337         0.928315         20            3.84855       0.729068       0.75489  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5f5ae774   TERMINATED     0.00444876                    5                1.04557               0.876413                 0.928841        2.25626          0.00873392       20            5.32517       1.09812        1.08513  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_727dbcd3   TERMINATED     0.00937608                    6                0.296585              0.630641                 0.990488        8.92507          0.066525         20            5.67205       1.03477        1.02561  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_e6359ef3   TERMINATED     0.00405246                    8                6.27517               0.93147                  0.823728        1.50083          0.003829         20           22.8202        1.09407        1.0825   â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5793bdb6   ERROR          0.00836553                    9                0.0374505             0.607379                 0.828608        0.00107156       3.67376           2            5.40395       1.14408        1.12887  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.492 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11172, ip=100.64.35.74)\u001b[0m [12:17:02] [14]\ttrain-rmse:1.14070\tvalid-rmse:1.12554\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:17:03] [155]\ttrain-rmse:0.35125\tvalid-rmse:0.47452\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.511 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.511 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.511 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.511 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.476 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.477 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.477 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.477 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11172, ip=100.64.35.74)\u001b[0m [12:17:05] [15]\ttrain-rmse:1.13940\tvalid-rmse:1.12432\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.488 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:17:06] [190]\ttrain-rmse:0.12591\tvalid-rmse:0.47283\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:17:08] [191]\ttrain-rmse:0.12533\tvalid-rmse:0.47282\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.503 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.506 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:17:09] [156]\ttrain-rmse:0.35065\tvalid-rmse:0.47464\n",
      "\u001b[36m(XGBoostTrainer pid=11172, ip=100.64.35.74)\u001b[0m [12:17:11] [16]\ttrain-rmse:1.13806\tvalid-rmse:1.12303\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.507 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.511 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.511 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.511 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.511 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:17:12] [157]\ttrain-rmse:0.35009\tvalid-rmse:0.47456\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.493 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11172, ip=100.64.35.74)\u001b[0m [12:17:14] [17]\ttrain-rmse:1.13724\tvalid-rmse:1.12225\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.492 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:17:15] [192]\ttrain-rmse:0.12485\tvalid-rmse:0.47281\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.503 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:17:17] [158]\ttrain-rmse:0.34915\tvalid-rmse:0.47389\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:17:18] [193]\ttrain-rmse:0.12437\tvalid-rmse:0.47278\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.503 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.499 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11172, ip=100.64.35.74)\u001b[0m [12:17:20] [18]\ttrain-rmse:1.13643\tvalid-rmse:1.12150\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.622 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.622 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.623 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.623 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:17:22] [159]\ttrain-rmse:0.34858\tvalid-rmse:0.47380\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:17:23] [194]\ttrain-rmse:0.12359\tvalid-rmse:0.47278\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.526 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.527 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.527 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.527 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.485 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.486 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:17:25] [160]\ttrain-rmse:0.34787\tvalid-rmse:0.47327\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:17:26] [195]\ttrain-rmse:0.12298\tvalid-rmse:0.47277\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.495 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11172, ip=100.64.35.74)\u001b[0m [12:17:28] [19]\ttrain-rmse:1.13514\tvalid-rmse:1.12027\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.540 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.541 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.541 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.541 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.504 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m ğŸƒ View run XGBoostTrainer_d5c4cf09 at: http://ray-68b1b0be9652633ae57e1b88-ray-proxy:8765/#/experiments/257/runs/5af065b993924ba6bc49cd5bf8880dc0\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m ğŸ§ª View experiment at: http://ray-68b1b0be9652633ae57e1b88-ray-proxy:8765/#/experiments/257\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial XGBoostTrainer_d5c4cf09 completed after 20 iterations at 2025-08-29 12:17:29. Total running time: 14min 17s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial XGBoostTrainer_d5c4cf09 result             â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ checkpoint_dir_name                              â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ time_this_iter_s                         0.00296 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ time_total_s                             5.71485 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ training_iteration                            20 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ train-rmse                               1.13514 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ valid-rmse                               1.12027 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.506 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:17:31] [196]\ttrain-rmse:0.12249\tvalid-rmse:0.47262\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:17:33] [161]\ttrain-rmse:0.34732\tvalid-rmse:0.47318\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.526 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.526 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.526 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.526 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial status: 2 RUNNING | 8 TERMINATED | 1 ERROR | 1 PENDING\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current time: 2025-08-29 12:17:33. Total running time: 14min 20s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current best trial: 946e81ea with valid-rmse=0.4727726218541214 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.12372102335862595, 'max_depth': 8, 'min_child_weight': 0.05312265152593065, 'subsample': 0.9848787891831414, 'colsample_bytree': 0.9496429603242498, 'lambda': 0.002729148416240024, 'alpha': 0.0016047175175163718, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_946e81ea   RUNNING        0.123721                      8                0.0531227             0.984879                 0.949643        0.00272915       0.00160472      196            5.98072       0.122975       0.472773 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_40f91dcb   RUNNING        0.158069                      5                4.35899               0.792105                 0.966918        0.800316         0.0164134       160            5.91434       0.348578       0.473805 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_65691eb2   TERMINATED     0.0166576                     5                0.0230802             0.885428                 0.784438        0.0153656        0.0139486        20            4.02765       0.968565       0.96315  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_42d76290   TERMINATED     0.0014152                     9                0.0178108             0.687814                 0.85763         0.0019692        0.00609112       60            3.93633       1.08652        1.07727  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_3e9fda17   TERMINATED     0.0012921                     9                0.0109805             0.867278                 0.839885        0.0905536        0.0516223        20            5.52629       1.135          1.12104  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_2941d575   TERMINATED     0.0369396                     8                0.0644973             0.751787                 0.959235        0.894337         0.928315         20            3.84855       0.729068       0.75489  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5f5ae774   TERMINATED     0.00444876                    5                1.04557               0.876413                 0.928841        2.25626          0.00873392       20            5.32517       1.09812        1.08513  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_727dbcd3   TERMINATED     0.00937608                    6                0.296585              0.630641                 0.990488        8.92507          0.066525         20            5.67205       1.03477        1.02561  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_e6359ef3   TERMINATED     0.00405246                    8                6.27517               0.93147                  0.823728        1.50083          0.003829         20           22.8202        1.09407        1.0825   â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_d5c4cf09   TERMINATED     0.00191343                    5                0.0261658             0.920898                 0.667298        0.00120904       1.11183          20            5.71485       1.13514        1.12027  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_c9063ba9   PENDING        0.0118361                     5                0.20819               0.665244                 0.644851        0.660378         1.44566                                                              â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5793bdb6   ERROR          0.00836553                    9                0.0374505             0.607379                 0.828608        0.00107156       3.67376           2            5.40395       1.14408        1.12887  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial XGBoostTrainer_c9063ba9 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial XGBoostTrainer_c9063ba9 config                          â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/alpha                               1.4456597297434044 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/colsample_bytree                    0.6448506704517948 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/eta                               0.011836089874192421 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/eval_metric                                       rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/lambda                               0.660377979781826 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/max_depth                                            5 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/min_child_weight                   0.20818968023896578 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/nthread                                              1 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/objective                             reg:squarederror â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/subsample                           0.6652437368839684 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/tree_method                                       hist â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=11455, ip=100.64.7.216)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=11455, ip=100.64.7.216)\u001b[0m - (node_id=9212372711d6417a3d6338c92f31be45ef97cdcf4ce252eb19b5435a, ip=100.64.7.216, pid=11501) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=11455, ip=100.64.7.216)\u001b[0m - (node_id=9212372711d6417a3d6338c92f31be45ef97cdcf4ce252eb19b5435a, ip=100.64.7.216, pid=11502) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=11455, ip=100.64.7.216)\u001b[0m - (node_id=9212372711d6417a3d6338c92f31be45ef97cdcf4ce252eb19b5435a, ip=100.64.7.216, pid=11503) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=11455, ip=100.64.7.216)\u001b[0m - (node_id=9212372711d6417a3d6338c92f31be45ef97cdcf4ce252eb19b5435a, ip=100.64.7.216, pid=11504) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:17:35] [162]\ttrain-rmse:0.34668\tvalid-rmse:0.47308\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.516 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.517 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.517 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.517 s, which may be a performance bottleneck.\n",
      "\u001b[36m(RayTrainWorker pid=11501, ip=100.64.7.216)\u001b[0m [12:17:36] Task [xgboost.ray-rank=00000000]:93ff85096d9d7862a446e2e424000000 got rank 0\n",
      "\u001b[36m(RayTrainWorker pid=11504, ip=100.64.7.216)\u001b[0m [12:17:36] Task [xgboost.ray-rank=00000003]:f5c0b19fbb76ab2433eec45824000000 got rank 3\n",
      "\u001b[36m(RayTrainWorker pid=11503, ip=100.64.7.216)\u001b[0m [12:17:36] Task [xgboost.ray-rank=00000002]:d3dd2686bb4ca281fd182c3024000000 got rank 2\n",
      "\u001b[36m(RayTrainWorker pid=11502, ip=100.64.7.216)\u001b[0m [12:17:36] Task [xgboost.ray-rank=00000001]:9a80cd649db5dc576e60585a24000000 got rank 1\n",
      "\u001b[36m(SplitCoordinator pid=11665, ip=100.64.7.216)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-08-29_06-53-11_170260_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=11665, ip=100.64.7.216)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.490 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:17:37] [197]\ttrain-rmse:0.12184\tvalid-rmse:0.47260\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:17:38] [163]\ttrain-rmse:0.34605\tvalid-rmse:0.47279\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.499 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(SplitCoordinator pid=11668, ip=100.64.7.216)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-08-29_06-53-11_170260_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=11668, ip=100.64.7.216)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=11455, ip=100.64.7.216)\u001b[0m [12:17:39] [0]\ttrain-rmse:1.14889\tvalid-rmse:1.13323\n",
      "\u001b[36m(XGBoostTrainer pid=11455, ip=100.64.7.216)\u001b[0m [12:17:39] [1]\ttrain-rmse:1.14370\tvalid-rmse:1.12819\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:17:40] [198]\ttrain-rmse:0.12124\tvalid-rmse:0.47260\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.498 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.495 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11455, ip=100.64.7.216)\u001b[0m [12:17:41] [2]\ttrain-rmse:1.13824\tvalid-rmse:1.12296\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:17:43] [199]\ttrain-rmse:0.12058\tvalid-rmse:0.47242\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.507 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.517 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.517 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.517 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.517 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11455, ip=100.64.7.216)\u001b[0m [12:17:44] [3]\ttrain-rmse:1.13259\tvalid-rmse:1.11747\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:17:46] [200]\ttrain-rmse:0.12012\tvalid-rmse:0.47261\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.503 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11455, ip=100.64.7.216)\u001b[0m [12:17:47] [4]\ttrain-rmse:1.12431\tvalid-rmse:1.10952\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.497 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:17:49] [201]\ttrain-rmse:0.11964\tvalid-rmse:0.47268\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.508 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.515 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.515 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.515 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.515 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11455, ip=100.64.7.216)\u001b[0m [12:17:50] [5]\ttrain-rmse:1.11944\tvalid-rmse:1.10483\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:17:52] [164]\ttrain-rmse:0.34552\tvalid-rmse:0.47298\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.500 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:17:53] [202]\ttrain-rmse:0.11941\tvalid-rmse:0.47266\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.496 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.496 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:17:55] [165]\ttrain-rmse:0.34481\tvalid-rmse:0.47281\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:17:56] [203]\ttrain-rmse:0.11875\tvalid-rmse:0.47265\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.519 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.519 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.519 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.519 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11455, ip=100.64.7.216)\u001b[0m [12:17:58] [6]\ttrain-rmse:1.11156\tvalid-rmse:1.09744\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.514 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.505 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:17:59] [166]\ttrain-rmse:0.34447\tvalid-rmse:0.47281\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.496 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11455, ip=100.64.7.216)\u001b[0m [12:18:01] [7]\ttrain-rmse:1.10724\tvalid-rmse:1.09315\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.503 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:18:02] [204]\ttrain-rmse:0.11794\tvalid-rmse:0.47248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial status: 3 RUNNING | 8 TERMINATED | 1 ERROR\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current time: 2025-08-29 12:18:04. Total running time: 14min 52s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current best trial: 946e81ea with valid-rmse=0.472647856680739 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.12372102335862595, 'max_depth': 8, 'min_child_weight': 0.05312265152593065, 'subsample': 0.9848787891831414, 'colsample_bytree': 0.9496429603242498, 'lambda': 0.002729148416240024, 'alpha': 0.0016047175175163718, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_946e81ea   RUNNING        0.123721                      8                0.0531227             0.984879                 0.949643        0.00272915       0.00160472      204            6.00256       0.11875        0.472648 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_40f91dcb   RUNNING        0.158069                      5                4.35899               0.792105                 0.966918        0.800316         0.0164134       165            5.92818       0.345518       0.472975 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_c9063ba9   RUNNING        0.0118361                     5                0.20819               0.665244                 0.644851        0.660378         1.44566           7            5.35892       1.11156        1.09744  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_65691eb2   TERMINATED     0.0166576                     5                0.0230802             0.885428                 0.784438        0.0153656        0.0139486        20            4.02765       0.968565       0.96315  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_42d76290   TERMINATED     0.0014152                     9                0.0178108             0.687814                 0.85763         0.0019692        0.00609112       60            3.93633       1.08652        1.07727  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_3e9fda17   TERMINATED     0.0012921                     9                0.0109805             0.867278                 0.839885        0.0905536        0.0516223        20            5.52629       1.135          1.12104  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_2941d575   TERMINATED     0.0369396                     8                0.0644973             0.751787                 0.959235        0.894337         0.928315         20            3.84855       0.729068       0.75489  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5f5ae774   TERMINATED     0.00444876                    5                1.04557               0.876413                 0.928841        2.25626          0.00873392       20            5.32517       1.09812        1.08513  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_727dbcd3   TERMINATED     0.00937608                    6                0.296585              0.630641                 0.990488        8.92507          0.066525         20            5.67205       1.03477        1.02561  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_e6359ef3   TERMINATED     0.00405246                    8                6.27517               0.93147                  0.823728        1.50083          0.003829         20           22.8202        1.09407        1.0825   â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_d5c4cf09   TERMINATED     0.00191343                    5                0.0261658             0.920898                 0.667298        0.00120904       1.11183          20            5.71485       1.13514        1.12027  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5793bdb6   ERROR          0.00836553                    9                0.0374505             0.607379                 0.828608        0.00107156       3.67376           2            5.40395       1.14408        1.12887  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.498 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11455, ip=100.64.7.216)\u001b[0m [12:18:04] [8]\ttrain-rmse:1.09961\tvalid-rmse:1.08603\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.489 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.489 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.489 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.489 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:18:05] [205]\ttrain-rmse:0.11699\tvalid-rmse:0.47242\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.498 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11455, ip=100.64.7.216)\u001b[0m [12:18:07] [9]\ttrain-rmse:1.09502\tvalid-rmse:1.08162\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.505 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:18:08] [206]\ttrain-rmse:0.11609\tvalid-rmse:0.47229\n",
      "\u001b[36m(XGBoostTrainer pid=11455, ip=100.64.7.216)\u001b[0m [12:18:10] [10]\ttrain-rmse:1.08733\tvalid-rmse:1.07439\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.502 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.507 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:18:11] [207]\ttrain-rmse:0.11565\tvalid-rmse:0.47226\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.501 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11455, ip=100.64.7.216)\u001b[0m [12:18:13] [11]\ttrain-rmse:1.07990\tvalid-rmse:1.06742\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:18:14] [208]\ttrain-rmse:0.11503\tvalid-rmse:0.47231\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.521 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.521 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.521 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.522 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.515 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.516 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.516 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.516 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:18:16] [167]\ttrain-rmse:0.34395\tvalid-rmse:0.47293\n",
      "\u001b[36m(XGBoostTrainer pid=11455, ip=100.64.7.216)\u001b[0m [12:18:17] [12]\ttrain-rmse:1.07286\tvalid-rmse:1.06085\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.522 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.522 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.522 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.522 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.510 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:18:19] [168]\ttrain-rmse:0.34342\tvalid-rmse:0.47266\n",
      "\u001b[36m(XGBoostTrainer pid=11455, ip=100.64.7.216)\u001b[0m [12:18:20] [13]\ttrain-rmse:1.06543\tvalid-rmse:1.05386\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.514 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.509 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11455, ip=100.64.7.216)\u001b[0m [12:18:22] [14]\ttrain-rmse:1.06037\tvalid-rmse:1.04902\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.524 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.524 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.524 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.525 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:18:23] [169]\ttrain-rmse:0.34318\tvalid-rmse:0.47266\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:18:25] [209]\ttrain-rmse:0.11490\tvalid-rmse:0.47232\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.502 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.518 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.518 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.518 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.518 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11455, ip=100.64.7.216)\u001b[0m [12:18:26] [15]\ttrain-rmse:1.05349\tvalid-rmse:1.04251\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:18:28] [170]\ttrain-rmse:0.34258\tvalid-rmse:0.47224\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.509 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11455, ip=100.64.7.216)\u001b[0m [12:18:29] [16]\ttrain-rmse:1.04633\tvalid-rmse:1.03574\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.499 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.514 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:18:31] [210]\ttrain-rmse:0.11428\tvalid-rmse:0.47245\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.658 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.659 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.659 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.659 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:18:33] [171]\ttrain-rmse:0.34203\tvalid-rmse:0.47244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial status: 3 RUNNING | 8 TERMINATED | 1 ERROR\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current time: 2025-08-29 12:18:34. Total running time: 15min 22s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current best trial: 946e81ea with valid-rmse=0.47232348328647966 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.12372102335862595, 'max_depth': 8, 'min_child_weight': 0.05312265152593065, 'subsample': 0.9848787891831414, 'colsample_bytree': 0.9496429603242498, 'lambda': 0.002729148416240024, 'alpha': 0.0016047175175163718, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_946e81ea   RUNNING        0.123721                      8                0.0531227             0.984879                 0.949643        0.00272915       0.00160472      210            6.01905       0.114898       0.472323 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_40f91dcb   RUNNING        0.158069                      5                4.35899               0.792105                 0.966918        0.800316         0.0164134       170            5.94181       0.343184       0.472662 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_c9063ba9   RUNNING        0.0118361                     5                0.20819               0.665244                 0.644851        0.660378         1.44566          16            5.38548       1.05349        1.04251  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_65691eb2   TERMINATED     0.0166576                     5                0.0230802             0.885428                 0.784438        0.0153656        0.0139486        20            4.02765       0.968565       0.96315  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_42d76290   TERMINATED     0.0014152                     9                0.0178108             0.687814                 0.85763         0.0019692        0.00609112       60            3.93633       1.08652        1.07727  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_3e9fda17   TERMINATED     0.0012921                     9                0.0109805             0.867278                 0.839885        0.0905536        0.0516223        20            5.52629       1.135          1.12104  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_2941d575   TERMINATED     0.0369396                     8                0.0644973             0.751787                 0.959235        0.894337         0.928315         20            3.84855       0.729068       0.75489  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5f5ae774   TERMINATED     0.00444876                    5                1.04557               0.876413                 0.928841        2.25626          0.00873392       20            5.32517       1.09812        1.08513  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_727dbcd3   TERMINATED     0.00937608                    6                0.296585              0.630641                 0.990488        8.92507          0.066525         20            5.67205       1.03477        1.02561  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_e6359ef3   TERMINATED     0.00405246                    8                6.27517               0.93147                  0.823728        1.50083          0.003829         20           22.8202        1.09407        1.0825   â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_d5c4cf09   TERMINATED     0.00191343                    5                0.0261658             0.920898                 0.667298        0.00120904       1.11183          20            5.71485       1.13514        1.12027  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5793bdb6   ERROR          0.00836553                    9                0.0374505             0.607379                 0.828608        0.00107156       3.67376           2            5.40395       1.14408        1.12887  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.505 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11455, ip=100.64.7.216)\u001b[0m [12:18:34] [17]\ttrain-rmse:1.04212\tvalid-rmse:1.03177\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:18:36] [172]\ttrain-rmse:0.34158\tvalid-rmse:0.47262\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.495 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.507 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11455, ip=100.64.7.216)\u001b[0m [12:18:37] [18]\ttrain-rmse:1.03791\tvalid-rmse:1.02790\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:18:39] [173]\ttrain-rmse:0.34105\tvalid-rmse:0.47229\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.495 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.491 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.491 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.491 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11455, ip=100.64.7.216)\u001b[0m [12:18:40] [19]\ttrain-rmse:1.03123\tvalid-rmse:1.02160\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:18:42] [174]\ttrain-rmse:0.34041\tvalid-rmse:0.47226\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.509 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11455, ip=100.64.7.216)\u001b[0m [12:18:43] [20]\ttrain-rmse:1.02435\tvalid-rmse:1.01507\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.508 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.524 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.524 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.524 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.524 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:18:45] [211]\ttrain-rmse:0.11359\tvalid-rmse:0.47236\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.514 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m ğŸƒ View run XGBoostTrainer_c9063ba9 at: http://ray-68b1b0be9652633ae57e1b88-ray-proxy:8765/#/experiments/257/runs/0585cfd4af8641f084508940ac42e52e\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m ğŸ§ª View experiment at: http://ray-68b1b0be9652633ae57e1b88-ray-proxy:8765/#/experiments/257\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial XGBoostTrainer_c9063ba9 completed after 20 iterations at 2025-08-29 12:18:47. Total running time: 15min 34s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial XGBoostTrainer_c9063ba9 result             â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ checkpoint_dir_name                              â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ time_this_iter_s                         0.00277 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ time_total_s                             5.39763 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ training_iteration                            20 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ train-rmse                               1.03123 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ valid-rmse                                1.0216 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.514 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:18:48] [175]\ttrain-rmse:0.33984\tvalid-rmse:0.47176\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:18:50] [212]\ttrain-rmse:0.11294\tvalid-rmse:0.47240\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.527 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.527 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.527 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.527 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial XGBoostTrainer_b74abd99 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial XGBoostTrainer_b74abd99 config                           â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/alpha                              0.011431661944315075 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/colsample_bytree                     0.7674554220663574 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/eta                               0.0018816588936588377 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/eval_metric                                        rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/lambda                                6.652500411937668 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/max_depth                                             7 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/min_child_weight                    0.37236795656645644 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/nthread                                               1 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/objective                              reg:squarederror â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/subsample                            0.9638256916089898 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/tree_method                                        hist â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=11723, ip=100.64.35.74)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=11723, ip=100.64.35.74)\u001b[0m - (node_id=1241d9436b2265d61f4f92a4765fc79e6ca8d250507ff92e1ea3419e, ip=100.64.35.74, pid=11769) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=11723, ip=100.64.35.74)\u001b[0m - (node_id=1241d9436b2265d61f4f92a4765fc79e6ca8d250507ff92e1ea3419e, ip=100.64.35.74, pid=11770) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=11723, ip=100.64.35.74)\u001b[0m - (node_id=1241d9436b2265d61f4f92a4765fc79e6ca8d250507ff92e1ea3419e, ip=100.64.35.74, pid=11771) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=11723, ip=100.64.35.74)\u001b[0m - (node_id=1241d9436b2265d61f4f92a4765fc79e6ca8d250507ff92e1ea3419e, ip=100.64.35.74, pid=11772) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:18:52] [213]\ttrain-rmse:0.11244\tvalid-rmse:0.47261\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.495 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(RayTrainWorker pid=11772, ip=100.64.35.74)\u001b[0m [12:18:53] Task [xgboost.ray-rank=00000003]:4498d0fab957a2485dd60c9124000000 got rank 3\n",
      "\u001b[36m(RayTrainWorker pid=11770, ip=100.64.35.74)\u001b[0m [12:18:53] Task [xgboost.ray-rank=00000001]:e007cea5ba5683efc80b035824000000 got rank 1\n",
      "\u001b[36m(RayTrainWorker pid=11769, ip=100.64.35.74)\u001b[0m [12:18:53] Task [xgboost.ray-rank=00000000]:3ecc70157e7dddb7e5509e8824000000 got rank 0\n",
      "\u001b[36m(RayTrainWorker pid=11771, ip=100.64.35.74)\u001b[0m [12:18:53] Task [xgboost.ray-rank=00000002]:eeb0c75023cdcfbb7baf007924000000 got rank 2\n",
      "\u001b[36m(SplitCoordinator pid=11933, ip=100.64.35.74)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-08-29_06-53-11_170260_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=11933, ip=100.64.35.74)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.511 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.512 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.512 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.512 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:18:54] [176]\ttrain-rmse:0.33932\tvalid-rmse:0.47204\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:18:55] [214]\ttrain-rmse:0.11217\tvalid-rmse:0.47264\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.497 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(SplitCoordinator pid=11934, ip=100.64.35.74)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-08-29_06-53-11_170260_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=11934, ip=100.64.35.74)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=11723, ip=100.64.35.74)\u001b[0m [12:18:56] [0]\ttrain-rmse:1.15600\tvalid-rmse:1.14002\n",
      "\u001b[36m(XGBoostTrainer pid=11723, ip=100.64.35.74)\u001b[0m [12:18:56] [1]\ttrain-rmse:1.15477\tvalid-rmse:1.13886\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:18:57] [177]\ttrain-rmse:0.33884\tvalid-rmse:0.47196\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.521 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.522 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.522 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.522 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:18:58] [215]\ttrain-rmse:0.11165\tvalid-rmse:0.47264\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.479 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.480 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.480 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.480 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.445 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.445 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.445 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.445 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11723, ip=100.64.35.74)\u001b[0m [12:19:00] [2]\ttrain-rmse:1.15349\tvalid-rmse:1.13765\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:19:01] [178]\ttrain-rmse:0.33819\tvalid-rmse:0.47162\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.486 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.483 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.484 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.484 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.484 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11723, ip=100.64.35.74)\u001b[0m [12:19:03] [3]\ttrain-rmse:1.15203\tvalid-rmse:1.13629\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:19:04] [179]\ttrain-rmse:0.33785\tvalid-rmse:0.47125\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.508 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial status: 3 RUNNING | 9 TERMINATED | 1 ERROR\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current time: 2025-08-29 12:19:04. Total running time: 15min 52s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current best trial: 40f91dcb with valid-rmse=0.47196372682236637 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.15806946838000527, 'max_depth': 5, 'min_child_weight': 4.35899404406858, 'subsample': 0.7921052844297682, 'colsample_bytree': 0.9669182441478732, 'lambda': 0.800315516071967, 'alpha': 0.016413398124265347, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_946e81ea   RUNNING        0.123721                      8                0.0531227             0.984879                 0.949643        0.00272915       0.00160472      215            6.03229       0.11217        0.472643 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_40f91dcb   RUNNING        0.158069                      5                4.35899               0.792105                 0.966918        0.800316         0.0164134       178            5.96413       0.338844       0.471964 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_b74abd99   RUNNING        0.00188166                    7                0.372368              0.963826                 0.767455        6.6525           0.0114317         2            5.32621       1.15477        1.13886  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_65691eb2   TERMINATED     0.0166576                     5                0.0230802             0.885428                 0.784438        0.0153656        0.0139486        20            4.02765       0.968565       0.96315  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_42d76290   TERMINATED     0.0014152                     9                0.0178108             0.687814                 0.85763         0.0019692        0.00609112       60            3.93633       1.08652        1.07727  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_3e9fda17   TERMINATED     0.0012921                     9                0.0109805             0.867278                 0.839885        0.0905536        0.0516223        20            5.52629       1.135          1.12104  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_2941d575   TERMINATED     0.0369396                     8                0.0644973             0.751787                 0.959235        0.894337         0.928315         20            3.84855       0.729068       0.75489  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5f5ae774   TERMINATED     0.00444876                    5                1.04557               0.876413                 0.928841        2.25626          0.00873392       20            5.32517       1.09812        1.08513  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_727dbcd3   TERMINATED     0.00937608                    6                0.296585              0.630641                 0.990488        8.92507          0.066525         20            5.67205       1.03477        1.02561  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_e6359ef3   TERMINATED     0.00405246                    8                6.27517               0.93147                  0.823728        1.50083          0.003829         20           22.8202        1.09407        1.0825   â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_d5c4cf09   TERMINATED     0.00191343                    5                0.0261658             0.920898                 0.667298        0.00120904       1.11183          20            5.71485       1.13514        1.12027  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_c9063ba9   TERMINATED     0.0118361                     5                0.20819               0.665244                 0.644851        0.660378         1.44566          20            5.39763       1.03123        1.0216   â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5793bdb6   ERROR          0.00836553                    9                0.0374505             0.607379                 0.828608        0.00107156       3.67376           2            5.40395       1.14408        1.12887  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:19:06] [216]\ttrain-rmse:0.11121\tvalid-rmse:0.47274\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.497 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:19:07] [180]\ttrain-rmse:0.33738\tvalid-rmse:0.47130\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.508 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:19:09] [217]\ttrain-rmse:0.11072\tvalid-rmse:0.47276\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.653 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.654 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.654 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.654 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.490 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11723, ip=100.64.35.74)\u001b[0m [12:19:11] [4]\ttrain-rmse:1.15057\tvalid-rmse:1.13493\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:19:12] [218]\ttrain-rmse:0.11022\tvalid-rmse:0.47269\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.489 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.489 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.489 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.489 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.493 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:19:14] [181]\ttrain-rmse:0.33703\tvalid-rmse:0.47137\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.490 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11723, ip=100.64.35.74)\u001b[0m [12:19:15] [5]\ttrain-rmse:1.14931\tvalid-rmse:1.13373\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.493 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:19:17] [219]\ttrain-rmse:0.10966\tvalid-rmse:0.47267\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.504 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:19:18] [182]\ttrain-rmse:0.33662\tvalid-rmse:0.47114\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.499 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:19:20] [220]\ttrain-rmse:0.10897\tvalid-rmse:0.47271\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.496 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:19:21] [183]\ttrain-rmse:0.33606\tvalid-rmse:0.47121\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:19:23] [221]\ttrain-rmse:0.10827\tvalid-rmse:0.47264\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.496 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.508 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11723, ip=100.64.35.74)\u001b[0m [12:19:24] [6]\ttrain-rmse:1.14790\tvalid-rmse:1.13244\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:19:26] [222]\ttrain-rmse:0.10800\tvalid-rmse:0.47263\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.486 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.510 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11723, ip=100.64.35.74)\u001b[0m [12:19:27] [7]\ttrain-rmse:1.14641\tvalid-rmse:1.13104\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:19:29] [184]\ttrain-rmse:0.33530\tvalid-rmse:0.47069\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.520 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.521 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.521 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.521 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:19:30] [223]\ttrain-rmse:0.10749\tvalid-rmse:0.47250\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.510 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.516 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.516 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.516 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.516 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11723, ip=100.64.35.74)\u001b[0m [12:19:32] [8]\ttrain-rmse:1.14501\tvalid-rmse:1.12974\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.505 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:19:33] [224]\ttrain-rmse:0.10693\tvalid-rmse:0.47245\n",
      "\u001b[36m(XGBoostTrainer pid=11723, ip=100.64.35.74)\u001b[0m [12:19:35] [9]\ttrain-rmse:1.14351\tvalid-rmse:1.12833\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.523 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.524 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.524 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.524 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial status: 3 RUNNING | 9 TERMINATED | 1 ERROR\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current time: 2025-08-29 12:19:35. Total running time: 16min 22s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current best trial: 40f91dcb with valid-rmse=0.4711359565607799 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.15806946838000527, 'max_depth': 5, 'min_child_weight': 4.35899404406858, 'subsample': 0.7921052844297682, 'colsample_bytree': 0.9669182441478732, 'lambda': 0.800315516071967, 'alpha': 0.016413398124265347, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_946e81ea   RUNNING        0.123721                      8                0.0531227             0.984879                 0.949643        0.00272915       0.00160472      224            6.05771       0.107495       0.472496 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_40f91dcb   RUNNING        0.158069                      5                4.35899               0.792105                 0.966918        0.800316         0.0164134       183            5.97777       0.336617       0.471136 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_b74abd99   RUNNING        0.00188166                    7                0.372368              0.963826                 0.767455        6.6525           0.0114317         8            5.34331       1.14641        1.13104  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_65691eb2   TERMINATED     0.0166576                     5                0.0230802             0.885428                 0.784438        0.0153656        0.0139486        20            4.02765       0.968565       0.96315  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_42d76290   TERMINATED     0.0014152                     9                0.0178108             0.687814                 0.85763         0.0019692        0.00609112       60            3.93633       1.08652        1.07727  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_3e9fda17   TERMINATED     0.0012921                     9                0.0109805             0.867278                 0.839885        0.0905536        0.0516223        20            5.52629       1.135          1.12104  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_2941d575   TERMINATED     0.0369396                     8                0.0644973             0.751787                 0.959235        0.894337         0.928315         20            3.84855       0.729068       0.75489  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5f5ae774   TERMINATED     0.00444876                    5                1.04557               0.876413                 0.928841        2.25626          0.00873392       20            5.32517       1.09812        1.08513  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_727dbcd3   TERMINATED     0.00937608                    6                0.296585              0.630641                 0.990488        8.92507          0.066525         20            5.67205       1.03477        1.02561  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_e6359ef3   TERMINATED     0.00405246                    8                6.27517               0.93147                  0.823728        1.50083          0.003829         20           22.8202        1.09407        1.0825   â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_d5c4cf09   TERMINATED     0.00191343                    5                0.0261658             0.920898                 0.667298        0.00120904       1.11183          20            5.71485       1.13514        1.12027  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_c9063ba9   TERMINATED     0.0118361                     5                0.20819               0.665244                 0.644851        0.660378         1.44566          20            5.39763       1.03123        1.0216   â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5793bdb6   ERROR          0.00836553                    9                0.0374505             0.607379                 0.828608        0.00107156       3.67376           2            5.40395       1.14408        1.12887  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=11723, ip=100.64.35.74)\u001b[0m [12:19:36] [10]\ttrain-rmse:1.14208\tvalid-rmse:1.12700\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.515 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.515 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.515 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.515 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.495 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:19:38] [185]\ttrain-rmse:0.33453\tvalid-rmse:0.47043\n",
      "\u001b[36m(XGBoostTrainer pid=11723, ip=100.64.35.74)\u001b[0m [12:19:39] [11]\ttrain-rmse:1.14072\tvalid-rmse:1.12575\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.504 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.507 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:19:41] [225]\ttrain-rmse:0.10642\tvalid-rmse:0.47252\n",
      "\u001b[36m(XGBoostTrainer pid=11723, ip=100.64.35.74)\u001b[0m [12:19:42] [12]\ttrain-rmse:1.13940\tvalid-rmse:1.12453\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.480 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.480 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.480 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.480 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.507 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:19:44] [226]\ttrain-rmse:0.10592\tvalid-rmse:0.47247\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:19:45] [186]\ttrain-rmse:0.33430\tvalid-rmse:0.47062\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.492 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:19:47] [227]\ttrain-rmse:0.10561\tvalid-rmse:0.47247\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.510 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.511 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11723, ip=100.64.35.74)\u001b[0m [12:19:48] [13]\ttrain-rmse:1.13799\tvalid-rmse:1.12320\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.496 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:19:50] [187]\ttrain-rmse:0.33377\tvalid-rmse:0.47070\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.522 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.523 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.523 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.523 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:19:51] [228]\ttrain-rmse:0.10508\tvalid-rmse:0.47264\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.522 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.523 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.523 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.523 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.503 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11723, ip=100.64.35.74)\u001b[0m [12:19:53] [14]\ttrain-rmse:1.13669\tvalid-rmse:1.12197\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:19:54] [229]\ttrain-rmse:0.10451\tvalid-rmse:0.47267\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.492 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.505 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11723, ip=100.64.35.74)\u001b[0m [12:19:56] [15]\ttrain-rmse:1.13521\tvalid-rmse:1.12057\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.495 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:19:57] [188]\ttrain-rmse:0.33317\tvalid-rmse:0.47066\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.475 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.476 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.476 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.476 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11723, ip=100.64.35.74)\u001b[0m [12:19:59] [16]\ttrain-rmse:1.13373\tvalid-rmse:1.11916\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:20:00] [230]\ttrain-rmse:0.10410\tvalid-rmse:0.47280\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.494 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.507 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:20:02] [189]\ttrain-rmse:0.33300\tvalid-rmse:0.47057\n",
      "\u001b[36m(XGBoostTrainer pid=11723, ip=100.64.35.74)\u001b[0m [12:20:03] [17]\ttrain-rmse:1.13269\tvalid-rmse:1.11816\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.503 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial status: 3 RUNNING | 9 TERMINATED | 1 ERROR\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current time: 2025-08-29 12:20:05. Total running time: 16min 52s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current best trial: 40f91dcb with valid-rmse=0.4706558623150754 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.15806946838000527, 'max_depth': 5, 'min_child_weight': 4.35899404406858, 'subsample': 0.7921052844297682, 'colsample_bytree': 0.9669182441478732, 'lambda': 0.800315516071967, 'alpha': 0.016413398124265347, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_946e81ea   RUNNING        0.123721                      8                0.0531227             0.984879                 0.949643        0.00272915       0.00160472      230            6.07437       0.104515       0.472668 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_40f91dcb   RUNNING        0.158069                      5                4.35899               0.792105                 0.966918        0.800316         0.0164134       189            5.99438       0.333172       0.470656 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_b74abd99   RUNNING        0.00188166                    7                0.372368              0.963826                 0.767455        6.6525           0.0114317        16            5.366         1.13521        1.12057  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_65691eb2   TERMINATED     0.0166576                     5                0.0230802             0.885428                 0.784438        0.0153656        0.0139486        20            4.02765       0.968565       0.96315  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_42d76290   TERMINATED     0.0014152                     9                0.0178108             0.687814                 0.85763         0.0019692        0.00609112       60            3.93633       1.08652        1.07727  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_3e9fda17   TERMINATED     0.0012921                     9                0.0109805             0.867278                 0.839885        0.0905536        0.0516223        20            5.52629       1.135          1.12104  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_2941d575   TERMINATED     0.0369396                     8                0.0644973             0.751787                 0.959235        0.894337         0.928315         20            3.84855       0.729068       0.75489  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5f5ae774   TERMINATED     0.00444876                    5                1.04557               0.876413                 0.928841        2.25626          0.00873392       20            5.32517       1.09812        1.08513  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_727dbcd3   TERMINATED     0.00937608                    6                0.296585              0.630641                 0.990488        8.92507          0.066525         20            5.67205       1.03477        1.02561  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_e6359ef3   TERMINATED     0.00405246                    8                6.27517               0.93147                  0.823728        1.50083          0.003829         20           22.8202        1.09407        1.0825   â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_d5c4cf09   TERMINATED     0.00191343                    5                0.0261658             0.920898                 0.667298        0.00120904       1.11183          20            5.71485       1.13514        1.12027  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_c9063ba9   TERMINATED     0.0118361                     5                0.20819               0.665244                 0.644851        0.660378         1.44566          20            5.39763       1.03123        1.0216   â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5793bdb6   ERROR          0.00836553                    9                0.0374505             0.607379                 0.828608        0.00107156       3.67376           2            5.40395       1.14408        1.12887  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.496 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:20:05] [190]\ttrain-rmse:0.33226\tvalid-rmse:0.47034\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:20:06] [231]\ttrain-rmse:0.10396\tvalid-rmse:0.47277\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.498 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.478 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.479 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.479 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.479 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:20:08] [191]\ttrain-rmse:0.33144\tvalid-rmse:0.47032\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:20:09] [232]\ttrain-rmse:0.10384\tvalid-rmse:0.47274\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.501 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:20:11] [192]\ttrain-rmse:0.33099\tvalid-rmse:0.47060\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.529 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.530 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.530 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.530 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.503 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:20:12] [233]\ttrain-rmse:0.10338\tvalid-rmse:0.47271\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.515 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.515 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.515 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.515 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11723, ip=100.64.35.74)\u001b[0m [12:20:14] [18]\ttrain-rmse:1.13130\tvalid-rmse:1.11687\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:20:15] [193]\ttrain-rmse:0.33066\tvalid-rmse:0.47064\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.509 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:20:17] [234]\ttrain-rmse:0.10296\tvalid-rmse:0.47265\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.504 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:20:18] [194]\ttrain-rmse:0.33017\tvalid-rmse:0.47054\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.511 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.511 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.511 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.503 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:20:20] [235]\ttrain-rmse:0.10249\tvalid-rmse:0.47277\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.500 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:20:21] [195]\ttrain-rmse:0.32956\tvalid-rmse:0.47030\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.512 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.513 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:20:23] [236]\ttrain-rmse:0.10206\tvalid-rmse:0.47272\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:20:24] [196]\ttrain-rmse:0.32928\tvalid-rmse:0.47020\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.506 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.666 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.667 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.667 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.667 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:20:26] [237]\ttrain-rmse:0.10166\tvalid-rmse:0.47269\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.542 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.543 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.543 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.543 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=11723, ip=100.64.35.74)\u001b[0m [12:20:28] [19]\ttrain-rmse:1.12988\tvalid-rmse:1.11553\n",
      "\u001b[36m(XGBoostTrainer pid=11723, ip=100.64.35.74)\u001b[0m [12:20:29] [20]\ttrain-rmse:1.12848\tvalid-rmse:1.11422\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.518 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.518 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.518 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.518 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.483 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.483 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.483 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.483 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:20:31] [238]\ttrain-rmse:0.10117\tvalid-rmse:0.47268\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.502 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m ğŸƒ View run XGBoostTrainer_b74abd99 at: http://ray-68b1b0be9652633ae57e1b88-ray-proxy:8765/#/experiments/257/runs/67b8f23ee9db419e83f0aca4652eec22\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m ğŸ§ª View experiment at: http://ray-68b1b0be9652633ae57e1b88-ray-proxy:8765/#/experiments/257\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial XGBoostTrainer_b74abd99 completed after 20 iterations at 2025-08-29 12:20:32. Total running time: 17min 20s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial XGBoostTrainer_b74abd99 result             â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ checkpoint_dir_name                              â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ time_this_iter_s                         0.00252 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ time_total_s                             5.37681 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ training_iteration                            20 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ train-rmse                               1.12988 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ valid-rmse                               1.11553 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:20:34] [239]\ttrain-rmse:0.10057\tvalid-rmse:0.47262\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.485 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.485 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.485 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.485 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial status: 2 RUNNING | 10 TERMINATED | 1 ERROR | 1 PENDING\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current time: 2025-08-29 12:20:36. Total running time: 17min 23s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current best trial: 40f91dcb with valid-rmse=0.4703045291309288 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.15806946838000527, 'max_depth': 5, 'min_child_weight': 4.35899404406858, 'subsample': 0.7921052844297682, 'colsample_bytree': 0.9669182441478732, 'lambda': 0.800315516071967, 'alpha': 0.016413398124265347, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_946e81ea   RUNNING        0.123721                      8                0.0531227             0.984879                 0.949643        0.00272915       0.00160472      239            6.09954       0.101169       0.472676 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_40f91dcb   RUNNING        0.158069                      5                4.35899               0.792105                 0.966918        0.800316         0.0164134       196            6.01386       0.329558       0.470305 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_65691eb2   TERMINATED     0.0166576                     5                0.0230802             0.885428                 0.784438        0.0153656        0.0139486        20            4.02765       0.968565       0.96315  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_42d76290   TERMINATED     0.0014152                     9                0.0178108             0.687814                 0.85763         0.0019692        0.00609112       60            3.93633       1.08652        1.07727  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_3e9fda17   TERMINATED     0.0012921                     9                0.0109805             0.867278                 0.839885        0.0905536        0.0516223        20            5.52629       1.135          1.12104  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_2941d575   TERMINATED     0.0369396                     8                0.0644973             0.751787                 0.959235        0.894337         0.928315         20            3.84855       0.729068       0.75489  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5f5ae774   TERMINATED     0.00444876                    5                1.04557               0.876413                 0.928841        2.25626          0.00873392       20            5.32517       1.09812        1.08513  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_727dbcd3   TERMINATED     0.00937608                    6                0.296585              0.630641                 0.990488        8.92507          0.066525         20            5.67205       1.03477        1.02561  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_e6359ef3   TERMINATED     0.00405246                    8                6.27517               0.93147                  0.823728        1.50083          0.003829         20           22.8202        1.09407        1.0825   â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_d5c4cf09   TERMINATED     0.00191343                    5                0.0261658             0.920898                 0.667298        0.00120904       1.11183          20            5.71485       1.13514        1.12027  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_c9063ba9   TERMINATED     0.0118361                     5                0.20819               0.665244                 0.644851        0.660378         1.44566          20            5.39763       1.03123        1.0216   â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_b74abd99   TERMINATED     0.00188166                    7                0.372368              0.963826                 0.767455        6.6525           0.0114317        20            5.37681       1.12988        1.11553  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_a148964a   PENDING        0.0355761                     5                1.69672               0.728479                 0.952439        0.399937         0.00415917                                                           â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5793bdb6   ERROR          0.00836553                    9                0.0374505             0.607379                 0.828608        0.00107156       3.67376           2            5.40395       1.14408        1.12887  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.488 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.489 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:20:36] [197]\ttrain-rmse:0.32860\tvalid-rmse:0.46999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial XGBoostTrainer_a148964a started with configuration:\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial XGBoostTrainer_a148964a config                          â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/alpha                             0.004159174016552751 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/colsample_bytree                    0.9524389812527051 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/eta                                0.03557610831675929 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/eval_metric                                       rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/lambda                               0.399936781434202 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/max_depth                                            5 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/min_child_weight                     1.696723730045077 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/nthread                                              1 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/objective                             reg:squarederror â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/subsample                           0.7284785718927383 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ params/tree_method                                       hist â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m - (node_id=9212372711d6417a3d6338c92f31be45ef97cdcf4ce252eb19b5435a, ip=100.64.7.216, pid=12050) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m - (node_id=9212372711d6417a3d6338c92f31be45ef97cdcf4ce252eb19b5435a, ip=100.64.7.216, pid=12051) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m - (node_id=9212372711d6417a3d6338c92f31be45ef97cdcf4ce252eb19b5435a, ip=100.64.7.216, pid=12052) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m - (node_id=9212372711d6417a3d6338c92f31be45ef97cdcf4ce252eb19b5435a, ip=100.64.7.216, pid=12053) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.495 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:20:38] [240]\ttrain-rmse:0.10037\tvalid-rmse:0.47249\n",
      "\u001b[36m(RayTrainWorker pid=12051, ip=100.64.7.216)\u001b[0m [12:20:39] Task [xgboost.ray-rank=00000001]:11e2b45ffab118d4da87a11524000000 got rank 1\n",
      "\u001b[36m(RayTrainWorker pid=12052, ip=100.64.7.216)\u001b[0m [12:20:39] Task [xgboost.ray-rank=00000002]:508a767a44cbf28b1ada176324000000 got rank 2\n",
      "\u001b[36m(RayTrainWorker pid=12053, ip=100.64.7.216)\u001b[0m [12:20:39] Task [xgboost.ray-rank=00000003]:395fc92a47addc2ffb8794aa24000000 got rank 3\n",
      "\u001b[36m(RayTrainWorker pid=12050, ip=100.64.7.216)\u001b[0m [12:20:39] Task [xgboost.ray-rank=00000000]:569467525ce5c637e8db6c0b24000000 got rank 0\n",
      "\u001b[36m(SplitCoordinator pid=12214, ip=100.64.7.216)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-08-29_06-53-11_170260_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=12214, ip=100.64.7.216)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:20:40] [241]\ttrain-rmse:0.10020\tvalid-rmse:0.47245\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.480 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.480 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.480 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.480 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:20:41] [198]\ttrain-rmse:0.32828\tvalid-rmse:0.46982\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.462 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.462 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.462 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.462 s, which may be a performance bottleneck.\n",
      "\u001b[36m(SplitCoordinator pid=12215, ip=100.64.7.216)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-08-29_06-53-11_170260_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=12215, ip=100.64.7.216)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:20:42] [0]\ttrain-rmse:1.13182\tvalid-rmse:1.11716\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.502 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:20:43] [242]\ttrain-rmse:0.09996\tvalid-rmse:0.47245\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:20:44] [1]\ttrain-rmse:1.10694\tvalid-rmse:1.09345\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.463 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.463 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.463 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.463 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.493 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:20:45] [243]\ttrain-rmse:0.09949\tvalid-rmse:0.47250\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:20:47] [199]\ttrain-rmse:0.32796\tvalid-rmse:0.46987\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.521 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.522 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.522 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.522 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.504 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:20:49] [2]\ttrain-rmse:1.08295\tvalid-rmse:1.07050\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.505 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:20:50] [244]\ttrain-rmse:0.09914\tvalid-rmse:0.47252\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:20:52] [200]\ttrain-rmse:0.32736\tvalid-rmse:0.46995\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.504 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.506 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:20:53] [3]\ttrain-rmse:1.06041\tvalid-rmse:1.04920\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:20:55] [245]\ttrain-rmse:0.09855\tvalid-rmse:0.47258\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.512 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.513 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.496 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:20:56] [201]\ttrain-rmse:0.32670\tvalid-rmse:0.46961\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:20:58] [246]\ttrain-rmse:0.09827\tvalid-rmse:0.47257\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.500 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:20:59] [4]\ttrain-rmse:1.03871\tvalid-rmse:1.02886\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.507 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:21:01] [5]\ttrain-rmse:1.01853\tvalid-rmse:1.01005\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.497 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:21:02] [247]\ttrain-rmse:0.09796\tvalid-rmse:0.47259\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.491 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.492 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.509 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:21:04] [6]\ttrain-rmse:0.99898\tvalid-rmse:0.99185\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:21:05] [248]\ttrain-rmse:0.09728\tvalid-rmse:0.47268\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.500 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial status: 3 RUNNING | 10 TERMINATED | 1 ERROR\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current time: 2025-08-29 12:21:07. Total running time: 17min 54s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current best trial: 40f91dcb with valid-rmse=0.469867476278983 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.15806946838000527, 'max_depth': 5, 'min_child_weight': 4.35899404406858, 'subsample': 0.7921052844297682, 'colsample_bytree': 0.9669182441478732, 'lambda': 0.800315516071967, 'alpha': 0.016413398124265347, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_946e81ea   RUNNING        0.123721                      8                0.0531227             0.984879                 0.949643        0.00272915       0.00160472      248            6.12477      0.0979643       0.472593 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_40f91dcb   RUNNING        0.158069                      5                4.35899               0.792105                 0.966918        0.800316         0.0164134       200            6.02453      0.327958        0.469867 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_a148964a   RUNNING        0.0355761                     5                1.69672               0.728479                 0.952439        0.399937         0.00415917        7            5.72668      0.99898         0.991847 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_65691eb2   TERMINATED     0.0166576                     5                0.0230802             0.885428                 0.784438        0.0153656        0.0139486        20            4.02765      0.968565        0.96315  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_42d76290   TERMINATED     0.0014152                     9                0.0178108             0.687814                 0.85763         0.0019692        0.00609112       60            3.93633      1.08652         1.07727  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_3e9fda17   TERMINATED     0.0012921                     9                0.0109805             0.867278                 0.839885        0.0905536        0.0516223        20            5.52629      1.135           1.12104  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_2941d575   TERMINATED     0.0369396                     8                0.0644973             0.751787                 0.959235        0.894337         0.928315         20            3.84855      0.729068        0.75489  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5f5ae774   TERMINATED     0.00444876                    5                1.04557               0.876413                 0.928841        2.25626          0.00873392       20            5.32517      1.09812         1.08513  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_727dbcd3   TERMINATED     0.00937608                    6                0.296585              0.630641                 0.990488        8.92507          0.066525         20            5.67205      1.03477         1.02561  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_e6359ef3   TERMINATED     0.00405246                    8                6.27517               0.93147                  0.823728        1.50083          0.003829         20           22.8202       1.09407         1.0825   â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_d5c4cf09   TERMINATED     0.00191343                    5                0.0261658             0.920898                 0.667298        0.00120904       1.11183          20            5.71485      1.13514         1.12027  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_c9063ba9   TERMINATED     0.0118361                     5                0.20819               0.665244                 0.644851        0.660378         1.44566          20            5.39763      1.03123         1.0216   â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_b74abd99   TERMINATED     0.00188166                    7                0.372368              0.963826                 0.767455        6.6525           0.0114317        20            5.37681      1.12988         1.11553  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5793bdb6   ERROR          0.00836553                    9                0.0374505             0.607379                 0.828608        0.00107156       3.67376           2            5.40395      1.14408         1.12887  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.490 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:21:07] [7]\ttrain-rmse:0.97977\tvalid-rmse:0.97352\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:21:08] [202]\ttrain-rmse:0.32630\tvalid-rmse:0.46947\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.503 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.496 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:21:10] [249]\ttrain-rmse:0.09664\tvalid-rmse:0.47254\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.505 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:21:11] [8]\ttrain-rmse:0.96244\tvalid-rmse:0.95786\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:21:13] [203]\ttrain-rmse:0.32597\tvalid-rmse:0.46920\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.504 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:21:14] [9]\ttrain-rmse:0.94492\tvalid-rmse:0.94165\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.494 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:21:16] [204]\ttrain-rmse:0.32549\tvalid-rmse:0.46942\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.499 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.512 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.513 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:21:17] [10]\ttrain-rmse:0.92837\tvalid-rmse:0.92606\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.510 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:21:19] [205]\ttrain-rmse:0.32510\tvalid-rmse:0.46925\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:21:20] [11]\ttrain-rmse:0.91241\tvalid-rmse:0.91092\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.514 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.510 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:21:22] [206]\ttrain-rmse:0.32462\tvalid-rmse:0.46915\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.508 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:21:23] [12]\ttrain-rmse:0.89729\tvalid-rmse:0.89718\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.520 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.521 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.521 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.521 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:21:25] [207]\ttrain-rmse:0.32441\tvalid-rmse:0.46919\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:21:26] [13]\ttrain-rmse:0.88290\tvalid-rmse:0.88336\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.523 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.523 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.523 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.523 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.502 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:21:28] [208]\ttrain-rmse:0.32401\tvalid-rmse:0.46913\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:21:29] [14]\ttrain-rmse:0.87078\tvalid-rmse:0.87186\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.493 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.513 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:21:31] [209]\ttrain-rmse:0.32363\tvalid-rmse:0.46906\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.510 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:21:32] [15]\ttrain-rmse:0.85694\tvalid-rmse:0.85876\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:21:34] [210]\ttrain-rmse:0.32332\tvalid-rmse:0.46906\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.501 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.515 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.515 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:21:35] [16]\ttrain-rmse:0.84365\tvalid-rmse:0.84637\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:21:37] [211]\ttrain-rmse:0.32303\tvalid-rmse:0.46891\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.508 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial status: 3 RUNNING | 10 TERMINATED | 1 ERROR\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current time: 2025-08-29 12:21:37. Total running time: 18min 24s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current best trial: 40f91dcb with valid-rmse=0.46906493143570793 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.15806946838000527, 'max_depth': 5, 'min_child_weight': 4.35899404406858, 'subsample': 0.7921052844297682, 'colsample_bytree': 0.9669182441478732, 'lambda': 0.800315516071967, 'alpha': 0.016413398124265347, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_946e81ea   RUNNING        0.123721                      8                0.0531227             0.984879                 0.949643        0.00272915       0.00160472      249            6.12763      0.0972824       0.472676 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_40f91dcb   RUNNING        0.158069                      5                4.35899               0.792105                 0.966918        0.800316         0.0164134       210            6.05339      0.323633        0.469065 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_a148964a   RUNNING        0.0355761                     5                1.69672               0.728479                 0.952439        0.399937         0.00415917       16            5.75339      0.856937        0.858763 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_65691eb2   TERMINATED     0.0166576                     5                0.0230802             0.885428                 0.784438        0.0153656        0.0139486        20            4.02765      0.968565        0.96315  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_42d76290   TERMINATED     0.0014152                     9                0.0178108             0.687814                 0.85763         0.0019692        0.00609112       60            3.93633      1.08652         1.07727  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_3e9fda17   TERMINATED     0.0012921                     9                0.0109805             0.867278                 0.839885        0.0905536        0.0516223        20            5.52629      1.135           1.12104  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_2941d575   TERMINATED     0.0369396                     8                0.0644973             0.751787                 0.959235        0.894337         0.928315         20            3.84855      0.729068        0.75489  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5f5ae774   TERMINATED     0.00444876                    5                1.04557               0.876413                 0.928841        2.25626          0.00873392       20            5.32517      1.09812         1.08513  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_727dbcd3   TERMINATED     0.00937608                    6                0.296585              0.630641                 0.990488        8.92507          0.066525         20            5.67205      1.03477         1.02561  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_e6359ef3   TERMINATED     0.00405246                    8                6.27517               0.93147                  0.823728        1.50083          0.003829         20           22.8202       1.09407         1.0825   â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_d5c4cf09   TERMINATED     0.00191343                    5                0.0261658             0.920898                 0.667298        0.00120904       1.11183          20            5.71485      1.13514         1.12027  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_c9063ba9   TERMINATED     0.0118361                     5                0.20819               0.665244                 0.644851        0.660378         1.44566          20            5.39763      1.03123         1.0216   â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_b74abd99   TERMINATED     0.00188166                    7                0.372368              0.963826                 0.767455        6.6525           0.0114317        20            5.37681      1.12988         1.11553  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5793bdb6   ERROR          0.00836553                    9                0.0374505             0.607379                 0.828608        0.00107156       3.67376           2            5.40395      1.14408         1.12887  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.521 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.521 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.521 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.521 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:21:38] [17]\ttrain-rmse:0.83293\tvalid-rmse:0.83625\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:21:40] [212]\ttrain-rmse:0.32238\tvalid-rmse:0.46874\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.518 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.519 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.519 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.519 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:21:41] [250]\ttrain-rmse:0.09628\tvalid-rmse:0.47250\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.504 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.680 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.680 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.680 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.680 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:21:43] [213]\ttrain-rmse:0.32186\tvalid-rmse:0.46849\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:21:44] [251]\ttrain-rmse:0.09554\tvalid-rmse:0.47250\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.501 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.485 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.485 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.485 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.485 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:21:46] [214]\ttrain-rmse:0.32150\tvalid-rmse:0.46841\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.522 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.522 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.522 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.522 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:21:47] [18]\ttrain-rmse:0.82115\tvalid-rmse:0.82526\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.500 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:21:49] [215]\ttrain-rmse:0.32082\tvalid-rmse:0.46783\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.488 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.488 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:21:50] [19]\ttrain-rmse:0.80946\tvalid-rmse:0.81458\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.510 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:21:52] [216]\ttrain-rmse:0.32047\tvalid-rmse:0.46789\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.496 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:21:53] [20]\ttrain-rmse:0.79820\tvalid-rmse:0.80419\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:21:55] [252]\ttrain-rmse:0.09522\tvalid-rmse:0.47254\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.504 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:21:57] [21]\ttrain-rmse:0.78762\tvalid-rmse:0.79461\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.504 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:21:58] [253]\ttrain-rmse:0.09475\tvalid-rmse:0.47253\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.512 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.512 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.512 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.512 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:22:00] [22]\ttrain-rmse:0.77872\tvalid-rmse:0.78619\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.484 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.484 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.484 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.484 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:22:01] [254]\ttrain-rmse:0.09451\tvalid-rmse:0.47254\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.504 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.500 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:22:03] [23]\ttrain-rmse:0.76873\tvalid-rmse:0.77715\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.503 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:22:04] [217]\ttrain-rmse:0.31999\tvalid-rmse:0.46782\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.514 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:22:06] [255]\ttrain-rmse:0.09416\tvalid-rmse:0.47258\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:22:07] [218]\ttrain-rmse:0.31904\tvalid-rmse:0.46725\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.499 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial status: 3 RUNNING | 10 TERMINATED | 1 ERROR\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current time: 2025-08-29 12:22:07. Total running time: 18min 55s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current best trial: 40f91dcb with valid-rmse=0.4678920249024473 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.15806946838000527, 'max_depth': 5, 'min_child_weight': 4.35899404406858, 'subsample': 0.7921052844297682, 'colsample_bytree': 0.9669182441478732, 'lambda': 0.800315516071967, 'alpha': 0.016413398124265347, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_946e81ea   RUNNING        0.123721                      8                0.0531227             0.984879                 0.949643        0.00272915       0.00160472      255            6.14508      0.0945059       0.472537 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_40f91dcb   RUNNING        0.158069                      5                4.35899               0.792105                 0.966918        0.800316         0.0164134       217            6.0719       0.320471        0.467892 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_a148964a   RUNNING        0.0355761                     5                1.69672               0.728479                 0.952439        0.399937         0.00415917       23            5.7733       0.778718        0.786192 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_65691eb2   TERMINATED     0.0166576                     5                0.0230802             0.885428                 0.784438        0.0153656        0.0139486        20            4.02765      0.968565        0.96315  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_42d76290   TERMINATED     0.0014152                     9                0.0178108             0.687814                 0.85763         0.0019692        0.00609112       60            3.93633      1.08652         1.07727  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_3e9fda17   TERMINATED     0.0012921                     9                0.0109805             0.867278                 0.839885        0.0905536        0.0516223        20            5.52629      1.135           1.12104  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_2941d575   TERMINATED     0.0369396                     8                0.0644973             0.751787                 0.959235        0.894337         0.928315         20            3.84855      0.729068        0.75489  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5f5ae774   TERMINATED     0.00444876                    5                1.04557               0.876413                 0.928841        2.25626          0.00873392       20            5.32517      1.09812         1.08513  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_727dbcd3   TERMINATED     0.00937608                    6                0.296585              0.630641                 0.990488        8.92507          0.066525         20            5.67205      1.03477         1.02561  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_e6359ef3   TERMINATED     0.00405246                    8                6.27517               0.93147                  0.823728        1.50083          0.003829         20           22.8202       1.09407         1.0825   â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_d5c4cf09   TERMINATED     0.00191343                    5                0.0261658             0.920898                 0.667298        0.00120904       1.11183          20            5.71485      1.13514         1.12027  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_c9063ba9   TERMINATED     0.0118361                     5                0.20819               0.665244                 0.644851        0.660378         1.44566          20            5.39763      1.03123         1.0216   â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_b74abd99   TERMINATED     0.00188166                    7                0.372368              0.963826                 0.767455        6.6525           0.0114317        20            5.37681      1.12988         1.11553  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5793bdb6   ERROR          0.00836553                    9                0.0374505             0.607379                 0.828608        0.00107156       3.67376           2            5.40395      1.14408         1.12887  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.502 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:22:09] [256]\ttrain-rmse:0.09375\tvalid-rmse:0.47244\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:22:10] [24]\ttrain-rmse:0.75896\tvalid-rmse:0.76840\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.504 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.491 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.491 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.491 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.491 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:22:12] [219]\ttrain-rmse:0.31884\tvalid-rmse:0.46722\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.502 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:22:13] [25]\ttrain-rmse:0.75020\tvalid-rmse:0.76111\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.518 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.518 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.519 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.519 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:22:15] [257]\ttrain-rmse:0.09338\tvalid-rmse:0.47254\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.497 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:22:16] [26]\ttrain-rmse:0.74180\tvalid-rmse:0.75364\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:22:18] [220]\ttrain-rmse:0.31851\tvalid-rmse:0.46730\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.504 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:22:19] [27]\ttrain-rmse:0.73388\tvalid-rmse:0.74604\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.504 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.505 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.497 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:22:21] [258]\ttrain-rmse:0.09294\tvalid-rmse:0.47252\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:22:22] [28]\ttrain-rmse:0.72581\tvalid-rmse:0.73865\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.517 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.517 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.517 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.517 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:22:24] [259]\ttrain-rmse:0.09243\tvalid-rmse:0.47250\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.519 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.519 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.519 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.519 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.494 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:22:25] [221]\ttrain-rmse:0.31804\tvalid-rmse:0.46747\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:22:27] [260]\ttrain-rmse:0.09209\tvalid-rmse:0.47258\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.494 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.505 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:22:28] [29]\ttrain-rmse:0.71812\tvalid-rmse:0.73197\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.514 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:22:30] [261]\ttrain-rmse:0.09168\tvalid-rmse:0.47258\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.497 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:22:31] [222]\ttrain-rmse:0.31762\tvalid-rmse:0.46747\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.510 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:22:33] [30]\ttrain-rmse:0.71043\tvalid-rmse:0.72507\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:22:34] [262]\ttrain-rmse:0.09126\tvalid-rmse:0.47258\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.502 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.503 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:22:36] [223]\ttrain-rmse:0.31732\tvalid-rmse:0.46730\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:22:37] [31]\ttrain-rmse:0.70357\tvalid-rmse:0.71903\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.509 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial status: 3 RUNNING | 10 TERMINATED | 1 ERROR\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current time: 2025-08-29 12:22:37. Total running time: 19min 25s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current best trial: 40f91dcb with valid-rmse=0.46746698707370055 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.15806946838000527, 'max_depth': 5, 'min_child_weight': 4.35899404406858, 'subsample': 0.7921052844297682, 'colsample_bytree': 0.9669182441478732, 'lambda': 0.800315516071967, 'alpha': 0.016413398124265347, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_946e81ea   RUNNING        0.123721                      8                0.0531227             0.984879                 0.949643        0.00272915       0.00160472      262            6.16497       0.091684       0.472582 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_40f91dcb   RUNNING        0.158069                      5                4.35899               0.792105                 0.966918        0.800316         0.0164134       222            6.08592       0.318043       0.467467 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_a148964a   RUNNING        0.0355761                     5                1.69672               0.728479                 0.952439        0.399937         0.00415917       31            5.7976        0.710433       0.72507  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_65691eb2   TERMINATED     0.0166576                     5                0.0230802             0.885428                 0.784438        0.0153656        0.0139486        20            4.02765       0.968565       0.96315  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_42d76290   TERMINATED     0.0014152                     9                0.0178108             0.687814                 0.85763         0.0019692        0.00609112       60            3.93633       1.08652        1.07727  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_3e9fda17   TERMINATED     0.0012921                     9                0.0109805             0.867278                 0.839885        0.0905536        0.0516223        20            5.52629       1.135          1.12104  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_2941d575   TERMINATED     0.0369396                     8                0.0644973             0.751787                 0.959235        0.894337         0.928315         20            3.84855       0.729068       0.75489  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5f5ae774   TERMINATED     0.00444876                    5                1.04557               0.876413                 0.928841        2.25626          0.00873392       20            5.32517       1.09812        1.08513  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_727dbcd3   TERMINATED     0.00937608                    6                0.296585              0.630641                 0.990488        8.92507          0.066525         20            5.67205       1.03477        1.02561  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_e6359ef3   TERMINATED     0.00405246                    8                6.27517               0.93147                  0.823728        1.50083          0.003829         20           22.8202        1.09407        1.0825   â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_d5c4cf09   TERMINATED     0.00191343                    5                0.0261658             0.920898                 0.667298        0.00120904       1.11183          20            5.71485       1.13514        1.12027  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_c9063ba9   TERMINATED     0.0118361                     5                0.20819               0.665244                 0.644851        0.660378         1.44566          20            5.39763       1.03123        1.0216   â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_b74abd99   TERMINATED     0.00188166                    7                0.372368              0.963826                 0.767455        6.6525           0.0114317        20            5.37681       1.12988        1.11553  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5793bdb6   ERROR          0.00836553                    9                0.0374505             0.607379                 0.828608        0.00107156       3.67376           2            5.40395       1.14408        1.12887  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.487 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:22:39] [224]\ttrain-rmse:0.31688\tvalid-rmse:0.46736\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:22:40] [32]\ttrain-rmse:0.69660\tvalid-rmse:0.71282\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.485 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.485 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.485 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.485 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:22:42] [263]\ttrain-rmse:0.09083\tvalid-rmse:0.47251\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.507 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.491 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.491 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.491 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:22:43] [33]\ttrain-rmse:0.68992\tvalid-rmse:0.70683\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:22:45] [264]\ttrain-rmse:0.09062\tvalid-rmse:0.47254\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.506 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.527 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.527 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.527 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.527 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:22:46] [34]\ttrain-rmse:0.68247\tvalid-rmse:0.70004\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:22:48] [265]\ttrain-rmse:0.09006\tvalid-rmse:0.47256\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.500 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.501 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:22:49] [225]\ttrain-rmse:0.31646\tvalid-rmse:0.46744\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.496 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:22:51] [35]\ttrain-rmse:0.67639\tvalid-rmse:0.69491\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.503 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:22:52] [266]\ttrain-rmse:0.08984\tvalid-rmse:0.47256\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.484 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.485 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.485 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.485 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:22:54] [36]\ttrain-rmse:0.66906\tvalid-rmse:0.68798\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.505 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:22:55] [267]\ttrain-rmse:0.08947\tvalid-rmse:0.47259\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.506 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:22:57] [226]\ttrain-rmse:0.31610\tvalid-rmse:0.46759\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.513 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.515 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.515 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.515 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.515 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:22:58] [37]\ttrain-rmse:0.66323\tvalid-rmse:0.68276\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:23:00] [227]\ttrain-rmse:0.31559\tvalid-rmse:0.46765\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.690 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.690 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.690 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.690 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.518 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.519 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.519 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.519 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:23:01] [268]\ttrain-rmse:0.08911\tvalid-rmse:0.47253\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.519 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.519 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.520 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.520 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:23:03] [228]\ttrain-rmse:0.31532\tvalid-rmse:0.46735\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:23:04] [269]\ttrain-rmse:0.08895\tvalid-rmse:0.47258\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.486 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.487 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.487 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.497 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:23:06] [229]\ttrain-rmse:0.31502\tvalid-rmse:0.46723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial status: 3 RUNNING | 10 TERMINATED | 1 ERROR\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current time: 2025-08-29 12:23:07. Total running time: 19min 55s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current best trial: 40f91dcb with valid-rmse=0.4673464444156438 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.15806946838000527, 'max_depth': 5, 'min_child_weight': 4.35899404406858, 'subsample': 0.7921052844297682, 'colsample_bytree': 0.9669182441478732, 'lambda': 0.800315516071967, 'alpha': 0.016413398124265347, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_946e81ea   RUNNING        0.123721                      8                0.0531227             0.984879                 0.949643        0.00272915       0.00160472      269            6.18396      0.0891135       0.472534 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_40f91dcb   RUNNING        0.158069                      5                4.35899               0.792105                 0.966918        0.800316         0.0164134       229            6.10505      0.315323        0.467346 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_a148964a   RUNNING        0.0355761                     5                1.69672               0.728479                 0.952439        0.399937         0.00415917       37            5.81529      0.669061        0.687979 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_65691eb2   TERMINATED     0.0166576                     5                0.0230802             0.885428                 0.784438        0.0153656        0.0139486        20            4.02765      0.968565        0.96315  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_42d76290   TERMINATED     0.0014152                     9                0.0178108             0.687814                 0.85763         0.0019692        0.00609112       60            3.93633      1.08652         1.07727  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_3e9fda17   TERMINATED     0.0012921                     9                0.0109805             0.867278                 0.839885        0.0905536        0.0516223        20            5.52629      1.135           1.12104  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_2941d575   TERMINATED     0.0369396                     8                0.0644973             0.751787                 0.959235        0.894337         0.928315         20            3.84855      0.729068        0.75489  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5f5ae774   TERMINATED     0.00444876                    5                1.04557               0.876413                 0.928841        2.25626          0.00873392       20            5.32517      1.09812         1.08513  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_727dbcd3   TERMINATED     0.00937608                    6                0.296585              0.630641                 0.990488        8.92507          0.066525         20            5.67205      1.03477         1.02561  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_e6359ef3   TERMINATED     0.00405246                    8                6.27517               0.93147                  0.823728        1.50083          0.003829         20           22.8202       1.09407         1.0825   â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_d5c4cf09   TERMINATED     0.00191343                    5                0.0261658             0.920898                 0.667298        0.00120904       1.11183          20            5.71485      1.13514         1.12027  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_c9063ba9   TERMINATED     0.0118361                     5                0.20819               0.665244                 0.644851        0.660378         1.44566          20            5.39763      1.03123         1.0216   â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_b74abd99   TERMINATED     0.00188166                    7                0.372368              0.963826                 0.767455        6.6525           0.0114317        20            5.37681      1.12988         1.11553  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5793bdb6   ERROR          0.00836553                    9                0.0374505             0.607379                 0.828608        0.00107156       3.67376           2            5.40395      1.14408         1.12887  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:23:07] [230]\ttrain-rmse:0.31470\tvalid-rmse:0.46734\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.529 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.530 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.530 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.530 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:23:09] [270]\ttrain-rmse:0.08879\tvalid-rmse:0.47256\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.498 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:23:10] [231]\ttrain-rmse:0.31409\tvalid-rmse:0.46718\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.490 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.491 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.498 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:23:12] [271]\ttrain-rmse:0.08852\tvalid-rmse:0.47258\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.508 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:23:13] [38]\ttrain-rmse:0.65648\tvalid-rmse:0.67642\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:23:15] [232]\ttrain-rmse:0.31370\tvalid-rmse:0.46709\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.483 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.483 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.483 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.483 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:23:16] [39]\ttrain-rmse:0.65079\tvalid-rmse:0.67135\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.505 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.505 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:23:18] [233]\ttrain-rmse:0.31329\tvalid-rmse:0.46751\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.508 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.495 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.495 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:23:19] [272]\ttrain-rmse:0.08800\tvalid-rmse:0.47251\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.507 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.508 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.508 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:23:21] [234]\ttrain-rmse:0.31294\tvalid-rmse:0.46742\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.516 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.516 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.516 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.516 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:23:22] [273]\ttrain-rmse:0.08785\tvalid-rmse:0.47249\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.506 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:23:24] [235]\ttrain-rmse:0.31241\tvalid-rmse:0.46762\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.502 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:23:25] [274]\ttrain-rmse:0.08746\tvalid-rmse:0.47250\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.514 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.514 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:23:27] [236]\ttrain-rmse:0.31208\tvalid-rmse:0.46771\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.513 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:23:29] [275]\ttrain-rmse:0.08712\tvalid-rmse:0.47248\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.522 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.522 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.522 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.522 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:23:30] [237]\ttrain-rmse:0.31171\tvalid-rmse:0.46775\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:23:32] [276]\ttrain-rmse:0.08667\tvalid-rmse:0.47254\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.496 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.497 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:23:33] [238]\ttrain-rmse:0.31120\tvalid-rmse:0.46776\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.506 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:23:35] [277]\ttrain-rmse:0.08617\tvalid-rmse:0.47249\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.494 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.494 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.517 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.517 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.517 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.517 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:23:36] [239]\ttrain-rmse:0.31079\tvalid-rmse:0.46804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial status: 3 RUNNING | 10 TERMINATED | 1 ERROR\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current time: 2025-08-29 12:23:38. Total running time: 20min 25s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current best trial: 40f91dcb with valid-rmse=0.46775327736772515 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.15806946838000527, 'max_depth': 5, 'min_child_weight': 4.35899404406858, 'subsample': 0.7921052844297682, 'colsample_bytree': 0.9669182441478732, 'lambda': 0.800315516071967, 'alpha': 0.016413398124265347, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_946e81ea   RUNNING        0.123721                      8                0.0531227             0.984879                 0.949643        0.00272915       0.00160472      278            6.20873      0.0861728       0.472485 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_40f91dcb   RUNNING        0.158069                      5                4.35899               0.792105                 0.966918        0.800316         0.0164134       238            6.13043      0.31171         0.467753 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_a148964a   RUNNING        0.0355761                     5                1.69672               0.728479                 0.952439        0.399937         0.00415917       39            5.82082      0.656481        0.676423 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_65691eb2   TERMINATED     0.0166576                     5                0.0230802             0.885428                 0.784438        0.0153656        0.0139486        20            4.02765      0.968565        0.96315  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_42d76290   TERMINATED     0.0014152                     9                0.0178108             0.687814                 0.85763         0.0019692        0.00609112       60            3.93633      1.08652         1.07727  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_3e9fda17   TERMINATED     0.0012921                     9                0.0109805             0.867278                 0.839885        0.0905536        0.0516223        20            5.52629      1.135           1.12104  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_2941d575   TERMINATED     0.0369396                     8                0.0644973             0.751787                 0.959235        0.894337         0.928315         20            3.84855      0.729068        0.75489  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5f5ae774   TERMINATED     0.00444876                    5                1.04557               0.876413                 0.928841        2.25626          0.00873392       20            5.32517      1.09812         1.08513  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_727dbcd3   TERMINATED     0.00937608                    6                0.296585              0.630641                 0.990488        8.92507          0.066525         20            5.67205      1.03477         1.02561  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_e6359ef3   TERMINATED     0.00405246                    8                6.27517               0.93147                  0.823728        1.50083          0.003829         20           22.8202       1.09407         1.0825   â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_d5c4cf09   TERMINATED     0.00191343                    5                0.0261658             0.920898                 0.667298        0.00120904       1.11183          20            5.71485      1.13514         1.12027  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_c9063ba9   TERMINATED     0.0118361                     5                0.20819               0.665244                 0.644851        0.660378         1.44566          20            5.39763      1.03123         1.0216   â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_b74abd99   TERMINATED     0.00188166                    7                0.372368              0.963826                 0.767455        6.6525           0.0114317        20            5.37681      1.12988         1.11553  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5793bdb6   ERROR          0.00836553                    9                0.0374505             0.607379                 0.828608        0.00107156       3.67376           2            5.40395      1.14408         1.12887  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.525 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.525 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.525 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.525 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:23:38] [278]\ttrain-rmse:0.08581\tvalid-rmse:0.47251\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:23:39] [240]\ttrain-rmse:0.31052\tvalid-rmse:0.46814\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.498 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.485 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.485 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.485 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.485 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:23:41] [279]\ttrain-rmse:0.08526\tvalid-rmse:0.47256\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:23:42] [241]\ttrain-rmse:0.31026\tvalid-rmse:0.46800\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.484 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.484 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.484 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.484 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:23:44] [40]\ttrain-rmse:0.64587\tvalid-rmse:0.66689\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.502 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.503 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.503 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:23:45] [242]\ttrain-rmse:0.30964\tvalid-rmse:0.46750\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.500 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.509 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.509 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.510 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:23:47] [41]\ttrain-rmse:0.64169\tvalid-rmse:0.66338\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.499 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:23:48] [243]\ttrain-rmse:0.30914\tvalid-rmse:0.46764\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:23:50] [42]\ttrain-rmse:0.63724\tvalid-rmse:0.65966\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.523 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.523 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.523 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.523 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.493 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:23:51] [244]\ttrain-rmse:0.30864\tvalid-rmse:0.46774\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.498 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:23:53] [43]\ttrain-rmse:0.63322\tvalid-rmse:0.65617\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.493 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.493 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:23:54] [245]\ttrain-rmse:0.30831\tvalid-rmse:0.46755\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.523 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.524 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.524 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.524 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:23:56] [280]\ttrain-rmse:0.08498\tvalid-rmse:0.47257\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:23:57] [246]\ttrain-rmse:0.30791\tvalid-rmse:0.46756\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.490 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.490 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:23:59] [281]\ttrain-rmse:0.08452\tvalid-rmse:0.47251\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.478 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.478 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.478 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.478 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:24:00] [282]\ttrain-rmse:0.08396\tvalid-rmse:0.47253\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.500 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.500 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=8951, ip=100.64.3.241)\u001b[0m [12:24:02] [247]\ttrain-rmse:0.30740\tvalid-rmse:0.46767\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.497 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.497 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.480 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.480 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.480 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.480 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:24:03] [283]\ttrain-rmse:0.08362\tvalid-rmse:0.47261\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.492 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.492 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:24:05] [44]\ttrain-rmse:0.62869\tvalid-rmse:0.65227\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:24:06] [284]\ttrain-rmse:0.08305\tvalid-rmse:0.47257\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.517 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.517 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.517 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.517 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=12004, ip=100.64.7.216)\u001b[0m [12:24:08] [45]\ttrain-rmse:0.62437\tvalid-rmse:0.64862\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.499 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=9427, ip=100.64.90.131)\u001b[0m [12:24:09] [285]\ttrain-rmse:0.08293\tvalid-rmse:0.47259\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `callbacks.on_trial_result` operation took 1.512 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Processing trial results took 1.513 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m The `process_trial_result` operation took 1.513 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Trial status: 3 RUNNING | 10 TERMINATED | 1 ERROR\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current time: 2025-08-29 12:24:09. Total running time: 20min 57s\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m Current best trial: 40f91dcb with valid-rmse=0.4675486691446892 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.15806946838000527, 'max_depth': 5, 'min_child_weight': 4.35899404406858, 'subsample': 0.7921052844297682, 'colsample_bytree': 0.9669182441478732, 'lambda': 0.800315516071967, 'alpha': 0.016413398124265347, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_946e81ea   RUNNING        0.123721                      8                0.0531227             0.984879                 0.949643        0.00272915       0.00160472      285            6.22836      0.0830545       0.47257  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_40f91dcb   RUNNING        0.158069                      5                4.35899               0.792105                 0.966918        0.800316         0.0164134       246            6.15296      0.308312        0.467549 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_a148964a   RUNNING        0.0355761                     5                1.69672               0.728479                 0.952439        0.399937         0.00415917       45            5.89094      0.628692        0.652267 â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_65691eb2   TERMINATED     0.0166576                     5                0.0230802             0.885428                 0.784438        0.0153656        0.0139486        20            4.02765      0.968565        0.96315  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_42d76290   TERMINATED     0.0014152                     9                0.0178108             0.687814                 0.85763         0.0019692        0.00609112       60            3.93633      1.08652         1.07727  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_3e9fda17   TERMINATED     0.0012921                     9                0.0109805             0.867278                 0.839885        0.0905536        0.0516223        20            5.52629      1.135           1.12104  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_2941d575   TERMINATED     0.0369396                     8                0.0644973             0.751787                 0.959235        0.894337         0.928315         20            3.84855      0.729068        0.75489  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5f5ae774   TERMINATED     0.00444876                    5                1.04557               0.876413                 0.928841        2.25626          0.00873392       20            5.32517      1.09812         1.08513  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_727dbcd3   TERMINATED     0.00937608                    6                0.296585              0.630641                 0.990488        8.92507          0.066525         20            5.67205      1.03477         1.02561  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_e6359ef3   TERMINATED     0.00405246                    8                6.27517               0.93147                  0.823728        1.50083          0.003829         20           22.8202       1.09407         1.0825   â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_d5c4cf09   TERMINATED     0.00191343                    5                0.0261658             0.920898                 0.667298        0.00120904       1.11183          20            5.71485      1.13514         1.12027  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_c9063ba9   TERMINATED     0.0118361                     5                0.20819               0.665244                 0.644851        0.660378         1.44566          20            5.39763      1.03123         1.0216   â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_b74abd99   TERMINATED     0.00188166                    7                0.372368              0.963826                 0.767455        6.6525           0.0114317        20            5.37681      1.12988         1.11553  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â”‚ XGBoostTrainer_5793bdb6   ERROR          0.00836553                    9                0.0374505             0.607379                 0.828608        0.00107156       3.67376           2            5.40395      1.14408         1.12887  â”‚\n",
      "\u001b[36m(TunerInternal pid=88477)\u001b[0m â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    }
   ],
   "source": [
    "# ---------- cluster client init (if using Ray Client) ----------\n",
    "# If you're connecting to a running Ray cluster via ray://, keep the IRSA vars with runtime_env there too.\n",
    "ray.shutdown()\n",
    "\n",
    "RAY_JOB_ENV = {\n",
    "    \"AWS_ROLE_ARN\": os.environ.get(\"AWS_ROLE_ARN\", \"\"),\n",
    "    \"AWS_WEB_IDENTITY_TOKEN_FILE\": os.environ.get(\"AWS_WEB_IDENTITY_TOKEN_FILE\", \"\"),\n",
    "    \"AWS_REGION\": os.environ.get(\"AWS_REGION\", os.environ.get(\"AWS_DEFAULT_REGION\", \"us-east-1\")),\n",
    "    \"AWS_DEFAULT_REGION\": os.environ.get(\"AWS_REGION\", os.environ.get(\"AWS_DEFAULT_REGION\", \"us-east-1\")),\n",
    "    \"TUNE_DISABLE_AUTO_CALLBACK_LOGGERS\":\"1\",\n",
    "    \"TUNE_RESULT_BUFFER_LENGTH\": \"16\",\n",
    "    \"TUNE_RESULT_BUFFER_FLUSH_INTERVAL_S\": \"3\",    \n",
    "    \n",
    "}\n",
    "_ensure_ray_connected(RAY_JOB_ENV,ray_ns=\"xgb-eval\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f090a047-0626-4d00-9554-aba802ddf5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"s3://ddl-wadkars/navy/california/\"\n",
    "main(data_dir=data_dir, num_workers=4, cpus_per_worker=1,experiment_name=experiment_name,DEV_FAST=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4e00d6-0f97-4180-a994-7cb7fc0e83ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray, sys, pyarrow as pa, pandas as pd\n",
    "print(\"DRIVER:\", sys.version)\n",
    "print(\"DRIVER pyarrow:\", pa.__version__)\n",
    "print(\"DRIVER pandas :\", pd.__version__)\n",
    "\n",
    "@ray.remote\n",
    "def _env_probe():\n",
    "    import sys, pyarrow as pa, pandas as pd\n",
    "    return {\n",
    "        \"python\": sys.version.split()[0],\n",
    "        \"pyarrow\": pa.__version__,\n",
    "        \"pandas\": pd.__version__,\n",
    "    }\n",
    "\n",
    "print(\"WORKER:\", ray.get(_env_probe.remote()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24693a55-d5a2-482c-95e0-364e8d60c521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a23211-b6aa-469e-878f-b19ec0943134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dd3a8b-6669-45fa-9368-dc722d74746c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
