{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1336f048-16eb-441b-9c12-74309c613578",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-01 18:47:01,680\tINFO util.py:154 -- Outdated packages:\n",
      "  ipywidgets==7.7.5 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-09-01 18:47:01,760\tINFO util.py:154 -- Outdated packages:\n",
      "  ipywidgets==7.7.5 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-09-01 18:47:01,897\tINFO util.py:154 -- Outdated packages:\n",
      "  ipywidgets==7.7.5 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import pyarrow as pa\n",
    "import pyarrow.dataset as pds\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import mlflow\n",
    "import mlflow.xgboost as mlflow_xgb\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.air import RunConfig, ScalingConfig\n",
    "from ray.data import read_parquet\n",
    "from ray.air.integrations.mlflow import MLflowLoggerCallback\n",
    "from ray.train.xgboost import XGBoostTrainer\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "try:\n",
    "    from ray.tune.callback import Callback      # Ray >= 2.6\n",
    "except ImportError:\n",
    "    from ray.tune.callbacks import Callback     # Older Ray\n",
    "from utils import cluster_scaler_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a54bc1-58ed-42ae-ae0c-341a0ca2d442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fe473df-6ff9-4cce-8bbf-10f4493cb6dd",
   "metadata": {},
   "source": [
    "## Pre-requsites\n",
    "\n",
    "Configure the following user environment variables\n",
    "\n",
    "1. AWS_ROLE_ARN - This is the AWS role being assumed via IR\n",
    "2. S3_BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8af9bda-73fe-4dde-b2b5-c9c6e54ee9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ../../tmp/train.parquet to s3://ddl-wadkars/end-to-end/california/train/train.parquet\n",
      "upload: ../../tmp/val.parquet to s3://ddl-wadkars/end-to-end/california/val/val.parquet\n",
      "upload: ../../tmp/test.parquet to s3://ddl-wadkars/end-to-end/california/test/test.parquet\n"
     ]
    }
   ],
   "source": [
    "# Download dataset and push to S3\n",
    "\n",
    "# Load dataset\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "df = data.frame.rename(columns={\"MedHouseVal\": \"median_house_value\"})\n",
    "\n",
    "# Split\n",
    "train, tmp = train_test_split(df, test_size=0.3, random_state=42)\n",
    "val, test  = train_test_split(tmp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Save locally\n",
    "train.to_parquet(\"/tmp/train.parquet\", index=False)\n",
    "val.to_parquet(\"/tmp/val.parquet\", index=False)\n",
    "test.to_parquet(\"/tmp/test.parquet\", index=False)\n",
    "\n",
    "# Push to S3\n",
    "!aws s3 cp /tmp/train.parquet s3://${S3_BUCKET_NAME}/end-to-end/california/train/\n",
    "!aws s3 cp /tmp/val.parquet   s3://${S3_BUCKET_NAME}/end-to-end/california/val/\n",
    "!aws s3 cp /tmp/test.parquet  s3://${S3_BUCKET_NAME}/end-to-end/california/test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7040bd1-cd6e-4be0-98d9-2f90d4a527ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_mlflow_experiment(experiment_name: str) -> int:\n",
    "    \"\"\"\n",
    "    Ensure an MLflow experiment exists and set it as current.\n",
    "\n",
    "    If an experiment with `experiment_name` does not exist, create it. In both cases,\n",
    "    set the active experiment so subsequent runs attach correctly.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    experiment_name : str\n",
    "        The MLflow experiment name.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The experiment ID.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    RuntimeError\n",
    "        If the experiment lookup/creation fails.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - The MLflow tracking URI and token are pre-configured in Domino\n",
    "    \"\"\"\n",
    "    try:\n",
    "        exp = mlflow.get_experiment_by_name(experiment_name)\n",
    "        if exp is None:\n",
    "            exp_id = mlflow.create_experiment(\n",
    "                experiment_name\n",
    "            )\n",
    "        else:\n",
    "            exp_id = exp.experiment_id\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "        return exp_id\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to ensure experiment {experiment_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1adda697-3841-450e-98f4-bed31db79159",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def _s3p(root: str, sub: str) -> str:\n",
    "    \"\"\"Safe join for S3/posix URIs.\"\"\"\n",
    "    return f\"{root.rstrip('/')}/{sub.lstrip('/')}\"\n",
    "\n",
    "\n",
    "def read_parquet_to_pandas(uri: str, columns=None, limit: int | None = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Robust Parquet→pandas loader that bypasses Ray Data.\n",
    "    Works with local paths and s3:// (PyArrow uses AWS_* env vars / IRSA).\n",
    "    \"\"\"\n",
    "    ds = pds.dataset(uri.rstrip(\"/\"), format=\"parquet\")\n",
    "    if limit is None:\n",
    "        return ds.to_table(columns=columns).to_pandas()\n",
    "\n",
    "    # Respect limit across files/row groups\n",
    "    scanner = pds.Scanner.from_dataset(ds, columns=columns)\n",
    "    batches, rows = [], 0\n",
    "    for b in scanner.to_batches():\n",
    "        batches.append(b)\n",
    "        rows += len(b)\n",
    "        if rows >= limit:\n",
    "            return pa.Table.from_batches(batches)[:limit].to_pandas()\n",
    "    return pa.Table.from_batches(batches).to_pandas()\n",
    "\n",
    "\n",
    "def main(experiment_name:str,data_dir: str,num_workers: int = 4, cpus_per_worker: int = 1,  DEV_FAST: bool = False):\n",
    "    \"\"\"\n",
    "    Quick knobs:\n",
    "      - num_workers * cpus_per_worker = CPUs per trial.\n",
    "      - trainer_resources={\"CPU\":0} so the driver doesn't steal a core.\n",
    "      - PACK placement to keep trials tight.\n",
    "      - max_concurrent_trials caps parallel trials.\n",
    "      - num_boost_round / early_stopping_rounds control trial length.\n",
    "      - nthread = cpus_per_worker to avoid oversubscription.\n",
    "    \"\"\"\n",
    "\n",
    "    exp_id = ensure_mlflow_experiment(experiment_name)\n",
    "    \n",
    "    # Storage: local for dev, S3/your env otherwise\n",
    "    RUN_STORAGE = os.environ.get(\"RAY_AIR_STORAGE\", f\"{data_dir}/air/xgb\")\n",
    "    TUNER_STORAGE = \"/tmp/air-dev\" if DEV_FAST else RUN_STORAGE\n",
    "    FINAL_STORAGE = \"/mnt/data/ddl-end-to-end-demo/air/final_fit\" if DEV_FAST else RUN_STORAGE\n",
    "\n",
    "    # Sanity: workers see IRSA env?\n",
    "    @ray.remote\n",
    "    def _peek():\n",
    "        import os\n",
    "        return {\n",
    "            \"ROLE\": bool(os.environ.get(\"AWS_ROLE_ARN\")),\n",
    "            \"TOKEN_FILE\": os.environ.get(\"AWS_WEB_IDENTITY_TOKEN_FILE\"),\n",
    "            \"REGION\": os.environ.get(\"AWS_REGION\"),\n",
    "        }\n",
    "    print(\"Worker env peek:\", ray.get(_peek.remote()))\n",
    "\n",
    "    # MLflow (experiment + parent run)\n",
    "    CLUSTER_TRACKING_URI = os.environ[\"CLUSTER_MLFLOW_TRACKING_URI\"]\n",
    "    \n",
    "    \n",
    "    client = MlflowClient()\n",
    "\n",
    "\n",
    "    parent = client.create_run(\n",
    "        experiment_id=exp_id,\n",
    "        tags={\"mlflow.runName\": \"xgb_parent\", \"role\": \"tune_parent\"},\n",
    "    )\n",
    "    parent_run_id = parent.info.run_id\n",
    "    print(\"Parent run id:\", parent_run_id)\n",
    "\n",
    "    # Data (Ray Datasets for training/val)\n",
    "    train_ds = read_parquet(_s3p(data_dir, \"train\"), parallelism=num_workers)\n",
    "    val_ds   = read_parquet(_s3p(data_dir, \"val\"),   parallelism=num_workers)\n",
    "    test_ds  = read_parquet(_s3p(data_dir, \"test\"),  parallelism=num_workers)\n",
    "    print(\"Schema:\", train_ds.schema())\n",
    "\n",
    "    # Label + features\n",
    "    label_col = \"median_house_value\"\n",
    "    feature_cols = [c for c in train_ds.schema().names if c != label_col]\n",
    "    keep = feature_cols + [label_col]\n",
    "    train_ds = train_ds.select_columns(keep)\n",
    "    val_ds   = val_ds.select_columns(keep)\n",
    "\n",
    "    # DEV: trim Ray Datasets used for training; eval will bypass Ray entirely\n",
    "    if DEV_FAST:\n",
    "        train_ds = train_ds.limit(5_000)\n",
    "        val_ds   = val_ds.limit(2_000)\n",
    "\n",
    "    # --- Build test DataFrame without Ray (avoids 'Global node is not initialized') ---\n",
    "    test_uri = _s3p(data_dir, \"test\")\n",
    "    test_pdf = read_parquet_to_pandas(\n",
    "        test_uri, columns=keep, limit=2_000 if DEV_FAST else None\n",
    "    )\n",
    "\n",
    "    # Search space\n",
    "    param_space = {\n",
    "        \"params\": {\n",
    "            \"objective\": \"reg:squarederror\",\n",
    "            \"tree_method\": \"hist\",\n",
    "            \"eval_metric\": \"rmse\",\n",
    "            \"eta\": tune.loguniform(1e-3, 3e-1),\n",
    "            \"max_depth\": tune.randint(4, 12),\n",
    "            \"min_child_weight\": tune.loguniform(1e-2, 10),\n",
    "            \"subsample\": tune.uniform(0.6, 1.0),\n",
    "            \"colsample_bytree\": tune.uniform(0.6, 1.0),\n",
    "            \"lambda\": tune.loguniform(1e-3, 10),\n",
    "            \"alpha\": tune.loguniform(1e-3, 10),\n",
    "        },\n",
    "        \"num_boost_round\": 300,\n",
    "        \"early_stopping_rounds\": 20,\n",
    "    }\n",
    "\n",
    "    # Dev shortcuts\n",
    "    if DEV_FAST:\n",
    "        param_space[\"num_boost_round\"] = 20\n",
    "        param_space[\"early_stopping_rounds\"] = 5\n",
    "        num_workers = 1\n",
    "        cpus_per_worker = 1\n",
    "        NUM_SAMPLES = 5\n",
    "        MAX_CONCURRENT = 3\n",
    "        SAVE_ARTIFACTS = True\n",
    "    else:\n",
    "        NUM_SAMPLES = 30\n",
    "        MAX_CONCURRENT = 3\n",
    "        SAVE_ARTIFACTS = True\n",
    "\n",
    "    # Threads per worker\n",
    "    param_space[\"params\"][\"nthread\"] = cpus_per_worker\n",
    "    print(\"Per-trial CPUs =\", num_workers * cpus_per_worker)\n",
    "\n",
    "    # Scaling / placement\n",
    "    scaling = ScalingConfig(\n",
    "        num_workers=num_workers,\n",
    "        use_gpu=False,\n",
    "        resources_per_worker={\"CPU\": cpus_per_worker},\n",
    "        trainer_resources={\"CPU\": 0},\n",
    "        placement_strategy=\"PACK\",\n",
    "    )\n",
    "\n",
    "    # Trainable\n",
    "    trainer = XGBoostTrainer(\n",
    "        label_column=label_col,\n",
    "        params=param_space[\"params\"],\n",
    "        datasets={\"train\": train_ds, \"valid\": val_ds},\n",
    "        num_boost_round=param_space[\"num_boost_round\"],\n",
    "        scaling_config=scaling,\n",
    "    )\n",
    "\n",
    "    # Search + scheduler\n",
    "    MAX_T = int(param_space[\"num_boost_round\"])\n",
    "    GRACE = int(min(param_space.get(\"early_stopping_rounds\", 1), MAX_T))\n",
    "    algo = HyperOptSearch(metric=\"valid-rmse\", mode=\"min\")\n",
    "    scheduler = ASHAScheduler(max_t=MAX_T, grace_period=GRACE, reduction_factor=3)\n",
    "\n",
    "    # MLflow callback (child runs)\n",
    "    mlflow_cb = MLflowLoggerCallback(\n",
    "        tracking_uri=CLUSTER_TRACKING_URI,\n",
    "        experiment_name=experiment_name,\n",
    "        save_artifact=SAVE_ARTIFACTS,\n",
    "        tags={\"mlflow.parentRunId\": parent_run_id},\n",
    "    )\n",
    "\n",
    "    # Tuner\n",
    "    tuner = tune.Tuner(\n",
    "        trainer.as_trainable(),\n",
    "        run_config=RunConfig(\n",
    "            name=\"xgb_from_s3_irsa\",\n",
    "            storage_path=TUNER_STORAGE,\n",
    "            callbacks=[mlflow_cb],\n",
    "        ),\n",
    "        tune_config=tune.TuneConfig(\n",
    "            search_alg=algo,\n",
    "            scheduler=scheduler,\n",
    "            metric=\"valid-rmse\",\n",
    "            mode=\"min\",\n",
    "            num_samples=NUM_SAMPLES,\n",
    "            max_concurrent_trials=MAX_CONCURRENT,\n",
    "        ),\n",
    "        param_space={\"params\": param_space[\"params\"]},\n",
    "    )\n",
    "\n",
    "    # Tune\n",
    "    results = tuner.fit()\n",
    "    best = results.get_best_result(metric=\"valid-rmse\", mode=\"min\")\n",
    "    print(\"Best config:\", best.config)\n",
    "    print(\"Best valid RMSE:\", best.metrics.get(\"valid-rmse\"))\n",
    "\n",
    "    # Final fit (train + val)\n",
    "    merged = train_ds.union(val_ds)\n",
    "    final_trainer = XGBoostTrainer(\n",
    "        label_column=label_col,\n",
    "        params=best.config[\"params\"],\n",
    "        datasets={\"train\": merged},\n",
    "        num_boost_round=param_space[\"num_boost_round\"],\n",
    "        scaling_config=scaling,\n",
    "        run_config=RunConfig(name=\"final_fit\", storage_path=FINAL_STORAGE),\n",
    "    )\n",
    "    final_result = final_trainer.fit()\n",
    "    final_ckpt = final_result.checkpoint\n",
    "\n",
    "    # Load Booster from checkpoint\n",
    "    with final_ckpt.as_directory() as ckpt_dir:\n",
    "        print(\"Checkpoint dir:\", ckpt_dir, \"files:\", os.listdir(ckpt_dir))\n",
    "        candidates = [\"model.json\", \"model.ubj\", \"model.xgb\", \"xgboost_model.json\", \"model\"]\n",
    "        model_path = next(\n",
    "            (os.path.join(ckpt_dir, f) for f in candidates if os.path.exists(os.path.join(ckpt_dir, f))),\n",
    "            None,\n",
    "        )\n",
    "        if not model_path:\n",
    "            raise FileNotFoundError(f\"No XGBoost model file found in checkpoint dir: {ckpt_dir}\")\n",
    "        booster = xgb.Booster()\n",
    "        booster.load_model(model_path)\n",
    "\n",
    "    # Driver-side eval (no Ray dependency)\n",
    "    X_test = test_pdf.drop(columns=[label_col])\n",
    "    \n",
    "    dmat = xgb.DMatrix(X_test)\n",
    "    y_pred = booster.predict(dmat)\n",
    "    rmse = math.sqrt(((test_pdf[label_col].to_numpy() - y_pred) ** 2).mean())\n",
    "    print(f\"Test RMSE: {rmse:.4f}\")\n",
    "\n",
    "    \n",
    "    # Log final under parent\n",
    "\n",
    "    with mlflow.start_run(run_id=parent_run_id):\n",
    "        X_example = X_test.head(5).copy()  \n",
    "        y_example = booster.predict(xgb.DMatrix(X_example))\n",
    "        sig = infer_signature(X_example, y_example)\n",
    "        with mlflow.start_run(run_name=\"final_fit\", nested=True):\n",
    "            mlflow.log_params(best.config.get(\"params\", {}))\n",
    "            mlflow.log_dict({\"label\": label_col, \"features\": feature_cols}, \"features.json\")\n",
    "            mlflow.log_metric(\"valid_rmse_best\", float(best.metrics.get(\"valid-rmse\")))\n",
    "            mlflow.log_metric(\"test_rmse\", float(rmse))\n",
    "            mlflow_xgb.log_model(booster, artifact_path=\"model\",signature=sig,input_example=X_example)\n",
    "    run = client.get_run(parent_run_id)\n",
    "    if run.info.status == \"RUNNING\":\n",
    "        client.set_terminated(parent_run_id, \"FINISHED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daaca126-a443-402f-8b44-1c5f9a3f2447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "def ensure_ray_connected(ray_envs: Dict[str,str], ray_ns:str):\n",
    "    if ray.is_initialized():\n",
    "        return\n",
    "    # Reconnect to the running cluster (prefers ray:// if present)\n",
    "    addr = None\n",
    "    if \"RAY_HEAD_SERVICE_HOST\" in os.environ and \"RAY_HEAD_SERVICE_PORT\" in os.environ:\n",
    "        addr = f\"ray://{os.environ['RAY_HEAD_SERVICE_HOST']}:{os.environ['RAY_HEAD_SERVICE_PORT']}\"\n",
    "    ray.init(\n",
    "        address=addr or \"auto\",\n",
    "        runtime_env={\"env_vars\": ray_envs},   # same env you used earlier\n",
    "        namespace=ray_ns,\n",
    "        ignore_reinit_error=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "043ca34d-56b3-42b4-9ced-c185bb3a7ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3804/372615125.py:5: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize(config_path=\"conf\"):\n"
     ]
    }
   ],
   "source": [
    "## Read Conf from Hydra\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "# Point Hydra to your conf/ directory\n",
    "with initialize(config_path=\"conf\"):\n",
    "    cfg = compose(config_name=\"config\", overrides=[\"env=dev\"])\n",
    "    #print(f\"Running in {cfg.env} environment\")\n",
    "    #print(OmegaConf.to_yaml(cfg, resolve=True))\n",
    "    \n",
    "    app_name = cfg.app.name\n",
    "    data_dir = cfg.app.data_dir\n",
    "    experiment_name = cfg.mlflow.experiment_name    \n",
    "    ray_workers = cfg.env.ray.num_workers\n",
    "    cpus_per_worker = cfg.env.ray.cpus_per_worker\n",
    "    dev_fast = cfg.env.ray.dev_fast\n",
    "    #print(ray_workers)\n",
    "    #print(dev_fast)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcb46094-7068-418f-817e-95d7d3053c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable tensorboard integration\n",
    "os.environ[\"TUNE_DISABLE_AUTO_CALLBACK_LOGGERS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41ee926e-ca00-486d-af2c-53cd603c4b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://ddl-cluster-scaler-svc.domino-field.svc.cluster.local/ddl_cluster_scaler/scale/rayclusters/ray-68b5e1f3b7910b03aaf26bb0\n",
      "Status code 200\n",
      "ray-68b5e1f3b7910b03aaf26bb0\n",
      "http://ddl-cluster-scaler-svc.domino-field.svc.cluster.local/ddl_cluster_scaler/get/rayclusters/ray-68b5e1f3b7910b03aaf26bb0\n",
      "Status code 200\n",
      "Expected worker nodes 4\n",
      "Current worker nodes ['ray-68b5e1f3b7910b03aaf26bb0-ray-worker-0']\n",
      "Scaling not yet done...\n",
      "ray-68b5e1f3b7910b03aaf26bb0\n",
      "http://ddl-cluster-scaler-svc.domino-field.svc.cluster.local/ddl_cluster_scaler/get/rayclusters/ray-68b5e1f3b7910b03aaf26bb0\n",
      "Status code 200\n",
      "Expected worker nodes 4\n",
      "Current worker nodes ['ray-68b5e1f3b7910b03aaf26bb0-ray-worker-0', 'ray-68b5e1f3b7910b03aaf26bb0-ray-worker-1', 'ray-68b5e1f3b7910b03aaf26bb0-ray-worker-2', 'ray-68b5e1f3b7910b03aaf26bb0-ray-worker-3']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_scaler_client.scale_cluster(cluster_kind=\"rayclusters\",replicas=4)\n",
    "cluster_scaler_client.wait_until_scaling_complete(cluster_kind=\"rayclusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224ba8ff-d2f0-4ad2-83b8-501b4dc41640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m AIR_VERBOSITY is set, ignoring passed-in ProgressReporter for now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Configuration for experiment     xgb_from_s3_irsa        │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Search algorithm                 SearchGenerator         │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Scheduler                        AsyncHyperBandScheduler │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Number of trials                 30                      │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m View detailed results here: ddl-wadkars/end-to-end/california/air/xgb/xgb_from_s3_irsa\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 1 PENDING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 11:49:12. Total running time: 0s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status       params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   PENDING       0.0279228                    8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_e6f7faf6 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_e6f7faf6 config                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/alpha                             0.0027673015151075727 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/colsample_bytree                     0.6994715912141354 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eta                                0.027922831871879127 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eval_metric                                        rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/lambda                            0.0020630616467057017 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/max_depth                                             8 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/min_child_weight                   0.035439580412438214 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/nthread                                               1 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/objective                              reg:squarederror │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/subsample                            0.7197886829704874 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/tree_method                                        hist │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m - (node_id=020c605741033b9152b4c9a349b6d58f62114a723ef561972a9adde1, ip=100.64.47.109, pid=343) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m - (node_id=020c605741033b9152b4c9a349b6d58f62114a723ef561972a9adde1, ip=100.64.47.109, pid=344) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m - (node_id=020c605741033b9152b4c9a349b6d58f62114a723ef561972a9adde1, ip=100.64.47.109, pid=345) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m - (node_id=020c605741033b9152b4c9a349b6d58f62114a723ef561972a9adde1, ip=100.64.47.109, pid=346) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(RayTrainWorker pid=343, ip=100.64.47.109)\u001b[0m [11:49:18] Task [xgboost.ray-rank=00000000]:361ba55c5007865d7aa0102a04000000 got rank 0\n",
      "\u001b[36m(RayTrainWorker pid=346, ip=100.64.47.109)\u001b[0m [11:49:18] Task [xgboost.ray-rank=00000003]:1a3aebb950711baf77b8b0ac04000000 got rank 3\n",
      "\u001b[36m(RayTrainWorker pid=344, ip=100.64.47.109)\u001b[0m [11:49:18] Task [xgboost.ray-rank=00000001]:d2fe8f10b6874de83ec8853804000000 got rank 1\n",
      "\u001b[36m(RayTrainWorker pid=345, ip=100.64.47.109)\u001b[0m [11:49:18] Task [xgboost.ray-rank=00000002]:9fe79c5799b7ff5cae4a5f5204000000 got rank 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_5f9c4ad7 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_5f9c4ad7 config                          │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/alpha                              0.39913158717439107 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/colsample_bytree                    0.7816500895048499 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eta                               0.011894835892141157 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eval_metric                                       rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/lambda                             0.08493766858268043 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/max_depth                                            6 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/min_child_weight                   0.03510024906691227 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/nthread                                              1 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/objective                             reg:squarederror │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/subsample                           0.8267365241163852 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/tree_method                                       hist │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SplitCoordinator pid=548, ip=100.64.47.109)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=548, ip=100.64.47.109)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m - (node_id=aa7a1be9217ecfac6d99669d9eee6a9281027e3894db76bdace3f284, ip=100.64.25.122, pid=353) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m - (node_id=aa7a1be9217ecfac6d99669d9eee6a9281027e3894db76bdace3f284, ip=100.64.25.122, pid=354) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m - (node_id=aa7a1be9217ecfac6d99669d9eee6a9281027e3894db76bdace3f284, ip=100.64.25.122, pid=355) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m - (node_id=aa7a1be9217ecfac6d99669d9eee6a9281027e3894db76bdace3f284, ip=100.64.25.122, pid=356) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(RayTrainWorker pid=353, ip=100.64.25.122)\u001b[0m [11:49:19] Task [xgboost.ray-rank=00000000]:f343af5176d69f7c9cae4fd204000000 got rank 0\n",
      "\u001b[36m(RayTrainWorker pid=354, ip=100.64.25.122)\u001b[0m [11:49:19] Task [xgboost.ray-rank=00000001]:3066947bf07eab72e538ca5004000000 got rank 1\n",
      "\u001b[36m(RayTrainWorker pid=356, ip=100.64.25.122)\u001b[0m [11:49:19] Task [xgboost.ray-rank=00000003]:4313721e3fa7e444743cf60a04000000 got rank 3\n",
      "\u001b[36m(RayTrainWorker pid=355, ip=100.64.25.122)\u001b[0m [11:49:19] Task [xgboost.ray-rank=00000002]:069587c348ddd66c471b352a04000000 got rank 2\n",
      "\u001b[36m(SplitCoordinator pid=517, ip=100.64.25.122)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=517, ip=100.64.25.122)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_e7b672c9 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_e7b672c9 config                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/alpha                              0.046228253563691375 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/colsample_bytree                     0.7671702811989362 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eta                               0.0033304809702342296 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eval_metric                                        rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/lambda                               1.3355876622469025 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/max_depth                                             4 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/min_child_weight                      3.242630298877694 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/nthread                                               1 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/objective                              reg:squarederror │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/subsample                            0.6839718962198272 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/tree_method                                        hist │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SplitCoordinator pid=551, ip=100.64.47.109)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=551, ip=100.64.47.109)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(SplitCoordinator pid=518, ip=100.64.25.122)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=518, ip=100.64.25.122)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=256, ip=100.64.8.234)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=256, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=303) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=256, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=304) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=256, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=305) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=256, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=306) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:49:21] [0]\ttrain-rmse:1.13399\tvalid-rmse:1.11994\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:49:21] [1]\ttrain-rmse:1.11545\tvalid-rmse:1.10318\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:49:21] [0]\ttrain-rmse:1.14834\tvalid-rmse:1.13279\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:49:21] [1]\ttrain-rmse:1.14133\tvalid-rmse:1.12612\n",
      "\u001b[36m(RayTrainWorker pid=306, ip=100.64.8.234)\u001b[0m [11:49:22] Task [xgboost.ray-rank=00000003]:6209892c6edef75b51fd1bb804000000 got rank 3\n",
      "\u001b[36m(RayTrainWorker pid=303, ip=100.64.8.234)\u001b[0m [11:49:22] Task [xgboost.ray-rank=00000000]:fdc12ae9c0cba3bb6ca0e31304000000 got rank 0\n",
      "\u001b[36m(RayTrainWorker pid=304, ip=100.64.8.234)\u001b[0m [11:49:22] Task [xgboost.ray-rank=00000001]:d651260f6b6dd9420b0d23ba04000000 got rank 1\n",
      "\u001b[36m(RayTrainWorker pid=305, ip=100.64.8.234)\u001b[0m [11:49:22] Task [xgboost.ray-rank=00000002]:196e4afe8d49fd84ba877fa504000000 got rank 2\n",
      "\u001b[36m(SplitCoordinator pid=467, ip=100.64.8.234)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=467, ip=100.64.8.234)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:49:23] [2]\ttrain-rmse:1.09844\tvalid-rmse:1.08761\n",
      "\u001b[36m(SplitCoordinator pid=468, ip=100.64.8.234)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=468, ip=100.64.8.234)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=256, ip=100.64.8.234)\u001b[0m [11:49:24] [0]\ttrain-rmse:1.15522\tvalid-rmse:1.13925\n",
      "\u001b[36m(XGBoostTrainer pid=256, ip=100.64.8.234)\u001b[0m [11:49:24] [1]\ttrain-rmse:1.15374\tvalid-rmse:1.13783\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:49:25] [3]\ttrain-rmse:1.08154\tvalid-rmse:1.07224\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:49:26] [2]\ttrain-rmse:1.13419\tvalid-rmse:1.11945\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:49:28] [4]\ttrain-rmse:1.05930\tvalid-rmse:1.05161\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:49:30] [3]\ttrain-rmse:1.12528\tvalid-rmse:1.11102\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:49:32] [5]\ttrain-rmse:1.04129\tvalid-rmse:1.03421\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:49:33] [4]\ttrain-rmse:1.11655\tvalid-rmse:1.10284\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:49:35] [6]\ttrain-rmse:1.02158\tvalid-rmse:1.01677\n",
      "\u001b[36m(XGBoostTrainer pid=256, ip=100.64.8.234)\u001b[0m [11:49:37] [2]\ttrain-rmse:1.15225\tvalid-rmse:1.13642\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:49:39] [7]\ttrain-rmse:1.00470\tvalid-rmse:1.00065\n",
      "\u001b[36m(XGBoostTrainer pid=256, ip=100.64.8.234)\u001b[0m [11:49:40] [3]\ttrain-rmse:1.15000\tvalid-rmse:1.13429\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:49:42] [5]\ttrain-rmse:1.10950\tvalid-rmse:1.09612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 11:49:42. Total running time: 30s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: e6f7faf6 with valid-rmse=1.0342086570926592 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.027922831871879127, 'max_depth': 8, 'min_child_weight': 0.035439580412438214, 'subsample': 0.7197886829704874, 'colsample_bytree': 0.6994715912141354, 'lambda': 0.0020630616467057017, 'alpha': 0.0027673015151075727, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status       params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING      0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673        6            6.56517        1.04129        1.03421 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   RUNNING      0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132         4            3.90595        1.12528        1.11102 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   RUNNING      0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283        2            3.75188        1.15374        1.13783 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=256, ip=100.64.8.234)\u001b[0m [11:49:44] [4]\ttrain-rmse:1.14777\tvalid-rmse:1.13217\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:49:45] [6]\ttrain-rmse:1.10117\tvalid-rmse:1.08833\n",
      "\u001b[36m(XGBoostTrainer pid=256, ip=100.64.8.234)\u001b[0m [11:49:47] [5]\ttrain-rmse:1.14631\tvalid-rmse:1.13077\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:49:49] [7]\ttrain-rmse:1.09257\tvalid-rmse:1.08015\n",
      "\u001b[36m(XGBoostTrainer pid=256, ip=100.64.8.234)\u001b[0m [11:49:51] [6]\ttrain-rmse:1.14414\tvalid-rmse:1.12874\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:49:52] [8]\ttrain-rmse:1.08474\tvalid-rmse:1.07301\n",
      "\u001b[36m(XGBoostTrainer pid=256, ip=100.64.8.234)\u001b[0m [11:49:54] [7]\ttrain-rmse:1.14195\tvalid-rmse:1.12667\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:49:56] [9]\ttrain-rmse:1.07636\tvalid-rmse:1.06508\n",
      "\u001b[36m(XGBoostTrainer pid=256, ip=100.64.8.234)\u001b[0m [11:49:58] [8]\ttrain-rmse:1.13992\tvalid-rmse:1.12481\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:50:00] [10]\ttrain-rmse:1.06826\tvalid-rmse:1.05742\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:50:01] [8]\ttrain-rmse:0.98507\tvalid-rmse:0.98257\n",
      "\u001b[36m(XGBoostTrainer pid=256, ip=100.64.8.234)\u001b[0m [11:50:03] [9]\ttrain-rmse:1.13776\tvalid-rmse:1.12275\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:50:05] [9]\ttrain-rmse:0.96905\tvalid-rmse:0.96737\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:50:07] [10]\ttrain-rmse:0.95138\tvalid-rmse:0.95159\n",
      "\u001b[36m(XGBoostTrainer pid=256, ip=100.64.8.234)\u001b[0m [11:50:08] [10]\ttrain-rmse:1.13557\tvalid-rmse:1.12067\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:50:10] [11]\ttrain-rmse:0.93296\tvalid-rmse:0.93490\n",
      "\u001b[36m(XGBoostTrainer pid=256, ip=100.64.8.234)\u001b[0m [11:50:12] [11]\ttrain-rmse:1.13353\tvalid-rmse:1.11877\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:50:14] [11]\ttrain-rmse:1.06073\tvalid-rmse:1.05042\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.777 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 11:50:14. Total running time: 1min 2s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: e6f7faf6 with valid-rmse=0.9673671174273308 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.027922831871879127, 'max_depth': 8, 'min_child_weight': 0.035439580412438214, 'subsample': 0.7197886829704874, 'colsample_bytree': 0.6994715912141354, 'lambda': 0.0020630616467057017, 'alpha': 0.0027673015151075727, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status       params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING      0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673       10            6.57628       0.969054       0.967367 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   RUNNING      0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        10            3.92245       1.07636        1.06508  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   RUNNING      0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       10            3.7742        1.13776        1.12275  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:50:15] [12]\ttrain-rmse:0.91736\tvalid-rmse:0.92121\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=256, ip=100.64.8.234)\u001b[0m [11:50:17] [12]\ttrain-rmse:1.13155\tvalid-rmse:1.11693\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.773 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:50:19] [12]\ttrain-rmse:1.05340\tvalid-rmse:1.04381\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=256, ip=100.64.8.234)\u001b[0m [11:50:21] [13]\ttrain-rmse:1.12942\tvalid-rmse:1.11493\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.786 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:50:23] [13]\ttrain-rmse:1.04563\tvalid-rmse:1.03658\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.923 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.923 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.923 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.923 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=256, ip=100.64.8.234)\u001b[0m [11:50:24] [14]\ttrain-rmse:1.12800\tvalid-rmse:1.11357\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:50:26] [13]\ttrain-rmse:0.90096\tvalid-rmse:0.90654\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:50:28] [14]\ttrain-rmse:1.03933\tvalid-rmse:1.03061\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:50:30] [14]\ttrain-rmse:0.88853\tvalid-rmse:0.89529\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.737 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=256, ip=100.64.8.234)\u001b[0m [11:50:31] [15]\ttrain-rmse:1.12587\tvalid-rmse:1.11153\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.742 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:50:33] [15]\ttrain-rmse:1.03156\tvalid-rmse:1.02321\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.722 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.722 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.722 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=256, ip=100.64.8.234)\u001b[0m [11:50:35] [16]\ttrain-rmse:1.12375\tvalid-rmse:1.10953\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:50:37] [16]\ttrain-rmse:1.02391\tvalid-rmse:1.01601\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:50:38] [17]\ttrain-rmse:1.01872\tvalid-rmse:1.01097\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.729 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.718 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.718 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.718 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.718 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=256, ip=100.64.8.234)\u001b[0m [11:50:40] [17]\ttrain-rmse:1.12239\tvalid-rmse:1.10820\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:50:42] [18]\ttrain-rmse:1.01150\tvalid-rmse:1.00425\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.729 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.719 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.719 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.719 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.719 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=256, ip=100.64.8.234)\u001b[0m [11:50:44] [18]\ttrain-rmse:1.12027\tvalid-rmse:1.10619\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:50:45] [19]\ttrain-rmse:1.00440\tvalid-rmse:0.99777\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.737 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 11:50:45. Total running time: 1min 33s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: e6f7faf6 with valid-rmse=0.921213088433364 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.027922831871879127, 'max_depth': 8, 'min_child_weight': 0.035439580412438214, 'subsample': 0.7197886829704874, 'colsample_bytree': 0.6994715912141354, 'lambda': 0.0020630616467057017, 'alpha': 0.0027673015151075727, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status       params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING      0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673       13            6.58432       0.917358       0.921213 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   RUNNING      0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        18            3.94549       1.01872        1.01097  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   RUNNING      0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       17            3.79368       1.12375        1.10953  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:50:47] [15]\ttrain-rmse:0.87210\tvalid-rmse:0.88054\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.728 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:50:49] [16]\ttrain-rmse:0.85716\tvalid-rmse:0.86726\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.725 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:50:51] [20]\ttrain-rmse:0.99730\tvalid-rmse:0.99119\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:50:52] [17]\ttrain-rmse:0.84765\tvalid-rmse:0.85912\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.716 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.717 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.717 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.717 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:50:54] [21]\ttrain-rmse:0.99124\tvalid-rmse:0.98530\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.735 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:50:56] [18]\ttrain-rmse:0.83815\tvalid-rmse:0.85142\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=256, ip=100.64.8.234)\u001b[0m [11:50:57] [19]\ttrain-rmse:1.11827\tvalid-rmse:1.10433\n",
      "\u001b[36m(XGBoostTrainer pid=256, ip=100.64.8.234)\u001b[0m [11:50:59] [20]\ttrain-rmse:1.11618\tvalid-rmse:1.10233\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.745 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:51:01] [22]\ttrain-rmse:0.98548\tvalid-rmse:0.97989\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🏃 View run XGBoostTrainer_e7b672c9 at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265/runs/af01947352cd4b6bbd50760c662c7333\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🧪 View experiment at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_e7b672c9 completed after 20 iterations at 2025-09-01 11:51:03. Total running time: 1min 51s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_e7b672c9 result             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ checkpoint_dir_name                              │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_this_iter_s                         0.00287 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_total_s                             3.80221 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ training_iteration                            20 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ train-rmse                               1.11827 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ valid-rmse                               1.10433 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.705 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.705 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.705 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.705 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:51:05] [23]\ttrain-rmse:0.97879\tvalid-rmse:0.97382\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:51:07] [19]\ttrain-rmse:0.82402\tvalid-rmse:0.83875\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_b837ab13 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_b837ab13 config                          │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/alpha                               1.0424740420799559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/colsample_bytree                    0.8160890636739222 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eta                               0.006335747767181478 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eval_metric                                       rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/lambda                             0.10378755436874924 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/max_depth                                            8 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/min_child_weight                   0.30618436049198644 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/nthread                                              1 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/objective                             reg:squarederror │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/subsample                           0.8738103876038282 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/tree_method                                       hist │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=504, ip=100.64.27.77)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=504, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=550) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=504, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=551) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=504, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=552) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=504, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=553) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.719 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.719 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.719 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.719 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:51:10] [24]\ttrain-rmse:0.97293\tvalid-rmse:0.96831\n",
      "\u001b[36m(RayTrainWorker pid=553, ip=100.64.27.77)\u001b[0m [11:51:10] Task [xgboost.ray-rank=00000003]:6e2dbcfe313acf03da49e97604000000 got rank 3\n",
      "\u001b[36m(RayTrainWorker pid=550, ip=100.64.27.77)\u001b[0m [11:51:10] Task [xgboost.ray-rank=00000000]:37140121dcfc6ad40d61198504000000 got rank 0\n",
      "\u001b[36m(RayTrainWorker pid=551, ip=100.64.27.77)\u001b[0m [11:51:10] Task [xgboost.ray-rank=00000001]:8abac8c1ac1996a2034d40f404000000 got rank 1\n",
      "\u001b[36m(RayTrainWorker pid=552, ip=100.64.27.77)\u001b[0m [11:51:10] Task [xgboost.ray-rank=00000002]:cb9f1ae530f6c9829512985e04000000 got rank 2\n",
      "\u001b[36m(SplitCoordinator pid=714, ip=100.64.27.77)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=714, ip=100.64.27.77)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:51:12] [20]\ttrain-rmse:0.81048\tvalid-rmse:0.82712\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.719 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.720 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.720 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.720 s, which may be a performance bottleneck.\n",
      "\u001b[36m(SplitCoordinator pid=717, ip=100.64.27.77)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=717, ip=100.64.27.77)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:51:13] [25]\ttrain-rmse:0.96634\tvalid-rmse:0.96229\n",
      "\u001b[36m(XGBoostTrainer pid=504, ip=100.64.27.77)\u001b[0m [11:51:13] [0]\ttrain-rmse:1.15218\tvalid-rmse:1.13653\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.720 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.721 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.721 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.721 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:51:15] [21]\ttrain-rmse:0.79904\tvalid-rmse:0.81755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 1 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 11:51:17. Total running time: 2min 5s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: e6f7faf6 with valid-rmse=0.8387516193102249 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.027922831871879127, 'max_depth': 8, 'min_child_weight': 0.035439580412438214, 'subsample': 0.7197886829704874, 'colsample_bytree': 0.6994715912141354, 'lambda': 0.0020630616467057017, 'alpha': 0.0027673015151075727, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673       20            6.60424       0.824024       0.838752 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   RUNNING        0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        25            3.96553       0.972935       0.968314 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   RUNNING        0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247                                                             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:51:17] [26]\ttrain-rmse:0.95974\tvalid-rmse:0.95617\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.678 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.678 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.678 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.678 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=504, ip=100.64.27.77)\u001b[0m [11:51:18] [1]\ttrain-rmse:1.14721\tvalid-rmse:1.13183\n",
      "\u001b[36m(XGBoostTrainer pid=504, ip=100.64.27.77)\u001b[0m [11:51:20] [2]\ttrain-rmse:1.14213\tvalid-rmse:1.12701\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.737 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:51:22] [27]\ttrain-rmse:0.95435\tvalid-rmse:0.95101\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.720 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.721 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.721 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.721 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:51:24] [22]\ttrain-rmse:0.78564\tvalid-rmse:0.80547\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.712 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.713 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.713 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.713 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:51:25] [28]\ttrain-rmse:0.94793\tvalid-rmse:0.94505\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.728 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=504, ip=100.64.27.77)\u001b[0m [11:51:27] [3]\ttrain-rmse:1.13698\tvalid-rmse:1.12222\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:51:29] [29]\ttrain-rmse:0.94271\tvalid-rmse:0.94005\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:51:31] [30]\ttrain-rmse:0.93668\tvalid-rmse:0.93461\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.737 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:51:32] [23]\ttrain-rmse:0.77319\tvalid-rmse:0.79508\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.733 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:51:34] [31]\ttrain-rmse:0.93029\tvalid-rmse:0.92868\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.716 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.717 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.717 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.717 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:51:36] [24]\ttrain-rmse:0.76021\tvalid-rmse:0.78311\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:51:37] [32]\ttrain-rmse:0.92426\tvalid-rmse:0.92318\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.717 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.717 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.717 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.718 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:51:39] [25]\ttrain-rmse:0.74916\tvalid-rmse:0.77412\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.708 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.708 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.708 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.708 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:51:41] [26]\ttrain-rmse:0.73760\tvalid-rmse:0.76460\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.715 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.715 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.715 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.715 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:51:43] [33]\ttrain-rmse:0.91802\tvalid-rmse:0.91739\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.720 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.721 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.721 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.721 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:51:44] [27]\ttrain-rmse:0.72666\tvalid-rmse:0.75428\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.922 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.923 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.923 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.923 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=504, ip=100.64.27.77)\u001b[0m [11:51:46] [4]\ttrain-rmse:1.13179\tvalid-rmse:1.11740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 1 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 11:51:48. Total running time: 2min 36s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: e6f7faf6 with valid-rmse=0.7741232221342513 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.027922831871879127, 'max_depth': 8, 'min_child_weight': 0.035439580412438214, 'subsample': 0.7197886829704874, 'colsample_bytree': 0.6994715912141354, 'lambda': 0.0020630616467057017, 'alpha': 0.0027673015151075727, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673       26            6.62095       0.749165       0.774123 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   RUNNING        0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        33            3.98879       0.924256       0.923182 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   RUNNING        0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247          4            5.2638        1.13698        1.12222  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.735 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:51:48] [34]\ttrain-rmse:0.91208\tvalid-rmse:0.91196\n",
      "\u001b[36m(XGBoostTrainer pid=504, ip=100.64.27.77)\u001b[0m [11:51:50] [5]\ttrain-rmse:1.12695\tvalid-rmse:1.11285\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.736 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=504, ip=100.64.27.77)\u001b[0m [11:51:51] [6]\ttrain-rmse:1.12196\tvalid-rmse:1.10829\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.734 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.732 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:51:53] [35]\ttrain-rmse:0.90672\tvalid-rmse:0.90676\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.733 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=504, ip=100.64.27.77)\u001b[0m [11:51:55] [7]\ttrain-rmse:1.11665\tvalid-rmse:1.10335\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.788 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:51:57] [28]\ttrain-rmse:0.71704\tvalid-rmse:0.74658\n",
      "\u001b[36m(XGBoostTrainer pid=504, ip=100.64.27.77)\u001b[0m [11:51:58] [8]\ttrain-rmse:1.11161\tvalid-rmse:1.09870\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:52:00] [29]\ttrain-rmse:0.70610\tvalid-rmse:0.73663\n",
      "\u001b[36m(XGBoostTrainer pid=504, ip=100.64.27.77)\u001b[0m [11:52:02] [9]\ttrain-rmse:1.10634\tvalid-rmse:1.09384\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.773 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.733 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:52:04] [30]\ttrain-rmse:0.69684\tvalid-rmse:0.72959\n",
      "\u001b[36m(XGBoostTrainer pid=504, ip=100.64.27.77)\u001b[0m [11:52:05] [10]\ttrain-rmse:1.10144\tvalid-rmse:1.08932\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.735 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.737 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:52:07] [31]\ttrain-rmse:0.68743\tvalid-rmse:0.72180\n",
      "\u001b[36m(XGBoostTrainer pid=504, ip=100.64.27.77)\u001b[0m [11:52:09] [11]\ttrain-rmse:1.09664\tvalid-rmse:1.08501\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.711 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.711 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.711 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.711 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.717 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.718 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.718 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.718 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:52:11] [32]\ttrain-rmse:0.67905\tvalid-rmse:0.71507\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.714 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.714 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.714 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.714 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=504, ip=100.64.27.77)\u001b[0m [11:52:12] [12]\ttrain-rmse:1.09211\tvalid-rmse:1.08100\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.713 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.714 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.714 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.714 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:52:14] [36]\ttrain-rmse:0.90149\tvalid-rmse:0.90180\n",
      "\u001b[36m(XGBoostTrainer pid=504, ip=100.64.27.77)\u001b[0m [11:52:16] [13]\ttrain-rmse:1.08732\tvalid-rmse:1.07656\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.730 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.715 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.716 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.716 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.716 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:52:18] [37]\ttrain-rmse:0.89559\tvalid-rmse:0.89634\n",
      "\u001b[36m(XGBoostTrainer pid=504, ip=100.64.27.77)\u001b[0m [11:52:19] [14]\ttrain-rmse:1.08264\tvalid-rmse:1.07220\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.705 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.706 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.706 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.706 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 1 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 11:52:19. Total running time: 3min 7s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: e6f7faf6 with valid-rmse=0.7295877492478354 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.027922831871879127, 'max_depth': 8, 'min_child_weight': 0.035439580412438214, 'subsample': 0.7197886829704874, 'colsample_bytree': 0.6994715912141354, 'lambda': 0.0020630616467057017, 'alpha': 0.0027673015151075727, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673       31            6.63512       0.696836       0.729588 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   RUNNING        0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        36            3.99731       0.906715       0.906758 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   RUNNING        0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         14            5.29309       1.08732        1.07656  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.739 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:52:21] [38]\ttrain-rmse:0.89053\tvalid-rmse:0.89160\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:52:23] [39]\ttrain-rmse:0.88496\tvalid-rmse:0.88660\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.700 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.701 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.701 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.701 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:52:24] [33]\ttrain-rmse:0.66910\tvalid-rmse:0.70700\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.726 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:52:26] [40]\ttrain-rmse:0.87901\tvalid-rmse:0.88104\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=504, ip=100.64.27.77)\u001b[0m [11:52:28] [15]\ttrain-rmse:1.07765\tvalid-rmse:1.06754\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.720 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.721 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.721 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.721 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:52:30] [41]\ttrain-rmse:0.87366\tvalid-rmse:0.87612\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=504, ip=100.64.27.77)\u001b[0m [11:52:31] [16]\ttrain-rmse:1.07263\tvalid-rmse:1.06285\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:52:33] [34]\ttrain-rmse:0.66021\tvalid-rmse:0.69998\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.726 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.717 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.717 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.717 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.718 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=504, ip=100.64.27.77)\u001b[0m [11:52:35] [17]\ttrain-rmse:1.06893\tvalid-rmse:1.05945\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:52:37] [35]\ttrain-rmse:0.65358\tvalid-rmse:0.69478\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=504, ip=100.64.27.77)\u001b[0m [11:52:38] [18]\ttrain-rmse:1.06434\tvalid-rmse:1.05527\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.732 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:52:40] [36]\ttrain-rmse:0.64487\tvalid-rmse:0.68699\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.725 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=504, ip=100.64.27.77)\u001b[0m [11:52:42] [19]\ttrain-rmse:1.05956\tvalid-rmse:1.05086\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.734 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:52:44] [42]\ttrain-rmse:0.86826\tvalid-rmse:0.87120\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.729 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:52:45] [37]\ttrain-rmse:0.63636\tvalid-rmse:0.68024\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:52:47] [43]\ttrain-rmse:0.86301\tvalid-rmse:0.86639\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:52:49] [38]\ttrain-rmse:0.62719\tvalid-rmse:0.67219\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:52:51] [44]\ttrain-rmse:0.85876\tvalid-rmse:0.86251\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 1 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 11:52:51. Total running time: 3min 38s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: e6f7faf6 with valid-rmse=0.6869870262417075 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.027922831871879127, 'max_depth': 8, 'min_child_weight': 0.035439580412438214, 'subsample': 0.7197886829704874, 'colsample_bytree': 0.6994715912141354, 'lambda': 0.0020630616467057017, 'alpha': 0.0027673015151075727, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673       37            6.65244       0.64487        0.686987 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   RUNNING        0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        43            4.06368       0.868257       0.871205 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   RUNNING        0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         19            5.30761       1.06434        1.05527  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.726 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:52:52] [39]\ttrain-rmse:0.61940\tvalid-rmse:0.66624\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.722 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.722 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.722 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.722 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:52:54] [45]\ttrain-rmse:0.85360\tvalid-rmse:0.85791\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:52:56] [40]\ttrain-rmse:0.61079\tvalid-rmse:0.65911\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🏃 View run XGBoostTrainer_b837ab13 at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265/runs/2f0f0b31826c49298220c4e4d87d2a91\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🧪 View experiment at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_b837ab13 completed after 20 iterations at 2025-09-01 11:52:58. Total running time: 3min 46s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_b837ab13 result             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ checkpoint_dir_name                              │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_this_iter_s                         0.00279 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_total_s                             5.31041 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ training_iteration                            20 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ train-rmse                               1.05956 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ valid-rmse                               1.05086 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:53:00] [46]\ttrain-rmse:0.84884\tvalid-rmse:0.85362\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.796 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:53:02] [41]\ttrain-rmse:0.60427\tvalid-rmse:0.65437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_f3a0bb1b started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_f3a0bb1b config                          │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/alpha                                 2.95444322054815 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/colsample_bytree                    0.9660738336222413 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eta                               0.010249052916635375 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eval_metric                                       rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/lambda                             0.14331221055053908 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/max_depth                                            7 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/min_child_weight                    1.0684315794200065 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/nthread                                              1 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/objective                             reg:squarederror │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/subsample                           0.9081188823073488 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/tree_method                                       hist │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=806, ip=100.64.8.234)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=806, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=852) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=806, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=853) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=806, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=854) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=806, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=855) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.730 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:53:05] [42]\ttrain-rmse:0.59718\tvalid-rmse:0.64915\n",
      "\u001b[36m(RayTrainWorker pid=852, ip=100.64.8.234)\u001b[0m [11:53:05] Task [xgboost.ray-rank=00000000]:7a42597a5b99529f0091f0d304000000 got rank 0\n",
      "\u001b[36m(RayTrainWorker pid=855, ip=100.64.8.234)\u001b[0m [11:53:05] Task [xgboost.ray-rank=00000003]:b22ea73934282f5a75af615604000000 got rank 3\n",
      "\u001b[36m(RayTrainWorker pid=854, ip=100.64.8.234)\u001b[0m [11:53:05] Task [xgboost.ray-rank=00000002]:ecf19f1d24775551728e57fb04000000 got rank 2\n",
      "\u001b[36m(RayTrainWorker pid=853, ip=100.64.8.234)\u001b[0m [11:53:05] Task [xgboost.ray-rank=00000001]:4874e80e1c86a52f84487b4f04000000 got rank 1\n",
      "\u001b[36m(SplitCoordinator pid=1016, ip=100.64.8.234)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=1016, ip=100.64.8.234)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:53:06] [47]\ttrain-rmse:0.84495\tvalid-rmse:0.85010\n",
      "\u001b[36m(SplitCoordinator pid=1017, ip=100.64.8.234)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=1017, ip=100.64.8.234)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=806, ip=100.64.8.234)\u001b[0m [11:53:08] [0]\ttrain-rmse:1.14941\tvalid-rmse:1.13385\n",
      "\u001b[36m(XGBoostTrainer pid=806, ip=100.64.8.234)\u001b[0m [11:53:08] [1]\ttrain-rmse:1.14136\tvalid-rmse:1.12626\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.879 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.880 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.880 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.880 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:53:08] [43]\ttrain-rmse:0.59082\tvalid-rmse:0.64456\n",
      "\u001b[36m(XGBoostTrainer pid=806, ip=100.64.8.234)\u001b[0m [11:53:10] [2]\ttrain-rmse:1.13338\tvalid-rmse:1.11871\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.679 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.679 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.679 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.680 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:53:12] [48]\ttrain-rmse:0.84010\tvalid-rmse:0.84574\n",
      "\u001b[36m(XGBoostTrainer pid=806, ip=100.64.8.234)\u001b[0m [11:53:13] [3]\ttrain-rmse:1.12557\tvalid-rmse:1.11134\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.734 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:53:15] [49]\ttrain-rmse:0.83524\tvalid-rmse:0.84130\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.723 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:53:17] [44]\ttrain-rmse:0.58390\tvalid-rmse:0.63846\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.723 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:53:19] [50]\ttrain-rmse:0.83043\tvalid-rmse:0.83695\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:53:20] [45]\ttrain-rmse:0.57776\tvalid-rmse:0.63386\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=806, ip=100.64.8.234)\u001b[0m [11:53:22] [4]\ttrain-rmse:1.11754\tvalid-rmse:1.10374\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 2 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 11:53:22. Total running time: 4min 10s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: e6f7faf6 with valid-rmse=0.6445569284128869 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.027922831871879127, 'max_depth': 8, 'min_child_weight': 0.035439580412438214, 'subsample': 0.7197886829704874, 'colsample_bytree': 0.6994715912141354, 'lambda': 0.0020630616467057017, 'alpha': 0.0027673015151075727, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673       44            6.67265       0.590821       0.644557 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   RUNNING        0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        49            4.08021       0.840098       0.845744 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   RUNNING        0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444          3            5.30156       1.13338        1.11871  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:53:24] [46]\ttrain-rmse:0.57266\tvalid-rmse:0.63041\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.716 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.716 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.716 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.716 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=806, ip=100.64.8.234)\u001b[0m [11:53:26] [5]\ttrain-rmse:1.10976\tvalid-rmse:1.09645\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.715 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.715 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.715 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.715 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:53:27] [47]\ttrain-rmse:0.56697\tvalid-rmse:0.62625\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.737 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=806, ip=100.64.8.234)\u001b[0m [11:53:29] [6]\ttrain-rmse:1.10232\tvalid-rmse:1.08950\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:53:31] [48]\ttrain-rmse:0.56140\tvalid-rmse:0.62263\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:53:32] [51]\ttrain-rmse:0.82551\tvalid-rmse:0.83240\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.739 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.732 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:53:34] [49]\ttrain-rmse:0.55551\tvalid-rmse:0.61841\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:53:36] [52]\ttrain-rmse:0.82109\tvalid-rmse:0.82842\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.777 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:53:38] [50]\ttrain-rmse:0.54973\tvalid-rmse:0.61441\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.727 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:53:39] [53]\ttrain-rmse:0.81684\tvalid-rmse:0.82448\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.709 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.710 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.710 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.710 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=806, ip=100.64.8.234)\u001b[0m [11:53:41] [7]\ttrain-rmse:1.09453\tvalid-rmse:1.08207\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:53:43] [51]\ttrain-rmse:0.54447\tvalid-rmse:0.61068\n",
      "\u001b[36m(XGBoostTrainer pid=806, ip=100.64.8.234)\u001b[0m [11:53:45] [8]\ttrain-rmse:1.08739\tvalid-rmse:1.07556\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.731 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:53:46] [52]\ttrain-rmse:0.53825\tvalid-rmse:0.60556\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.737 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=806, ip=100.64.8.234)\u001b[0m [11:53:48] [9]\ttrain-rmse:1.07980\tvalid-rmse:1.06842\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.716 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.717 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.717 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.717 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:53:50] [53]\ttrain-rmse:0.53241\tvalid-rmse:0.60075\n",
      "\u001b[36m(XGBoostTrainer pid=806, ip=100.64.8.234)\u001b[0m [11:53:52] [10]\ttrain-rmse:1.07263\tvalid-rmse:1.06179\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:53:53] [54]\ttrain-rmse:0.52870\tvalid-rmse:0.59810\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 2 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 11:53:53. Total running time: 4min 41s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: e6f7faf6 with valid-rmse=0.6055572646853986 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.027922831871879127, 'max_depth': 8, 'min_child_weight': 0.035439580412438214, 'subsample': 0.7197886829704874, 'colsample_bytree': 0.6994715912141354, 'lambda': 0.0020630616467057017, 'alpha': 0.0027673015151075727, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673       53            6.6973        0.538253       0.605557 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   RUNNING        0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        52            4.08856       0.825511       0.832397 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   RUNNING        0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444          9            5.31848       1.08739        1.07556  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=806, ip=100.64.8.234)\u001b[0m [11:53:55] [11]\ttrain-rmse:1.06527\tvalid-rmse:1.05488\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:53:57] [54]\ttrain-rmse:0.81324\tvalid-rmse:0.82103\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.809 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.809 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.809 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.809 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=806, ip=100.64.8.234)\u001b[0m [11:53:59] [12]\ttrain-rmse:1.05832\tvalid-rmse:1.04847\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:54:00] [55]\ttrain-rmse:0.80871\tvalid-rmse:0.81672\n",
      "\u001b[36m(XGBoostTrainer pid=806, ip=100.64.8.234)\u001b[0m [11:54:02] [13]\ttrain-rmse:1.05139\tvalid-rmse:1.04203\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.784 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.725 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:54:04] [56]\ttrain-rmse:0.80432\tvalid-rmse:0.81272\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:54:06] [55]\ttrain-rmse:0.52415\tvalid-rmse:0.59506\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.731 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:54:07] [56]\ttrain-rmse:0.51925\tvalid-rmse:0.59173\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:54:09] [57]\ttrain-rmse:0.80020\tvalid-rmse:0.80909\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.721 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.721 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.721 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.721 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:54:11] [57]\ttrain-rmse:0.51575\tvalid-rmse:0.58944\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:54:13] [58]\ttrain-rmse:0.79585\tvalid-rmse:0.80515\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.732 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=806, ip=100.64.8.234)\u001b[0m [11:54:14] [14]\ttrain-rmse:1.04497\tvalid-rmse:1.03595\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:54:16] [58]\ttrain-rmse:0.51145\tvalid-rmse:0.58651\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=806, ip=100.64.8.234)\u001b[0m [11:54:18] [15]\ttrain-rmse:1.03785\tvalid-rmse:1.02926\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:54:20] [59]\ttrain-rmse:0.79162\tvalid-rmse:0.80138\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:54:21] [59]\ttrain-rmse:0.50714\tvalid-rmse:0.58375\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=806, ip=100.64.8.234)\u001b[0m [11:54:23] [16]\ttrain-rmse:1.03100\tvalid-rmse:1.02296\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.726 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:54:25] [60]\ttrain-rmse:0.50301\tvalid-rmse:0.58125\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.745 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 2 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 11:54:25. Total running time: 5min 13s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: e6f7faf6 with valid-rmse=0.5865106303828943 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.027922831871879127, 'max_depth': 8, 'min_child_weight': 0.035439580412438214, 'subsample': 0.7197886829704874, 'colsample_bytree': 0.6994715912141354, 'lambda': 0.0020630616467057017, 'alpha': 0.0027673015151075727, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673       59            6.75647       0.511445       0.586511 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   RUNNING        0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        58            4.10515       0.800196       0.809087 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   RUNNING        0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         15            5.3351        1.04497        1.03595  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=806, ip=100.64.8.234)\u001b[0m [11:54:27] [17]\ttrain-rmse:1.02475\tvalid-rmse:1.01703\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:54:28] [61]\ttrain-rmse:0.49980\tvalid-rmse:0.57941\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=806, ip=100.64.8.234)\u001b[0m [11:54:30] [18]\ttrain-rmse:1.01822\tvalid-rmse:1.01101\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.877 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.878 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.878 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.878 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:54:32] [62]\ttrain-rmse:0.49628\tvalid-rmse:0.57755\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=806, ip=100.64.8.234)\u001b[0m [11:54:34] [19]\ttrain-rmse:1.01147\tvalid-rmse:1.00470\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:54:36] [63]\ttrain-rmse:0.49185\tvalid-rmse:0.57419\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=306, ip=100.64.25.122)\u001b[0m [11:54:37] [60]\ttrain-rmse:0.78745\tvalid-rmse:0.79764\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🏃 View run XGBoostTrainer_5f9c4ad7 at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265/runs/585c1e5fe06c4a8fa24c7a4250ed1891\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🧪 View experiment at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_5f9c4ad7 completed after 60 iterations at 2025-09-01 11:54:39. Total running time: 5min 27s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_5f9c4ad7 result             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ checkpoint_dir_name                              │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_this_iter_s                         0.00283 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_total_s                             4.11066 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ training_iteration                            60 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ train-rmse                               0.79162 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ valid-rmse                               0.80138 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=806, ip=100.64.8.234)\u001b[0m [11:54:41] [20]\ttrain-rmse:1.00493\tvalid-rmse:0.99869\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:54:43] [64]\ttrain-rmse:0.48749\tvalid-rmse:0.57087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_6281491e started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_6281491e config                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/alpha                              0.012042510141950458 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/colsample_bytree                     0.9927549016852539 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eta                               0.0029818937931162907 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eval_metric                                        rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/lambda                                2.511096753631646 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/max_depth                                             7 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/min_child_weight                   0.012143896009482793 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/nthread                                               1 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/objective                              reg:squarederror │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/subsample                            0.9601269347979653 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/tree_method                                        hist │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=1053, ip=100.64.27.77)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=1053, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=1099) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=1053, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=1100) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=1053, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=1101) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=1053, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=1102) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.735 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:54:46] [65]\ttrain-rmse:0.48294\tvalid-rmse:0.56743\n",
      "\u001b[36m(RayTrainWorker pid=1099, ip=100.64.27.77)\u001b[0m [11:54:46] Task [xgboost.ray-rank=00000000]:fb5a38bc9df4cbf1a4f949b304000000 got rank 0\n",
      "\u001b[36m(RayTrainWorker pid=1101, ip=100.64.27.77)\u001b[0m [11:54:46] Task [xgboost.ray-rank=00000002]:c5b358f03d168893e693c72104000000 got rank 2\n",
      "\u001b[36m(RayTrainWorker pid=1102, ip=100.64.27.77)\u001b[0m [11:54:46] Task [xgboost.ray-rank=00000003]:744a6ad3bf40d46853eb916e04000000 got rank 3\n",
      "\u001b[36m(RayTrainWorker pid=1100, ip=100.64.27.77)\u001b[0m [11:54:46] Task [xgboost.ray-rank=00000001]:ef83ee168ea5b8e63f74956404000000 got rank 1\n",
      "\u001b[36m(SplitCoordinator pid=1263, ip=100.64.27.77)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=1263, ip=100.64.27.77)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🏃 View run XGBoostTrainer_f3a0bb1b at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265/runs/25db572aed4349fb87253ad0df5e436f\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🧪 View experiment at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_f3a0bb1b completed after 20 iterations at 2025-09-01 11:54:48. Total running time: 5min 36s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_f3a0bb1b result             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ checkpoint_dir_name                              │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_this_iter_s                         0.00297 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_total_s                             5.34938 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ training_iteration                            20 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ train-rmse                               1.01147 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ valid-rmse                                1.0047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SplitCoordinator pid=1264, ip=100.64.27.77)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=1264, ip=100.64.27.77)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=1053, ip=100.64.27.77)\u001b[0m [11:54:50] [0]\ttrain-rmse:1.15510\tvalid-rmse:1.13920\n",
      "\u001b[36m(XGBoostTrainer pid=1053, ip=100.64.27.77)\u001b[0m [11:54:50] [1]\ttrain-rmse:1.15271\tvalid-rmse:1.13694\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:54:50] [66]\ttrain-rmse:0.47859\tvalid-rmse:0.56423\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.735 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.704 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.704 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.704 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.704 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1053, ip=100.64.27.77)\u001b[0m [11:54:52] [2]\ttrain-rmse:1.15035\tvalid-rmse:1.13473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_1ef99b81 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_1ef99b81 config                          │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/alpha                             0.027612640840478292 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/colsample_bytree                     0.802389171528815 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eta                                0.07611298258734957 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eval_metric                                       rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/lambda                             0.11148202293421741 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/max_depth                                            6 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/min_child_weight                   0.01762990058290712 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/nthread                                              1 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/objective                             reg:squarederror │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/subsample                            0.857262197348321 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/tree_method                                       hist │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=1256) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=1257) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=1258) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=1259) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1053, ip=100.64.27.77)\u001b[0m [11:54:55] [3]\ttrain-rmse:1.14801\tvalid-rmse:1.13254\n",
      "\u001b[36m(RayTrainWorker pid=1256, ip=100.64.8.234)\u001b[0m [11:54:55] Task [xgboost.ray-rank=00000000]:0612c6af847a6074d70123a604000000 got rank 0\n",
      "\u001b[36m(RayTrainWorker pid=1258, ip=100.64.8.234)\u001b[0m [11:54:55] Task [xgboost.ray-rank=00000002]:d3bd160bb32fbadcd7c2ebaf04000000 got rank 2\n",
      "\u001b[36m(RayTrainWorker pid=1257, ip=100.64.8.234)\u001b[0m [11:54:55] Task [xgboost.ray-rank=00000001]:76290c0ba76b879c2233465204000000 got rank 1\n",
      "\u001b[36m(RayTrainWorker pid=1259, ip=100.64.8.234)\u001b[0m [11:54:55] Task [xgboost.ray-rank=00000003]:77e4fe9902ebee5dbb20d33204000000 got rank 3\n",
      "\u001b[36m(SplitCoordinator pid=1420, ip=100.64.8.234)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=1420, ip=100.64.8.234)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(SplitCoordinator pid=1421, ip=100.64.8.234)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=1421, ip=100.64.8.234)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:54:57] [67]\ttrain-rmse:0.47590\tvalid-rmse:0.56240\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:54:57] [0]\ttrain-rmse:1.09970\tvalid-rmse:1.08692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 4 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 11:54:57. Total running time: 5min 44s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: e6f7faf6 with valid-rmse=0.5674258500508078 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.027922831871879127, 'max_depth': 8, 'min_child_weight': 0.035439580412438214, 'subsample': 0.7197886829704874, 'colsample_bytree': 0.6994715912141354, 'lambda': 0.0020630616467057017, 'alpha': 0.0027673015151075727, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673       66            6.77568       0.482935       0.567426 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   RUNNING        0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425        2            5.3698        1.15271        1.13694  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1053, ip=100.64.27.77)\u001b[0m [11:54:58] [4]\ttrain-rmse:1.14566\tvalid-rmse:1.13034\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:55:00] [1]\ttrain-rmse:1.05716\tvalid-rmse:1.04621\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.677 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.677 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.677 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.677 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.790 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1053, ip=100.64.27.77)\u001b[0m [11:55:02] [5]\ttrain-rmse:1.14328\tvalid-rmse:1.12811\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:55:04] [2]\ttrain-rmse:1.01508\tvalid-rmse:1.00662\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.732 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1053, ip=100.64.27.77)\u001b[0m [11:55:05] [6]\ttrain-rmse:1.14098\tvalid-rmse:1.12597\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:55:07] [68]\ttrain-rmse:0.47147\tvalid-rmse:0.55907\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.729 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:55:09] [3]\ttrain-rmse:0.96820\tvalid-rmse:0.96295\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:55:11] [69]\ttrain-rmse:0.46830\tvalid-rmse:0.55716\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.730 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.742 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1053, ip=100.64.27.77)\u001b[0m [11:55:12] [7]\ttrain-rmse:1.13859\tvalid-rmse:1.12369\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.733 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:55:14] [4]\ttrain-rmse:0.92566\tvalid-rmse:0.92393\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.730 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1053, ip=100.64.27.77)\u001b[0m [11:55:16] [8]\ttrain-rmse:1.13638\tvalid-rmse:1.12167\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:55:17] [5]\ttrain-rmse:0.89374\tvalid-rmse:0.89473\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.733 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.731 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1053, ip=100.64.27.77)\u001b[0m [11:55:19] [9]\ttrain-rmse:1.13404\tvalid-rmse:1.11948\n",
      "\u001b[36m(XGBoostTrainer pid=1053, ip=100.64.27.77)\u001b[0m [11:55:21] [10]\ttrain-rmse:1.13176\tvalid-rmse:1.11734\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:55:23] [6]\ttrain-rmse:0.85837\tvalid-rmse:0.86322\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.736 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:55:24] [70]\ttrain-rmse:0.46564\tvalid-rmse:0.55585\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.717 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.717 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.717 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.717 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:55:26] [7]\ttrain-rmse:0.82323\tvalid-rmse:0.83104\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.726 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 4 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 11:55:28. Total running time: 6min 16s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: e6f7faf6 with valid-rmse=0.559074124378185 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.027922831871879127, 'max_depth': 8, 'min_child_weight': 0.035439580412438214, 'subsample': 0.7197886829704874, 'colsample_bytree': 0.6994715912141354, 'lambda': 0.0020630616467057017, 'alpha': 0.0027673015151075727, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673       69            6.78392       0.471466       0.559074 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   RUNNING        0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       10            5.3927        1.13404        1.11948  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126        7            3.68271       0.858368       0.86322  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1053, ip=100.64.27.77)\u001b[0m [11:55:28] [11]\ttrain-rmse:1.12945\tvalid-rmse:1.11518\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:55:30] [71]\ttrain-rmse:0.46183\tvalid-rmse:0.55275\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.728 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:55:31] [8]\ttrain-rmse:0.79278\tvalid-rmse:0.80341\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.742 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:55:33] [72]\ttrain-rmse:0.45807\tvalid-rmse:0.55017\n",
      "\u001b[36m(XGBoostTrainer pid=1053, ip=100.64.27.77)\u001b[0m [11:55:35] [12]\ttrain-rmse:1.12720\tvalid-rmse:1.11307\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.729 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:55:37] [73]\ttrain-rmse:0.45449\tvalid-rmse:0.54769\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.735 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.722 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.722 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.722 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.722 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1053, ip=100.64.27.77)\u001b[0m [11:55:38] [13]\ttrain-rmse:1.12496\tvalid-rmse:1.11096\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:55:40] [74]\ttrain-rmse:0.45216\tvalid-rmse:0.54628\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.697 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.698 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.698 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.698 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:55:42] [75]\ttrain-rmse:0.44891\tvalid-rmse:0.54408\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.718 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.718 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.718 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.718 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.707 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.707 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.707 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.707 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1053, ip=100.64.27.77)\u001b[0m [11:55:43] [14]\ttrain-rmse:1.12285\tvalid-rmse:1.10894\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:55:45] [9]\ttrain-rmse:0.76421\tvalid-rmse:0.77728\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.728 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1053, ip=100.64.27.77)\u001b[0m [11:55:47] [15]\ttrain-rmse:1.12051\tvalid-rmse:1.10672\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.707 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.707 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.707 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.707 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:55:49] [10]\ttrain-rmse:0.73937\tvalid-rmse:0.75576\n",
      "\u001b[36m(XGBoostTrainer pid=1053, ip=100.64.27.77)\u001b[0m [11:55:51] [16]\ttrain-rmse:1.11824\tvalid-rmse:1.10460\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.913 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.914 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.914 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.914 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1053, ip=100.64.27.77)\u001b[0m [11:55:52] [17]\ttrain-rmse:1.11635\tvalid-rmse:1.10282\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:55:54] [76]\ttrain-rmse:0.44529\tvalid-rmse:0.54132\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.710 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.710 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.710 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.710 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:55:56] [11]\ttrain-rmse:0.71817\tvalid-rmse:0.73781\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:55:58] [77]\ttrain-rmse:0.44314\tvalid-rmse:0.54040\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.735 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:55:59] [12]\ttrain-rmse:0.69878\tvalid-rmse:0.72170\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.722 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.722 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.722 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.722 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 4 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 11:55:59. Total running time: 6min 47s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: e6f7faf6 with valid-rmse=0.5440823241932259 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.027922831871879127, 'max_depth': 8, 'min_child_weight': 0.035439580412438214, 'subsample': 0.7197886829704874, 'colsample_bytree': 0.6994715912141354, 'lambda': 0.0020630616467057017, 'alpha': 0.0027673015151075727, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673       76            6.80321       0.448908       0.544082 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   RUNNING        0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       16            5.41043       1.12051        1.10672  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126       12            3.69726       0.718168       0.737805 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:56:01] [78]\ttrain-rmse:0.44092\tvalid-rmse:0.53956\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.719 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.720 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.720 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.720 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:56:03] [13]\ttrain-rmse:0.68025\tvalid-rmse:0.70538\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.729 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:56:04] [79]\ttrain-rmse:0.43855\tvalid-rmse:0.53810\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:56:06] [14]\ttrain-rmse:0.66347\tvalid-rmse:0.69023\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.716 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.717 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.717 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.717 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:56:08] [80]\ttrain-rmse:0.43644\tvalid-rmse:0.53727\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.709 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.709 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.709 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.709 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:56:10] [15]\ttrain-rmse:0.64672\tvalid-rmse:0.67517\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.712 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.713 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.713 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.713 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1053, ip=100.64.27.77)\u001b[0m [11:56:11] [18]\ttrain-rmse:1.11413\tvalid-rmse:1.10075\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.710 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.710 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.710 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.710 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1053, ip=100.64.27.77)\u001b[0m [11:56:13] [19]\ttrain-rmse:1.11182\tvalid-rmse:1.09856\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.697 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.698 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.698 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.698 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:56:15] [16]\ttrain-rmse:0.63152\tvalid-rmse:0.66198\n",
      "\u001b[36m(XGBoostTrainer pid=1053, ip=100.64.27.77)\u001b[0m [11:56:16] [20]\ttrain-rmse:1.10958\tvalid-rmse:1.09648\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.710 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.710 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.710 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.711 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.727 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:56:18] [17]\ttrain-rmse:0.62279\tvalid-rmse:0.65427\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.722 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.723 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:56:20] [81]\ttrain-rmse:0.43418\tvalid-rmse:0.53627\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:56:22] [18]\ttrain-rmse:0.61109\tvalid-rmse:0.64558\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.719 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.720 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.720 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.720 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:56:23] [19]\ttrain-rmse:0.59749\tvalid-rmse:0.63383\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.696 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.697 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.697 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.697 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🏃 View run XGBoostTrainer_6281491e at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265/runs/daff2ae895424873970baceb023cac91\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🧪 View experiment at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_6281491e completed after 20 iterations at 2025-09-01 11:56:26. Total running time: 7min 13s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_6281491e result             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ checkpoint_dir_name                              │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_this_iter_s                          0.0029 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_total_s                             5.42193 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ training_iteration                            20 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ train-rmse                               1.11182 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ valid-rmse                               1.09856 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:56:28] [20]\ttrain-rmse:0.58761\tvalid-rmse:0.62540\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 2.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 2.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 2.499 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 2.499 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:56:30] [82]\ttrain-rmse:0.43102\tvalid-rmse:0.53380\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 2 RUNNING | 5 TERMINATED | 1 PENDING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 11:56:30. Total running time: 7min 18s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 16.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: e6f7faf6 with valid-rmse=0.5372746770370104 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.027922831871879127, 'max_depth': 8, 'min_child_weight': 0.035439580412438214, 'subsample': 0.7197886829704874, 'colsample_bytree': 0.6994715912141354, 'lambda': 0.0020630616467057017, 'alpha': 0.0027673015151075727, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673       81            6.81704       0.43644        0.537275 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126       20            3.71981       0.597492       0.633833 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   PENDING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261                                                             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.721 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.722 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.722 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.722 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:56:32] [21]\ttrain-rmse:0.57599\tvalid-rmse:0.61401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_ca919a62 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_ca919a62 config                         │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/alpha                              1.7026072301402462 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/colsample_bytree                   0.7011982798079494 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eta                               0.04092727091511802 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eval_metric                                      rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/lambda                              0.004974847839491 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/max_depth                                          10 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/min_child_weight                   2.6961269193856783 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/nthread                                             1 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/objective                            reg:squarederror │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/subsample                          0.7423996250457794 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/tree_method                                      hist │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m - (node_id=aa7a1be9217ecfac6d99669d9eee6a9281027e3894db76bdace3f284, ip=100.64.25.122, pid=915) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m - (node_id=aa7a1be9217ecfac6d99669d9eee6a9281027e3894db76bdace3f284, ip=100.64.25.122, pid=916) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m - (node_id=aa7a1be9217ecfac6d99669d9eee6a9281027e3894db76bdace3f284, ip=100.64.25.122, pid=917) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m - (node_id=aa7a1be9217ecfac6d99669d9eee6a9281027e3894db76bdace3f284, ip=100.64.25.122, pid=918) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:56:35] [83]\ttrain-rmse:0.42872\tvalid-rmse:0.53257\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.717 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.717 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.717 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.717 s, which may be a performance bottleneck.\n",
      "\u001b[36m(RayTrainWorker pid=916, ip=100.64.25.122)\u001b[0m [11:56:35] Task [xgboost.ray-rank=00000001]:cc711de126bc37dd69ee060904000000 got rank 1\n",
      "\u001b[36m(RayTrainWorker pid=915, ip=100.64.25.122)\u001b[0m [11:56:35] Task [xgboost.ray-rank=00000000]:e8205296386a50b601d6517504000000 got rank 0\n",
      "\u001b[36m(RayTrainWorker pid=917, ip=100.64.25.122)\u001b[0m [11:56:35] Task [xgboost.ray-rank=00000002]:56701f0a45e6dfb526889a4004000000 got rank 2\n",
      "\u001b[36m(RayTrainWorker pid=918, ip=100.64.25.122)\u001b[0m [11:56:35] Task [xgboost.ray-rank=00000003]:8ad7f786e9d9afc819f2e9c604000000 got rank 3\n",
      "\u001b[36m(SplitCoordinator pid=1080, ip=100.64.25.122)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=1080, ip=100.64.25.122)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.731 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:56:36] [22]\ttrain-rmse:0.56419\tvalid-rmse:0.60351\n",
      "\u001b[36m(SplitCoordinator pid=1081, ip=100.64.25.122)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=1081, ip=100.64.25.122)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.737 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:56:38] [84]\ttrain-rmse:0.42711\tvalid-rmse:0.53183\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:56:38] [0]\ttrain-rmse:1.12288\tvalid-rmse:1.10994\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.726 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:56:40] [23]\ttrain-rmse:0.55677\tvalid-rmse:0.59844\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:56:41] [1]\ttrain-rmse:1.09458\tvalid-rmse:1.08540\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.670 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.671 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.671 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.671 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.728 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:56:43] [85]\ttrain-rmse:0.42461\tvalid-rmse:0.53061\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.712 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.712 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.713 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.713 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:56:45] [86]\ttrain-rmse:0.42284\tvalid-rmse:0.52984\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.725 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:56:47] [2]\ttrain-rmse:1.06916\tvalid-rmse:1.06272\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:56:48] [87]\ttrain-rmse:0.42137\tvalid-rmse:0.52911\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.736 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:56:50] [3]\ttrain-rmse:1.04352\tvalid-rmse:1.04000\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.735 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:56:52] [88]\ttrain-rmse:0.41867\tvalid-rmse:0.52694\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.730 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:56:54] [4]\ttrain-rmse:1.01182\tvalid-rmse:1.01070\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.730 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:56:55] [5]\ttrain-rmse:0.98508\tvalid-rmse:0.98551\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:56:57] [89]\ttrain-rmse:0.41584\tvalid-rmse:0.52484\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.736 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.727 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:56:59] [6]\ttrain-rmse:0.95797\tvalid-rmse:0.96158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 11:57:00. Total running time: 7min 48s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: e6f7faf6 with valid-rmse=0.529110553082319 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.027922831871879127, 'max_depth': 8, 'min_child_weight': 0.035439580412438214, 'subsample': 0.7197886829704874, 'colsample_bytree': 0.6994715912141354, 'lambda': 0.0020630616467057017, 'alpha': 0.0027673015151075727, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673       88            6.83622       0.421366       0.529111 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126       24            3.73106       0.556773       0.598437 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261          6            5.4003        0.985079       0.985506 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.734 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:57:00] [24]\ttrain-rmse:0.54584\tvalid-rmse:0.58882\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.785 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:57:02] [7]\ttrain-rmse:0.93340\tvalid-rmse:0.93845\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.717 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.718 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.718 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.718 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:57:04] [25]\ttrain-rmse:0.53968\tvalid-rmse:0.58483\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.710 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.710 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.710 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.710 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:57:06] [8]\ttrain-rmse:0.90603\tvalid-rmse:0.91309\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:57:07] [90]\ttrain-rmse:0.41371\tvalid-rmse:0.52363\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.742 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:57:09] [9]\ttrain-rmse:0.88351\tvalid-rmse:0.89209\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.729 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:57:11] [91]\ttrain-rmse:0.41197\tvalid-rmse:0.52294\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:57:13] [10]\ttrain-rmse:0.86086\tvalid-rmse:0.87242\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.882 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.883 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.883 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.883 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.733 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:57:15] [26]\ttrain-rmse:0.53391\tvalid-rmse:0.58056\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:57:16] [11]\ttrain-rmse:0.83677\tvalid-rmse:0.85058\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:57:18] [92]\ttrain-rmse:0.41064\tvalid-rmse:0.52246\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.727 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:57:20] [12]\ttrain-rmse:0.81694\tvalid-rmse:0.83365\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.729 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:57:21] [27]\ttrain-rmse:0.52346\tvalid-rmse:0.57119\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:57:23] [93]\ttrain-rmse:0.40969\tvalid-rmse:0.52189\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.745 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:57:25] [28]\ttrain-rmse:0.51868\tvalid-rmse:0.56780\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.703 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.704 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.704 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.704 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:57:27] [94]\ttrain-rmse:0.40805\tvalid-rmse:0.52139\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:57:28] [13]\ttrain-rmse:0.79689\tvalid-rmse:0.81590\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:57:30] [95]\ttrain-rmse:0.40656\tvalid-rmse:0.52090\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:57:32] [14]\ttrain-rmse:0.78121\tvalid-rmse:0.80226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 11:57:32. Total running time: 8min 20s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: e6f7faf6 with valid-rmse=0.5218886553187233 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.027922831871879127, 'max_depth': 8, 'min_child_weight': 0.035439580412438214, 'subsample': 0.7197886829704874, 'colsample_bytree': 0.6994715912141354, 'lambda': 0.0020630616467057017, 'alpha': 0.0027673015151075727, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673       94            6.85237       0.409691       0.521889 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126       28            3.74359       0.523457       0.571189 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261         14            5.42287       0.796885       0.815898 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.792 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:57:34] [29]\ttrain-rmse:0.51257\tvalid-rmse:0.56272\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.787 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:57:36] [15]\ttrain-rmse:0.76126\tvalid-rmse:0.78481\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.785 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:57:37] [30]\ttrain-rmse:0.50729\tvalid-rmse:0.55882\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:57:39] [16]\ttrain-rmse:0.74359\tvalid-rmse:0.77006\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.786 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:57:41] [96]\ttrain-rmse:0.40407\tvalid-rmse:0.51904\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:57:43] [17]\ttrain-rmse:0.73210\tvalid-rmse:0.76029\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:57:44] [31]\ttrain-rmse:0.50286\tvalid-rmse:0.55564\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:57:46] [18]\ttrain-rmse:0.72054\tvalid-rmse:0.75143\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.799 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:57:48] [32]\ttrain-rmse:0.49976\tvalid-rmse:0.55405\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.782 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:57:50] [19]\ttrain-rmse:0.70305\tvalid-rmse:0.73627\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:57:52] [33]\ttrain-rmse:0.49567\tvalid-rmse:0.55109\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:57:53] [20]\ttrain-rmse:0.68781\tvalid-rmse:0.72409\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:57:55] [34]\ttrain-rmse:0.49215\tvalid-rmse:0.54902\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:57:57] [97]\ttrain-rmse:0.40276\tvalid-rmse:0.51855\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.784 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.781 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:57:59] [35]\ttrain-rmse:0.48775\tvalid-rmse:0.54492\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.771 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:58:00] [21]\ttrain-rmse:0.67460\tvalid-rmse:0.71389\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:58:02] [36]\ttrain-rmse:0.48497\tvalid-rmse:0.54259\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.785 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 11:58:02. Total running time: 8min 50s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: e6f7faf6 with valid-rmse=0.5208954799559133 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.027922831871879127, 'max_depth': 8, 'min_child_weight': 0.035439580412438214, 'subsample': 0.7197886829704874, 'colsample_bytree': 0.6994715912141354, 'lambda': 0.0020630616467057017, 'alpha': 0.0027673015151075727, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673       96            6.85831       0.406564       0.520895 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126       36            3.7666        0.487746       0.544923 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261         21            5.44194       0.687813       0.724087 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:58:04] [22]\ttrain-rmse:0.65903\tvalid-rmse:0.70028\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:58:06] [37]\ttrain-rmse:0.48061\tvalid-rmse:0.53944\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:58:07] [23]\ttrain-rmse:0.64564\tvalid-rmse:0.68962\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:58:09] [38]\ttrain-rmse:0.47659\tvalid-rmse:0.53610\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:58:11] [98]\ttrain-rmse:0.40141\tvalid-rmse:0.51829\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.773 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:58:13] [39]\ttrain-rmse:0.47428\tvalid-rmse:0.53503\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:58:15] [99]\ttrain-rmse:0.39921\tvalid-rmse:0.51685\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:58:16] [40]\ttrain-rmse:0.47085\tvalid-rmse:0.53271\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:58:18] [100]\ttrain-rmse:0.39727\tvalid-rmse:0.51563\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.771 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:58:20] [41]\ttrain-rmse:0.46901\tvalid-rmse:0.53226\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:58:22] [24]\ttrain-rmse:0.63085\tvalid-rmse:0.67650\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:58:23] [42]\ttrain-rmse:0.46712\tvalid-rmse:0.53109\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.785 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:58:25] [25]\ttrain-rmse:0.61931\tvalid-rmse:0.66795\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:58:27] [43]\ttrain-rmse:0.46484\tvalid-rmse:0.52962\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:58:29] [26]\ttrain-rmse:0.60767\tvalid-rmse:0.65891\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.791 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:58:30] [44]\ttrain-rmse:0.46050\tvalid-rmse:0.52593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 11:58:32. Total running time: 9min 20s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: e6f7faf6 with valid-rmse=0.5182868945842927 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.027922831871879127, 'max_depth': 8, 'min_child_weight': 0.035439580412438214, 'subsample': 0.7197886829704874, 'colsample_bytree': 0.6994715912141354, 'lambda': 0.0020630616467057017, 'alpha': 0.0027673015151075727, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673       99            6.86649       0.401413       0.518287 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126       44            3.83794       0.464845       0.529617 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261         27            5.46046       0.607666       0.658907 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:58:32] [27]\ttrain-rmse:0.59551\tvalid-rmse:0.64838\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:58:34] [45]\ttrain-rmse:0.45771\tvalid-rmse:0.52416\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.934 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.935 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.935 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.935 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:58:36] [28]\ttrain-rmse:0.58591\tvalid-rmse:0.64144\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.789 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:58:38] [46]\ttrain-rmse:0.45630\tvalid-rmse:0.52344\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:58:39] [29]\ttrain-rmse:0.57406\tvalid-rmse:0.63110\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.745 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:58:41] [30]\ttrain-rmse:0.56514\tvalid-rmse:0.62489\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:58:43] [47]\ttrain-rmse:0.45432\tvalid-rmse:0.52247\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.745 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:58:45] [31]\ttrain-rmse:0.55629\tvalid-rmse:0.61839\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:58:46] [48]\ttrain-rmse:0.45278\tvalid-rmse:0.52177\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:58:48] [101]\ttrain-rmse:0.39580\tvalid-rmse:0.51481\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:58:50] [32]\ttrain-rmse:0.54803\tvalid-rmse:0.61281\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:58:52] [102]\ttrain-rmse:0.39442\tvalid-rmse:0.51432\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.843 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.843 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.843 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.843 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:58:54] [49]\ttrain-rmse:0.45111\tvalid-rmse:0.52132\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:58:55] [103]\ttrain-rmse:0.39236\tvalid-rmse:0.51274\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:58:57] [50]\ttrain-rmse:0.44996\tvalid-rmse:0.52108\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:58:59] [104]\ttrain-rmse:0.39096\tvalid-rmse:0.51234\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.777 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:59:01] [51]\ttrain-rmse:0.44731\tvalid-rmse:0.51901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 11:59:02. Total running time: 9min 50s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: e6f7faf6 with valid-rmse=0.5143198162508081 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.027922831871879127, 'max_depth': 8, 'min_child_weight': 0.035439580412438214, 'subsample': 0.7197886829704874, 'colsample_bytree': 0.6994715912141354, 'lambda': 0.0020630616467057017, 'alpha': 0.0027673015151075727, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      103            6.87769       0.394415       0.51432  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126       52            3.86004       0.447306       0.519008 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261         32            5.47405       0.556292       0.618385 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:59:02] [52]\ttrain-rmse:0.44474\tvalid-rmse:0.51771\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:59:04] [105]\ttrain-rmse:0.38970\tvalid-rmse:0.51191\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:59:06] [33]\ttrain-rmse:0.53826\tvalid-rmse:0.60543\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:59:08] [106]\ttrain-rmse:0.38739\tvalid-rmse:0.51017\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:59:09] [34]\ttrain-rmse:0.53007\tvalid-rmse:0.59980\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:59:11] [107]\ttrain-rmse:0.38606\tvalid-rmse:0.50965\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.729 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:59:13] [35]\ttrain-rmse:0.52378\tvalid-rmse:0.59533\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.725 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:59:15] [108]\ttrain-rmse:0.38450\tvalid-rmse:0.50867\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:59:16] [53]\ttrain-rmse:0.44212\tvalid-rmse:0.51589\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.727 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.717 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.717 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.718 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.718 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:59:18] [36]\ttrain-rmse:0.51497\tvalid-rmse:0.58777\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.725 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:59:20] [54]\ttrain-rmse:0.44090\tvalid-rmse:0.51535\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:59:22] [37]\ttrain-rmse:0.50758\tvalid-rmse:0.58277\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.926 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.926 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.926 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.926 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:59:24] [38]\ttrain-rmse:0.49869\tvalid-rmse:0.57540\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.720 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.720 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.720 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.721 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:59:25] [55]\ttrain-rmse:0.43981\tvalid-rmse:0.51494\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:59:27] [39]\ttrain-rmse:0.49209\tvalid-rmse:0.57099\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.734 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:59:29] [56]\ttrain-rmse:0.43877\tvalid-rmse:0.51477\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.733 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:59:30] [40]\ttrain-rmse:0.48471\tvalid-rmse:0.56555\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.723 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:59:32] [57]\ttrain-rmse:0.43785\tvalid-rmse:0.51445\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:59:34] [58]\ttrain-rmse:0.43620\tvalid-rmse:0.51322\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 11:59:34. Total running time: 10min 22s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: e6f7faf6 with valid-rmse=0.5101686482216911 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.027922831871879127, 'max_depth': 8, 'min_child_weight': 0.035439580412438214, 'subsample': 0.7197886829704874, 'colsample_bytree': 0.6994715912141354, 'lambda': 0.0020630616467057017, 'alpha': 0.0027673015151075727, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      107            6.88861       0.387385       0.510169 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126       58            3.87735       0.437846       0.514453 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261         40            5.49607       0.492087       0.570991 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:59:36] [41]\ttrain-rmse:0.47934\tvalid-rmse:0.56213\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:59:37] [59]\ttrain-rmse:0.43452\tvalid-rmse:0.51235\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:59:39] [42]\ttrain-rmse:0.47373\tvalid-rmse:0.55858\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:59:41] [60]\ttrain-rmse:0.43307\tvalid-rmse:0.51174\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:59:43] [43]\ttrain-rmse:0.46878\tvalid-rmse:0.55549\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:59:45] [61]\ttrain-rmse:0.43191\tvalid-rmse:0.51159\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:59:46] [44]\ttrain-rmse:0.46173\tvalid-rmse:0.54951\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:59:48] [62]\ttrain-rmse:0.43062\tvalid-rmse:0.51136\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:59:50] [109]\ttrain-rmse:0.38285\tvalid-rmse:0.50771\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [11:59:52] [63]\ttrain-rmse:0.42801\tvalid-rmse:0.50970\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:59:53] [45]\ttrain-rmse:0.45698\tvalid-rmse:0.54650\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:59:55] [46]\ttrain-rmse:0.45258\tvalid-rmse:0.54412\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.953 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.954 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.954 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.954 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [11:59:57] [110]\ttrain-rmse:0.38189\tvalid-rmse:0.50718\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [11:59:59] [47]\ttrain-rmse:0.44817\tvalid-rmse:0.54140\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.781 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:00:01] [111]\ttrain-rmse:0.38028\tvalid-rmse:0.50595\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:00:02] [48]\ttrain-rmse:0.44391\tvalid-rmse:0.53929\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.792 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:00:04] [112]\ttrain-rmse:0.37925\tvalid-rmse:0.50569\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:00:04. Total running time: 10min 52s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: e6f7faf6 with valid-rmse=0.5071750763016473 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.027922831871879127, 'max_depth': 8, 'min_child_weight': 0.035439580412438214, 'subsample': 0.7197886829704874, 'colsample_bytree': 0.6994715912141354, 'lambda': 0.0020630616467057017, 'alpha': 0.0027673015151075727, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      111            6.89959       0.38189        0.507175 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126       63            3.89128       0.430618       0.511359 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261         48            5.56285       0.448167       0.541396 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:00:06] [113]\ttrain-rmse:0.37831\tvalid-rmse:0.50526\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.736 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:00:08] [49]\ttrain-rmse:0.43964\tvalid-rmse:0.53656\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.733 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:00:09] [114]\ttrain-rmse:0.37638\tvalid-rmse:0.50372\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.730 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:00:11] [50]\ttrain-rmse:0.43534\tvalid-rmse:0.53420\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.727 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:00:13] [115]\ttrain-rmse:0.37530\tvalid-rmse:0.50356\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.725 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:00:15] [51]\ttrain-rmse:0.43161\tvalid-rmse:0.53196\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:00:16] [52]\ttrain-rmse:0.42626\tvalid-rmse:0.52786\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:00:18] [116]\ttrain-rmse:0.37405\tvalid-rmse:0.50310\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.722 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.723 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:00:20] [53]\ttrain-rmse:0.42128\tvalid-rmse:0.52425\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:00:22] [117]\ttrain-rmse:0.37303\tvalid-rmse:0.50286\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:00:23] [54]\ttrain-rmse:0.41840\tvalid-rmse:0.52249\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.728 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:00:25] [118]\ttrain-rmse:0.37124\tvalid-rmse:0.50169\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:00:27] [64]\ttrain-rmse:0.42594\tvalid-rmse:0.50822\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.735 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:00:28] [55]\ttrain-rmse:0.41516\tvalid-rmse:0.52091\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.718 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.718 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.718 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.718 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:00:30] [65]\ttrain-rmse:0.42342\tvalid-rmse:0.50613\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:00:32] [119]\ttrain-rmse:0.36982\tvalid-rmse:0.50099\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:00:34] [56]\ttrain-rmse:0.41179\tvalid-rmse:0.51905\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.722 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.723 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:00:35] [66]\ttrain-rmse:0.42185\tvalid-rmse:0.50524\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.742 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:00:35. Total running time: 11min 23s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: e6f7faf6 with valid-rmse=0.5028597197223792 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.027922831871879127, 'max_depth': 8, 'min_child_weight': 0.035439580412438214, 'subsample': 0.7197886829704874, 'colsample_bytree': 0.6994715912141354, 'lambda': 0.0020630616467057017, 'alpha': 0.0027673015151075727, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      118            6.9197        0.373025       0.50286  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126       66            3.89933       0.423424       0.506132 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261         56            5.59225       0.415156       0.52091  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:00:37] [67]\ttrain-rmse:0.42017\tvalid-rmse:0.50465\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:00:39] [57]\ttrain-rmse:0.40913\tvalid-rmse:0.51782\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:00:41] [120]\ttrain-rmse:0.36897\tvalid-rmse:0.50067\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:00:42] [58]\ttrain-rmse:0.40602\tvalid-rmse:0.51647\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:00:44] [121]\ttrain-rmse:0.36776\tvalid-rmse:0.50000\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:00:46] [59]\ttrain-rmse:0.40305\tvalid-rmse:0.51506\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:00:48] [60]\ttrain-rmse:0.40041\tvalid-rmse:0.51374\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:00:49] [122]\ttrain-rmse:0.36691\tvalid-rmse:0.49984\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:00:51] [61]\ttrain-rmse:0.39797\tvalid-rmse:0.51274\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:00:53] [123]\ttrain-rmse:0.36495\tvalid-rmse:0.49863\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.732 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.739 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:00:55] [62]\ttrain-rmse:0.39542\tvalid-rmse:0.51197\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:00:56] [68]\ttrain-rmse:0.41901\tvalid-rmse:0.50409\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:00:58] [69]\ttrain-rmse:0.41726\tvalid-rmse:0.50265\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.732 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:01:00] [63]\ttrain-rmse:0.39190\tvalid-rmse:0.50938\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.815 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.815 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.815 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.815 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:01:02] [124]\ttrain-rmse:0.36418\tvalid-rmse:0.49836\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:01:04] [64]\ttrain-rmse:0.38872\tvalid-rmse:0.50720\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.777 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:01:05] [125]\ttrain-rmse:0.36353\tvalid-rmse:0.49819\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:01:07] [65]\ttrain-rmse:0.38517\tvalid-rmse:0.50473\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.780 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:01:07. Total running time: 11min 55s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: e6f7faf6 with valid-rmse=0.49862885633450926 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.027922831871879127, 'max_depth': 8, 'min_child_weight': 0.035439580412438214, 'subsample': 0.7197886829704874, 'colsample_bytree': 0.6994715912141354, 'lambda': 0.0020630616467057017, 'alpha': 0.0027673015151075727, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      124            6.93681       0.364954       0.498629 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126       69            3.90811       0.419015       0.504086 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261         65            5.61962       0.388718       0.507199 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.777 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:01:09] [70]\ttrain-rmse:0.41559\tvalid-rmse:0.50132\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:01:11] [126]\ttrain-rmse:0.36267\tvalid-rmse:0.49795\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.776 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:01:12] [66]\ttrain-rmse:0.38225\tvalid-rmse:0.50296\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:01:14] [127]\ttrain-rmse:0.36178\tvalid-rmse:0.49767\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.773 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:01:16] [67]\ttrain-rmse:0.38020\tvalid-rmse:0.50202\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:01:18] [128]\ttrain-rmse:0.36089\tvalid-rmse:0.49749\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.916 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.917 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.917 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.917 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:01:20] [68]\ttrain-rmse:0.37695\tvalid-rmse:0.49979\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:01:21] [129]\ttrain-rmse:0.35966\tvalid-rmse:0.49676\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:01:23] [69]\ttrain-rmse:0.37488\tvalid-rmse:0.49908\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:01:25] [130]\ttrain-rmse:0.35873\tvalid-rmse:0.49656\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:01:27] [70]\ttrain-rmse:0.37305\tvalid-rmse:0.49843\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:01:28] [131]\ttrain-rmse:0.35717\tvalid-rmse:0.49531\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.776 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.784 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:01:30] [71]\ttrain-rmse:0.36999\tvalid-rmse:0.49589\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.795 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:01:32] [71]\ttrain-rmse:0.41432\tvalid-rmse:0.50052\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:01:34] [132]\ttrain-rmse:0.35635\tvalid-rmse:0.49497\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.820 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.820 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.820 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.820 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:01:36] [72]\ttrain-rmse:0.41300\tvalid-rmse:0.49997\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:01:37] [133]\ttrain-rmse:0.35542\tvalid-rmse:0.49470\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.782 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:01:37. Total running time: 12min 25s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: e6f7faf6 with valid-rmse=0.4953085076014274 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.027922831871879127, 'max_depth': 8, 'min_child_weight': 0.035439580412438214, 'subsample': 0.7197886829704874, 'colsample_bytree': 0.6994715912141354, 'lambda': 0.0020630616467057017, 'alpha': 0.0027673015151075727, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      132            6.95868       0.357165       0.495309 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126       72            3.91667       0.41432        0.500518 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261         71            5.63647       0.373046       0.498426 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:01:39] [72]\ttrain-rmse:0.36728\tvalid-rmse:0.49420\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:01:41] [73]\ttrain-rmse:0.41148\tvalid-rmse:0.49917\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:01:43] [73]\ttrain-rmse:0.36455\tvalid-rmse:0.49274\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:01:44] [74]\ttrain-rmse:0.41004\tvalid-rmse:0.49853\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.735 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:01:46] [74]\ttrain-rmse:0.36297\tvalid-rmse:0.49221\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:01:48] [75]\ttrain-rmse:0.40886\tvalid-rmse:0.49761\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:01:50] [75]\ttrain-rmse:0.36055\tvalid-rmse:0.49058\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:01:51] [134]\ttrain-rmse:0.35413\tvalid-rmse:0.49383\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:01:53] [76]\ttrain-rmse:0.35777\tvalid-rmse:0.48867\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:01:55] [135]\ttrain-rmse:0.35358\tvalid-rmse:0.49382\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:01:57] [77]\ttrain-rmse:0.35601\tvalid-rmse:0.48808\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.783 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:01:58] [136]\ttrain-rmse:0.35264\tvalid-rmse:0.49357\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:02:00] [78]\ttrain-rmse:0.35472\tvalid-rmse:0.48779\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:02:02] [79]\ttrain-rmse:0.35322\tvalid-rmse:0.48715\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.799 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:02:04] [137]\ttrain-rmse:0.35208\tvalid-rmse:0.49346\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:02:05] [76]\ttrain-rmse:0.40716\tvalid-rmse:0.49660\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.792 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:02:07] [80]\ttrain-rmse:0.35186\tvalid-rmse:0.48691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:02:09. Total running time: 12min 57s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.4871548544983997 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      137            6.97228       0.352639       0.493573 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126       76            3.92749       0.40886        0.497608 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261         80            5.66069       0.353218       0.487155 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:02:09] [138]\ttrain-rmse:0.35064\tvalid-rmse:0.49246\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:02:11] [81]\ttrain-rmse:0.35053\tvalid-rmse:0.48661\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.790 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:02:13] [82]\ttrain-rmse:0.34801\tvalid-rmse:0.48475\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:02:14] [139]\ttrain-rmse:0.34995\tvalid-rmse:0.49247\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.780 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:02:16] [77]\ttrain-rmse:0.40638\tvalid-rmse:0.49624\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:02:18] [83]\ttrain-rmse:0.34682\tvalid-rmse:0.48437\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.776 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:02:20] [78]\ttrain-rmse:0.40547\tvalid-rmse:0.49616\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.797 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:02:22] [84]\ttrain-rmse:0.34568\tvalid-rmse:0.48408\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:02:23] [140]\ttrain-rmse:0.34876\tvalid-rmse:0.49168\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.800 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.800 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.800 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:02:25] [79]\ttrain-rmse:0.40418\tvalid-rmse:0.49559\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:02:27] [141]\ttrain-rmse:0.34831\tvalid-rmse:0.49150\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:02:29] [80]\ttrain-rmse:0.40337\tvalid-rmse:0.49509\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.783 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:02:30] [142]\ttrain-rmse:0.34747\tvalid-rmse:0.49122\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:02:32] [81]\ttrain-rmse:0.40240\tvalid-rmse:0.49498\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:02:34] [85]\ttrain-rmse:0.34403\tvalid-rmse:0.48312\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:02:36] [82]\ttrain-rmse:0.40141\tvalid-rmse:0.49458\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:02:37] [143]\ttrain-rmse:0.34682\tvalid-rmse:0.49081\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.781 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:02:39] [86]\ttrain-rmse:0.34272\tvalid-rmse:0.48270\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:02:39. Total running time: 13min 27s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.4831163307812596 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      142            6.98592       0.348309       0.491502 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126       82            3.94419       0.402397       0.494977 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261         86            5.67701       0.34403        0.483116 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:02:41] [144]\ttrain-rmse:0.34594\tvalid-rmse:0.49048\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.932 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.933 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.933 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.933 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:02:43] [87]\ttrain-rmse:0.34141\tvalid-rmse:0.48247\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.795 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:02:45] [88]\ttrain-rmse:0.33918\tvalid-rmse:0.48089\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:02:46] [145]\ttrain-rmse:0.34540\tvalid-rmse:0.49037\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.799 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:02:48] [89]\ttrain-rmse:0.33759\tvalid-rmse:0.47958\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:02:50] [83]\ttrain-rmse:0.40068\tvalid-rmse:0.49434\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:02:52] [90]\ttrain-rmse:0.33614\tvalid-rmse:0.47867\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:02:54] [84]\ttrain-rmse:0.39928\tvalid-rmse:0.49334\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:02:55] [91]\ttrain-rmse:0.33518\tvalid-rmse:0.47844\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.787 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:02:57] [146]\ttrain-rmse:0.34480\tvalid-rmse:0.49030\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.799 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.800 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:02:59] [85]\ttrain-rmse:0.39876\tvalid-rmse:0.49323\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.780 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.780 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:03:01] [92]\ttrain-rmse:0.33431\tvalid-rmse:0.47827\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:03:03] [86]\ttrain-rmse:0.39741\tvalid-rmse:0.49298\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.792 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:03:04] [93]\ttrain-rmse:0.33351\tvalid-rmse:0.47815\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:03:06] [87]\ttrain-rmse:0.39627\tvalid-rmse:0.49263\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:03:08] [147]\ttrain-rmse:0.34400\tvalid-rmse:0.49006\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:03:10. Total running time: 13min 57s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.47827029720115943 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      146            6.99679       0.345397       0.490369 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126       88            3.96109       0.396266       0.492631 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261         93            5.69679       0.33431        0.47827  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:03:10] [88]\ttrain-rmse:0.39468\tvalid-rmse:0.49155\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:03:11] [94]\ttrain-rmse:0.33261\tvalid-rmse:0.47801\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:03:13] [148]\ttrain-rmse:0.34323\tvalid-rmse:0.48979\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:03:15] [89]\ttrain-rmse:0.39400\tvalid-rmse:0.49096\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:03:17] [95]\ttrain-rmse:0.33168\tvalid-rmse:0.47783\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:03:18] [149]\ttrain-rmse:0.34254\tvalid-rmse:0.48967\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:03:20] [96]\ttrain-rmse:0.33011\tvalid-rmse:0.47693\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:03:22] [90]\ttrain-rmse:0.39244\tvalid-rmse:0.48953\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:03:24] [97]\ttrain-rmse:0.32935\tvalid-rmse:0.47673\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:03:25] [91]\ttrain-rmse:0.39178\tvalid-rmse:0.48917\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:03:27] [98]\ttrain-rmse:0.32850\tvalid-rmse:0.47659\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:03:29] [150]\ttrain-rmse:0.34146\tvalid-rmse:0.48902\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:03:31] [92]\ttrain-rmse:0.39075\tvalid-rmse:0.48915\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:03:32] [151]\ttrain-rmse:0.34049\tvalid-rmse:0.48857\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:03:34] [93]\ttrain-rmse:0.38973\tvalid-rmse:0.48856\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.797 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:03:36] [152]\ttrain-rmse:0.33952\tvalid-rmse:0.48804\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:03:38] [153]\ttrain-rmse:0.33876\tvalid-rmse:0.48780\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.792 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.736 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:03:40] [94]\ttrain-rmse:0.38902\tvalid-rmse:0.48809\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:03:41] [99]\ttrain-rmse:0.32700\tvalid-rmse:0.47533\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:03:41. Total running time: 14min 29s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.47659322095059803 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      152            7.01333       0.34049        0.48857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126       94            3.97832       0.389725       0.48856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261         99            5.71278       0.328496       0.476593 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:03:43] [95]\ttrain-rmse:0.38819\tvalid-rmse:0.48826\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:03:45] [100]\ttrain-rmse:0.32549\tvalid-rmse:0.47463\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:03:47] [96]\ttrain-rmse:0.38709\tvalid-rmse:0.48759\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:03:48] [97]\ttrain-rmse:0.38615\tvalid-rmse:0.48720\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:03:50] [154]\ttrain-rmse:0.33764\tvalid-rmse:0.48713\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:03:52] [98]\ttrain-rmse:0.38528\tvalid-rmse:0.48705\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:03:54] [155]\ttrain-rmse:0.33714\tvalid-rmse:0.48705\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.731 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:03:55] [99]\ttrain-rmse:0.38422\tvalid-rmse:0.48643\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:03:57] [156]\ttrain-rmse:0.33649\tvalid-rmse:0.48691\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.796 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:03:59] [157]\ttrain-rmse:0.33546\tvalid-rmse:0.48630\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:04:01] [100]\ttrain-rmse:0.38324\tvalid-rmse:0.48575\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:04:02] [158]\ttrain-rmse:0.33492\tvalid-rmse:0.48630\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:04:04] [101]\ttrain-rmse:0.38223\tvalid-rmse:0.48538\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.909 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.910 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.910 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.910 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:04:06] [159]\ttrain-rmse:0.33435\tvalid-rmse:0.48621\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.734 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:04:08] [102]\ttrain-rmse:0.38143\tvalid-rmse:0.48504\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:04:10] [103]\ttrain-rmse:0.38053\tvalid-rmse:0.48422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:04:11. Total running time: 14min 59s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.47533327770724154 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      159            7.03245       0.334915       0.486296 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      103            4.00436       0.381433       0.485039 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        100            5.71553       0.327003       0.475333 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.790 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:04:11] [160]\ttrain-rmse:0.33376\tvalid-rmse:0.48611\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.803 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.803 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.803 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.803 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:04:13] [101]\ttrain-rmse:0.32448\tvalid-rmse:0.47434\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:04:15] [161]\ttrain-rmse:0.33315\tvalid-rmse:0.48589\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.784 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:04:17] [102]\ttrain-rmse:0.32366\tvalid-rmse:0.47412\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.780 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:04:19] [162]\ttrain-rmse:0.33270\tvalid-rmse:0.48596\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:04:20] [163]\ttrain-rmse:0.33209\tvalid-rmse:0.48580\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.788 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:04:22] [103]\ttrain-rmse:0.32203\tvalid-rmse:0.47314\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:04:24] [164]\ttrain-rmse:0.33152\tvalid-rmse:0.48575\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:04:26] [104]\ttrain-rmse:0.37975\tvalid-rmse:0.48424\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:04:27] [104]\ttrain-rmse:0.32128\tvalid-rmse:0.47292\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:04:29] [165]\ttrain-rmse:0.33068\tvalid-rmse:0.48527\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:04:31] [105]\ttrain-rmse:0.37892\tvalid-rmse:0.48408\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:04:33] [105]\ttrain-rmse:0.32017\tvalid-rmse:0.47277\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:04:34] [166]\ttrain-rmse:0.32961\tvalid-rmse:0.48439\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:04:36] [106]\ttrain-rmse:0.37830\tvalid-rmse:0.48389\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:04:38] [167]\ttrain-rmse:0.32860\tvalid-rmse:0.48350\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:04:40] [107]\ttrain-rmse:0.37743\tvalid-rmse:0.48339\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:04:41] [168]\ttrain-rmse:0.32812\tvalid-rmse:0.48363\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.773 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:04:41. Total running time: 15min 29s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.4729164183373954 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      167            7.05522       0.329611       0.48439  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      107            4.01582       0.378295       0.483891 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        105            5.72914       0.321276       0.472916 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:04:43] [108]\ttrain-rmse:0.37599\tvalid-rmse:0.48232\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:04:45] [169]\ttrain-rmse:0.32725\tvalid-rmse:0.48297\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:04:47] [109]\ttrain-rmse:0.37476\tvalid-rmse:0.48184\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:04:48] [170]\ttrain-rmse:0.32616\tvalid-rmse:0.48217\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:04:50] [110]\ttrain-rmse:0.37315\tvalid-rmse:0.48076\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.776 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:04:52] [111]\ttrain-rmse:0.37221\tvalid-rmse:0.48054\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:04:54] [171]\ttrain-rmse:0.32561\tvalid-rmse:0.48195\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.736 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:04:56] [112]\ttrain-rmse:0.37136\tvalid-rmse:0.48032\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.745 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:04:57] [172]\ttrain-rmse:0.32520\tvalid-rmse:0.48180\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:04:59] [113]\ttrain-rmse:0.37045\tvalid-rmse:0.48019\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.742 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:05:01] [173]\ttrain-rmse:0.32465\tvalid-rmse:0.48163\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:05:03] [174]\ttrain-rmse:0.32356\tvalid-rmse:0.48088\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:05:04] [114]\ttrain-rmse:0.36966\tvalid-rmse:0.47961\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.724 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:05:06] [175]\ttrain-rmse:0.32291\tvalid-rmse:0.48063\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:05:08] [115]\ttrain-rmse:0.36873\tvalid-rmse:0.47935\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.729 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.742 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:05:11] [116]\ttrain-rmse:0.36822\tvalid-rmse:0.47930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:05:13. Total running time: 16min 1s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.4729164183373954 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      175            7.0776        0.32356        0.48088  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      117            4.04349       0.368218       0.479303 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        105            5.72914       0.321276       0.472916 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:05:13] [117]\ttrain-rmse:0.36749\tvalid-rmse:0.47898\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:05:15] [177]\ttrain-rmse:0.32179\tvalid-rmse:0.48031\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.709 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.710 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.710 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.710 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:06:45. Total running time: 17min 33s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.4667159961031904 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      194            7.12912       0.311          0.475901 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      135            4.09365       0.352962       0.474012 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        120            5.76974       0.306531       0.466716 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:06:45] [195]\ttrain-rmse:0.30966\tvalid-rmse:0.47550\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:06:47] [121]\ttrain-rmse:0.30460\tvalid-rmse:0.46586\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.895 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.896 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.896 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.896 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:06:49] [122]\ttrain-rmse:0.30413\tvalid-rmse:0.46581\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:06:50] [196]\ttrain-rmse:0.30912\tvalid-rmse:0.47544\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:06:52] [123]\ttrain-rmse:0.30293\tvalid-rmse:0.46508\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:06:54] [136]\ttrain-rmse:0.35140\tvalid-rmse:0.47343\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:06:56] [197]\ttrain-rmse:0.30840\tvalid-rmse:0.47495\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:06:58] [137]\ttrain-rmse:0.35090\tvalid-rmse:0.47359\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:06:59] [138]\ttrain-rmse:0.34996\tvalid-rmse:0.47310\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.796 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:07:01] [198]\ttrain-rmse:0.30771\tvalid-rmse:0.47448\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:07:03] [139]\ttrain-rmse:0.34922\tvalid-rmse:0.47317\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.771 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:07:05] [199]\ttrain-rmse:0.30729\tvalid-rmse:0.47438\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:07:06] [124]\ttrain-rmse:0.30241\tvalid-rmse:0.46506\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:07:08] [200]\ttrain-rmse:0.30686\tvalid-rmse:0.47434\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:07:10] [140]\ttrain-rmse:0.34832\tvalid-rmse:0.47282\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.791 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:07:12] [201]\ttrain-rmse:0.30633\tvalid-rmse:0.47444\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:07:13] [125]\ttrain-rmse:0.30190\tvalid-rmse:0.46496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:07:15. Total running time: 18min 3s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.465062383335042 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      201            7.14903       0.306863       0.474342 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      140            4.10748       0.34922        0.473168 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        125            5.78314       0.302414       0.465062 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:07:15] [202]\ttrain-rmse:0.30573\tvalid-rmse:0.47413\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:07:17] [126]\ttrain-rmse:0.30099\tvalid-rmse:0.46500\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.777 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:07:19] [203]\ttrain-rmse:0.30526\tvalid-rmse:0.47402\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.726 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:07:21] [204]\ttrain-rmse:0.30427\tvalid-rmse:0.47346\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:07:22] [127]\ttrain-rmse:0.30016\tvalid-rmse:0.46487\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.784 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.722 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.722 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.722 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.722 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:07:24] [205]\ttrain-rmse:0.30396\tvalid-rmse:0.47341\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.732 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:07:26] [128]\ttrain-rmse:0.29966\tvalid-rmse:0.46478\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.960 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.960 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.960 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.960 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:07:28] [206]\ttrain-rmse:0.30337\tvalid-rmse:0.47324\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:07:29] [129]\ttrain-rmse:0.29879\tvalid-rmse:0.46422\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:07:31] [141]\ttrain-rmse:0.34735\tvalid-rmse:0.47278\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:07:33] [130]\ttrain-rmse:0.29800\tvalid-rmse:0.46416\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:07:35] [142]\ttrain-rmse:0.34696\tvalid-rmse:0.47260\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:07:37] [131]\ttrain-rmse:0.29714\tvalid-rmse:0.46357\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.728 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:07:38] [143]\ttrain-rmse:0.34646\tvalid-rmse:0.47260\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:07:40] [132]\ttrain-rmse:0.29652\tvalid-rmse:0.46355\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:07:42] [133]\ttrain-rmse:0.29574\tvalid-rmse:0.46322\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:07:44] [144]\ttrain-rmse:0.34620\tvalid-rmse:0.47255\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:07:45. Total running time: 18min 33s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.46321557321590084 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      205            7.15988       0.304275       0.473459 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      144            4.11858       0.346455       0.472601 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        134            5.80759       0.295736       0.463216 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:07:45] [134]\ttrain-rmse:0.29466\tvalid-rmse:0.46249\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:07:47] [145]\ttrain-rmse:0.34557\tvalid-rmse:0.47250\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:07:49] [207]\ttrain-rmse:0.30283\tvalid-rmse:0.47314\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:07:51] [135]\ttrain-rmse:0.29395\tvalid-rmse:0.46252\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:07:52] [146]\ttrain-rmse:0.34504\tvalid-rmse:0.47241\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:07:54] [136]\ttrain-rmse:0.29353\tvalid-rmse:0.46253\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.796 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:07:56] [147]\ttrain-rmse:0.34449\tvalid-rmse:0.47221\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:07:58] [137]\ttrain-rmse:0.29291\tvalid-rmse:0.46235\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.745 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:07:59] [148]\ttrain-rmse:0.34385\tvalid-rmse:0.47216\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:08:01] [138]\ttrain-rmse:0.29194\tvalid-rmse:0.46176\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:08:03] [139]\ttrain-rmse:0.29128\tvalid-rmse:0.46178\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:08:05] [149]\ttrain-rmse:0.34337\tvalid-rmse:0.47206\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:08:06] [140]\ttrain-rmse:0.29050\tvalid-rmse:0.46129\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:08:08] [150]\ttrain-rmse:0.34279\tvalid-rmse:0.47162\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:08:10] [141]\ttrain-rmse:0.28986\tvalid-rmse:0.46122\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:08:12] [151]\ttrain-rmse:0.34202\tvalid-rmse:0.47135\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.913 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.913 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.913 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.913 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:08:14] [208]\ttrain-rmse:0.30181\tvalid-rmse:0.47270\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:08:15. Total running time: 19min 3s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.4612902980213318 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      207            7.16552       0.303368       0.473243 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      152            4.14114       0.342022       0.471346 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        141            5.82678       0.290502       0.46129  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:08:15] [152]\ttrain-rmse:0.34132\tvalid-rmse:0.47133\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:08:17] [142]\ttrain-rmse:0.28915\tvalid-rmse:0.46107\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:08:19] [209]\ttrain-rmse:0.30136\tvalid-rmse:0.47264\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.736 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:08:21] [143]\ttrain-rmse:0.28848\tvalid-rmse:0.46098\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.733 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:08:22] [210]\ttrain-rmse:0.30101\tvalid-rmse:0.47263\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:08:24] [211]\ttrain-rmse:0.30067\tvalid-rmse:0.47255\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:08:26] [153]\ttrain-rmse:0.34064\tvalid-rmse:0.47155\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.737 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.745 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:08:28] [144]\ttrain-rmse:0.28787\tvalid-rmse:0.46094\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:08:29] [212]\ttrain-rmse:0.30011\tvalid-rmse:0.47229\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.745 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:08:31] [145]\ttrain-rmse:0.28727\tvalid-rmse:0.46079\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:08:33] [213]\ttrain-rmse:0.29976\tvalid-rmse:0.47220\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:08:35] [154]\ttrain-rmse:0.34046\tvalid-rmse:0.47147\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.734 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:08:36] [214]\ttrain-rmse:0.29929\tvalid-rmse:0.47222\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:08:38] [155]\ttrain-rmse:0.34005\tvalid-rmse:0.47142\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:08:40] [215]\ttrain-rmse:0.29877\tvalid-rmse:0.47188\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.742 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:08:42] [156]\ttrain-rmse:0.33950\tvalid-rmse:0.47138\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:08:43] [216]\ttrain-rmse:0.29828\tvalid-rmse:0.47178\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.736 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:08:45] [217]\ttrain-rmse:0.29768\tvalid-rmse:0.47140\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:08:47. Total running time: 19min 35s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.4607875988809748 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      216            7.19006       0.298771       0.471881 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      156            4.1521        0.340046       0.471425 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        146            5.84038       0.287272       0.460788 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:08:47] [146]\ttrain-rmse:0.28699\tvalid-rmse:0.46074\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:08:49] [157]\ttrain-rmse:0.33903\tvalid-rmse:0.47142\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:08:50] [218]\ttrain-rmse:0.29690\tvalid-rmse:0.47096\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:08:52] [158]\ttrain-rmse:0.33849\tvalid-rmse:0.47147\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:08:54] [219]\ttrain-rmse:0.29630\tvalid-rmse:0.47073\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.733 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:08:56] [220]\ttrain-rmse:0.29590\tvalid-rmse:0.47068\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.731 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:08:57] [159]\ttrain-rmse:0.33776\tvalid-rmse:0.47153\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:08:59] [147]\ttrain-rmse:0.28622\tvalid-rmse:0.46067\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.727 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:09:01] [160]\ttrain-rmse:0.33743\tvalid-rmse:0.47154\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:09:03] [148]\ttrain-rmse:0.28558\tvalid-rmse:0.46060\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:09:04] [221]\ttrain-rmse:0.29553\tvalid-rmse:0.47064\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.733 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:09:06] [149]\ttrain-rmse:0.28497\tvalid-rmse:0.46059\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:09:08] [222]\ttrain-rmse:0.29499\tvalid-rmse:0.47029\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.735 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:09:10] [161]\ttrain-rmse:0.33700\tvalid-rmse:0.47146\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:09:11] [223]\ttrain-rmse:0.29436\tvalid-rmse:0.47008\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.724 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:09:13] [162]\ttrain-rmse:0.33650\tvalid-rmse:0.47139\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:09:15] [150]\ttrain-rmse:0.28416\tvalid-rmse:0.46019\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:09:17] [224]\ttrain-rmse:0.29373\tvalid-rmse:0.46986\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:09:18. Total running time: 20min 6s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.4605856278650308 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      223            7.20919       0.294987       0.470288 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      163            4.17168       0.336498       0.471395 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        150            5.85178       0.284971       0.460586 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:09:18] [163]\ttrain-rmse:0.33574\tvalid-rmse:0.47145\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:09:20] [225]\ttrain-rmse:0.29313\tvalid-rmse:0.46956\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.784 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:09:22] [164]\ttrain-rmse:0.33457\tvalid-rmse:0.47091\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:09:24] [226]\ttrain-rmse:0.29269\tvalid-rmse:0.46946\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:09:25] [165]\ttrain-rmse:0.33390\tvalid-rmse:0.47059\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.722 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.722 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.722 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.722 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:09:27] [166]\ttrain-rmse:0.33334\tvalid-rmse:0.47050\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:09:29] [151]\ttrain-rmse:0.28349\tvalid-rmse:0.45984\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:09:31] [167]\ttrain-rmse:0.33235\tvalid-rmse:0.46988\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.786 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.903 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.904 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.904 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.904 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:09:33] [152]\ttrain-rmse:0.28274\tvalid-rmse:0.45944\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:09:34] [168]\ttrain-rmse:0.33208\tvalid-rmse:0.46979\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:09:36] [153]\ttrain-rmse:0.28231\tvalid-rmse:0.45942\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.795 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.771 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:09:38] [154]\ttrain-rmse:0.28151\tvalid-rmse:0.45919\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:09:40] [169]\ttrain-rmse:0.33161\tvalid-rmse:0.46966\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:09:41] [227]\ttrain-rmse:0.29209\tvalid-rmse:0.46953\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:09:43] [170]\ttrain-rmse:0.33072\tvalid-rmse:0.46907\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:09:45] [155]\ttrain-rmse:0.28103\tvalid-rmse:0.45914\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:09:47] [171]\ttrain-rmse:0.33022\tvalid-rmse:0.46908\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:09:48] [156]\ttrain-rmse:0.28041\tvalid-rmse:0.45910\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:09:48. Total running time: 20min 36s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.45913810572863334 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      226            7.2173        0.293127       0.469561 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      171            4.19423       0.330716       0.469069 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        156            5.86829       0.281027       0.459138 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:09:50] [228]\ttrain-rmse:0.29173\tvalid-rmse:0.46933\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.784 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:09:52] [157]\ttrain-rmse:0.27972\tvalid-rmse:0.45874\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:09:54] [229]\ttrain-rmse:0.29122\tvalid-rmse:0.46914\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.715 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.716 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.716 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.716 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:09:55] [158]\ttrain-rmse:0.27924\tvalid-rmse:0.45867\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:09:57] [230]\ttrain-rmse:0.29083\tvalid-rmse:0.46917\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:09:59] [231]\ttrain-rmse:0.29035\tvalid-rmse:0.46903\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:10:01] [172]\ttrain-rmse:0.32950\tvalid-rmse:0.46884\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.776 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:10:03] [232]\ttrain-rmse:0.28997\tvalid-rmse:0.46906\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.730 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:10:04] [159]\ttrain-rmse:0.27858\tvalid-rmse:0.45860\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:10:06] [173]\ttrain-rmse:0.32889\tvalid-rmse:0.46882\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:10:08] [233]\ttrain-rmse:0.28937\tvalid-rmse:0.46883\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:10:10] [174]\ttrain-rmse:0.32828\tvalid-rmse:0.46871\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:10:11] [234]\ttrain-rmse:0.28900\tvalid-rmse:0.46864\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.736 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.723 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:10:13] [175]\ttrain-rmse:0.32776\tvalid-rmse:0.46879\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.720 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.720 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.720 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.721 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:10:15] [235]\ttrain-rmse:0.28838\tvalid-rmse:0.46851\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:10:16] [176]\ttrain-rmse:0.32717\tvalid-rmse:0.46874\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.736 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:10:18] [236]\ttrain-rmse:0.28786\tvalid-rmse:0.46840\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:10:20. Total running time: 21min 8s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.4586689962571451 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      236            7.24503       0.288382       0.468506 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      176            4.20788       0.32776        0.468794 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        159            5.87648       0.279242       0.458669 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.739 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:10:20] [237]\ttrain-rmse:0.28744\tvalid-rmse:0.46843\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:10:22] [177]\ttrain-rmse:0.32664\tvalid-rmse:0.46862\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:10:23] [238]\ttrain-rmse:0.28680\tvalid-rmse:0.46818\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.711 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.712 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.712 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.712 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:10:25] [160]\ttrain-rmse:0.27806\tvalid-rmse:0.45857\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:10:27] [178]\ttrain-rmse:0.32597\tvalid-rmse:0.46839\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:10:29] [239]\ttrain-rmse:0.28631\tvalid-rmse:0.46822\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.733 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.730 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:10:30] [179]\ttrain-rmse:0.32542\tvalid-rmse:0.46830\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:10:32] [240]\ttrain-rmse:0.28569\tvalid-rmse:0.46795\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:10:34] [180]\ttrain-rmse:0.32477\tvalid-rmse:0.46822\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:10:36] [161]\ttrain-rmse:0.27736\tvalid-rmse:0.45850\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:10:37] [181]\ttrain-rmse:0.32425\tvalid-rmse:0.46829\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:10:39] [162]\ttrain-rmse:0.27695\tvalid-rmse:0.45851\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:10:41] [182]\ttrain-rmse:0.32379\tvalid-rmse:0.46833\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.732 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:10:43] [163]\ttrain-rmse:0.27653\tvalid-rmse:0.45852\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:10:44] [183]\ttrain-rmse:0.32316\tvalid-rmse:0.46803\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:10:46] [241]\ttrain-rmse:0.28526\tvalid-rmse:0.46772\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:10:48] [164]\ttrain-rmse:0.27604\tvalid-rmse:0.45844\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:10:50] [242]\ttrain-rmse:0.28470\tvalid-rmse:0.46772\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:10:51] [243]\ttrain-rmse:0.28418\tvalid-rmse:0.46766\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:10:51. Total running time: 21min 39s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.45851752671434226 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      242            7.26145       0.285264       0.46772  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      183            4.2275        0.323787       0.468327 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        164            5.89057       0.276526       0.458518 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:10:53] [165]\ttrain-rmse:0.27550\tvalid-rmse:0.45821\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.964 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.965 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.965 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.965 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:10:55] [244]\ttrain-rmse:0.28359\tvalid-rmse:0.46735\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:10:57] [166]\ttrain-rmse:0.27494\tvalid-rmse:0.45780\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:10:59] [184]\ttrain-rmse:0.32281\tvalid-rmse:0.46786\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:11:00] [167]\ttrain-rmse:0.27418\tvalid-rmse:0.45739\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.791 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:11:02] [168]\ttrain-rmse:0.27372\tvalid-rmse:0.45745\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:11:04] [185]\ttrain-rmse:0.32242\tvalid-rmse:0.46763\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.781 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:11:06] [169]\ttrain-rmse:0.27300\tvalid-rmse:0.45710\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.784 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:11:07] [186]\ttrain-rmse:0.32195\tvalid-rmse:0.46733\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:11:09] [170]\ttrain-rmse:0.27214\tvalid-rmse:0.45676\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:11:11] [187]\ttrain-rmse:0.32137\tvalid-rmse:0.46738\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.733 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:11:13] [171]\ttrain-rmse:0.27165\tvalid-rmse:0.45670\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:11:14] [188]\ttrain-rmse:0.32097\tvalid-rmse:0.46737\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:11:16] [172]\ttrain-rmse:0.27123\tvalid-rmse:0.45676\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:11:18] [189]\ttrain-rmse:0.32033\tvalid-rmse:0.46733\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:11:20] [173]\ttrain-rmse:0.27063\tvalid-rmse:0.45665\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:11:21] [190]\ttrain-rmse:0.31980\tvalid-rmse:0.46733\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:11:21. Total running time: 22min 9s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.45675751724407937 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      243            7.26417       0.284695       0.467721 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      190            4.24758       0.320328       0.467335 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        173            5.9163        0.271229       0.456758 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:11:23] [245]\ttrain-rmse:0.28304\tvalid-rmse:0.46721\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.720 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.721 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.721 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.721 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:11:25] [191]\ttrain-rmse:0.31922\tvalid-rmse:0.46734\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:11:27] [246]\ttrain-rmse:0.28272\tvalid-rmse:0.46722\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:11:29] [192]\ttrain-rmse:0.31868\tvalid-rmse:0.46711\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:11:30] [247]\ttrain-rmse:0.28243\tvalid-rmse:0.46717\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:11:32] [193]\ttrain-rmse:0.31820\tvalid-rmse:0.46714\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:11:34] [248]\ttrain-rmse:0.28203\tvalid-rmse:0.46705\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:11:36] [174]\ttrain-rmse:0.26979\tvalid-rmse:0.45629\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:11:37] [249]\ttrain-rmse:0.28163\tvalid-rmse:0.46683\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:11:39] [194]\ttrain-rmse:0.31769\tvalid-rmse:0.46692\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:11:41] [175]\ttrain-rmse:0.26930\tvalid-rmse:0.45622\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:11:43] [250]\ttrain-rmse:0.28088\tvalid-rmse:0.46653\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:11:44] [251]\ttrain-rmse:0.28025\tvalid-rmse:0.46637\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:11:46] [176]\ttrain-rmse:0.26885\tvalid-rmse:0.45620\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:11:48] [252]\ttrain-rmse:0.27959\tvalid-rmse:0.46603\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:11:50] [177]\ttrain-rmse:0.26823\tvalid-rmse:0.45621\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:11:51] [253]\ttrain-rmse:0.27908\tvalid-rmse:0.46612\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.777 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:11:53] [178]\ttrain-rmse:0.26749\tvalid-rmse:0.45591\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:11:53. Total running time: 22min 41s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.45620625442723317 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      252            7.289         0.280253       0.466372 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      194            4.25882       0.3182         0.467143 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        178            5.93          0.26823        0.456206 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:11:55] [254]\ttrain-rmse:0.27882\tvalid-rmse:0.46608\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:11:57] [179]\ttrain-rmse:0.26687\tvalid-rmse:0.45565\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:11:59] [255]\ttrain-rmse:0.27835\tvalid-rmse:0.46609\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:12:00] [180]\ttrain-rmse:0.26612\tvalid-rmse:0.45540\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:12:02] [195]\ttrain-rmse:0.31726\tvalid-rmse:0.46700\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.809 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.809 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.809 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.809 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:12:04] [181]\ttrain-rmse:0.26559\tvalid-rmse:0.45538\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:12:06] [182]\ttrain-rmse:0.26497\tvalid-rmse:0.45498\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:12:07] [256]\ttrain-rmse:0.27786\tvalid-rmse:0.46609\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:12:09] [183]\ttrain-rmse:0.26431\tvalid-rmse:0.45467\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:12:11] [257]\ttrain-rmse:0.27710\tvalid-rmse:0.46599\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:12:13] [184]\ttrain-rmse:0.26386\tvalid-rmse:0.45451\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:12:14] [258]\ttrain-rmse:0.27663\tvalid-rmse:0.46595\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.731 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:12:16] [259]\ttrain-rmse:0.27626\tvalid-rmse:0.46602\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.910 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.910 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.910 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.910 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:12:18] [196]\ttrain-rmse:0.31698\tvalid-rmse:0.46693\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:12:20] [185]\ttrain-rmse:0.26317\tvalid-rmse:0.45457\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:12:22] [197]\ttrain-rmse:0.31626\tvalid-rmse:0.46665\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.809 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.809 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.809 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.809 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:12:23] [260]\ttrain-rmse:0.27575\tvalid-rmse:0.46592\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:12:23. Total running time: 23min 11s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.454505345233612 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      259            7.30753       0.276633       0.465949 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      197            4.26711       0.316979       0.466925 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        185            5.94932       0.26386        0.454505 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:12:25] [198]\ttrain-rmse:0.31601\tvalid-rmse:0.46679\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:12:27] [261]\ttrain-rmse:0.27531\tvalid-rmse:0.46588\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:12:29] [199]\ttrain-rmse:0.31555\tvalid-rmse:0.46680\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:12:30] [262]\ttrain-rmse:0.27496\tvalid-rmse:0.46579\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:12:32] [200]\ttrain-rmse:0.31539\tvalid-rmse:0.46672\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:12:34] [263]\ttrain-rmse:0.27473\tvalid-rmse:0.46570\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:12:36] [201]\ttrain-rmse:0.31496\tvalid-rmse:0.46667\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:12:37] [264]\ttrain-rmse:0.27431\tvalid-rmse:0.46553\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:12:39] [202]\ttrain-rmse:0.31392\tvalid-rmse:0.46615\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.771 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:12:41] [265]\ttrain-rmse:0.27381\tvalid-rmse:0.46545\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:12:43] [203]\ttrain-rmse:0.31344\tvalid-rmse:0.46619\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:12:44] [266]\ttrain-rmse:0.27353\tvalid-rmse:0.46539\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:12:46] [204]\ttrain-rmse:0.31312\tvalid-rmse:0.46619\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:12:48] [267]\ttrain-rmse:0.27299\tvalid-rmse:0.46527\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:12:50] [205]\ttrain-rmse:0.31273\tvalid-rmse:0.46625\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.803 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.804 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.804 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.804 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:12:52] [268]\ttrain-rmse:0.27268\tvalid-rmse:0.46533\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:12:53] [206]\ttrain-rmse:0.31224\tvalid-rmse:0.46612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:12:55. Total running time: 23min 43s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.454505345233612 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      268            7.33218       0.27299        0.465269 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      206            4.2919        0.312727       0.466251 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        185            5.94932       0.26386        0.454505 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:12:55] [269]\ttrain-rmse:0.27224\tvalid-rmse:0.46526\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.789 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:12:57] [207]\ttrain-rmse:0.31173\tvalid-rmse:0.46603\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:12:59] [208]\ttrain-rmse:0.31099\tvalid-rmse:0.46608\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.735 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:13:00] [186]\ttrain-rmse:0.26257\tvalid-rmse:0.45432\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:13:02] [209]\ttrain-rmse:0.31063\tvalid-rmse:0.46601\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.804 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.804 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.805 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.805 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.745 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:13:04] [270]\ttrain-rmse:0.27177\tvalid-rmse:0.46521\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.730 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:13:06] [187]\ttrain-rmse:0.26207\tvalid-rmse:0.45425\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:13:07] [271]\ttrain-rmse:0.27140\tvalid-rmse:0.46508\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:13:09] [272]\ttrain-rmse:0.27089\tvalid-rmse:0.46484\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:13:11] [188]\ttrain-rmse:0.26155\tvalid-rmse:0.45424\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.733 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:13:13] [210]\ttrain-rmse:0.31018\tvalid-rmse:0.46603\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.739 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:13:14] [273]\ttrain-rmse:0.27041\tvalid-rmse:0.46478\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:13:16] [211]\ttrain-rmse:0.30964\tvalid-rmse:0.46604\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:13:18] [274]\ttrain-rmse:0.27002\tvalid-rmse:0.46466\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:13:20] [275]\ttrain-rmse:0.26965\tvalid-rmse:0.46455\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:13:21] [212]\ttrain-rmse:0.30899\tvalid-rmse:0.46572\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.745 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:13:23] [276]\ttrain-rmse:0.26906\tvalid-rmse:0.46424\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:13:25] [213]\ttrain-rmse:0.30850\tvalid-rmse:0.46582\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.713 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.713 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.713 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.713 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:13:27. Total running time: 24min 14s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.4542526609070767 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      276            7.35425       0.269645       0.464553 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      213            4.31169       0.30899        0.46572  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        188            5.95768       0.262068       0.454253 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:13:27] [277]\ttrain-rmse:0.26866\tvalid-rmse:0.46412\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:13:28] [214]\ttrain-rmse:0.30815\tvalid-rmse:0.46575\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:13:30] [278]\ttrain-rmse:0.26825\tvalid-rmse:0.46400\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.797 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:13:32] [215]\ttrain-rmse:0.30773\tvalid-rmse:0.46569\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:13:34] [279]\ttrain-rmse:0.26759\tvalid-rmse:0.46369\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:13:35] [216]\ttrain-rmse:0.30723\tvalid-rmse:0.46578\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.786 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:13:37] [280]\ttrain-rmse:0.26726\tvalid-rmse:0.46367\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.939 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.939 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.939 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.939 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:13:39] [217]\ttrain-rmse:0.30672\tvalid-rmse:0.46584\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:13:41] [218]\ttrain-rmse:0.30610\tvalid-rmse:0.46586\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.736 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:13:43] [281]\ttrain-rmse:0.26702\tvalid-rmse:0.46365\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:13:44] [189]\ttrain-rmse:0.26116\tvalid-rmse:0.45420\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:13:46] [282]\ttrain-rmse:0.26649\tvalid-rmse:0.46353\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:13:48] [190]\ttrain-rmse:0.26072\tvalid-rmse:0.45421\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:13:50] [283]\ttrain-rmse:0.26618\tvalid-rmse:0.46357\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:13:51] [191]\ttrain-rmse:0.26027\tvalid-rmse:0.45410\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:13:53] [219]\ttrain-rmse:0.30578\tvalid-rmse:0.46571\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:13:55] [192]\ttrain-rmse:0.25955\tvalid-rmse:0.45385\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.734 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:13:57. Total running time: 24min 45s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.45409545363017695 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      282            7.37046       0.267024       0.463652 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      220            4.33079       0.305784       0.465711 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        192            5.96887       0.260265       0.454095 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:13:57] [220]\ttrain-rmse:0.30543\tvalid-rmse:0.46574\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:13:58] [193]\ttrain-rmse:0.25913\tvalid-rmse:0.45393\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:14:00] [284]\ttrain-rmse:0.26583\tvalid-rmse:0.46350\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.797 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:14:02] [285]\ttrain-rmse:0.26547\tvalid-rmse:0.46346\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:14:04] [194]\ttrain-rmse:0.25882\tvalid-rmse:0.45380\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.783 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:14:06] [221]\ttrain-rmse:0.30478\tvalid-rmse:0.46555\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:14:07] [195]\ttrain-rmse:0.25838\tvalid-rmse:0.45383\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.776 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:14:09] [222]\ttrain-rmse:0.30434\tvalid-rmse:0.46534\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:14:11] [196]\ttrain-rmse:0.25799\tvalid-rmse:0.45387\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:14:13] [197]\ttrain-rmse:0.25749\tvalid-rmse:0.45355\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:14:14] [223]\ttrain-rmse:0.30369\tvalid-rmse:0.46524\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:14:16] [286]\ttrain-rmse:0.26512\tvalid-rmse:0.46334\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:14:18] [198]\ttrain-rmse:0.25693\tvalid-rmse:0.45321\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.724 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:14:20] [287]\ttrain-rmse:0.26467\tvalid-rmse:0.46332\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:14:21] [199]\ttrain-rmse:0.25637\tvalid-rmse:0.45333\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:14:23] [224]\ttrain-rmse:0.30339\tvalid-rmse:0.46518\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:14:25] [200]\ttrain-rmse:0.25588\tvalid-rmse:0.45332\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:14:27] [225]\ttrain-rmse:0.30274\tvalid-rmse:0.46493\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.742 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:14:28] [201]\ttrain-rmse:0.25530\tvalid-rmse:0.45340\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:14:28. Total running time: 25min 16s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.45331937201410993 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      286            7.38118       0.265472       0.463462 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      225            4.34427       0.303385       0.465179 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        201            5.99354       0.255878       0.453319 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:14:30] [226]\ttrain-rmse:0.30224\tvalid-rmse:0.46477\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.786 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:14:32] [288]\ttrain-rmse:0.26412\tvalid-rmse:0.46304\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:14:34] [227]\ttrain-rmse:0.30175\tvalid-rmse:0.46493\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:14:35] [289]\ttrain-rmse:0.26362\tvalid-rmse:0.46306\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.745 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.780 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:14:37] [228]\ttrain-rmse:0.30138\tvalid-rmse:0.46476\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:14:39] [290]\ttrain-rmse:0.26319\tvalid-rmse:0.46302\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.745 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:14:41] [229]\ttrain-rmse:0.30090\tvalid-rmse:0.46487\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:14:42] [291]\ttrain-rmse:0.26280\tvalid-rmse:0.46304\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:14:44] [230]\ttrain-rmse:0.30050\tvalid-rmse:0.46479\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.737 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.742 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:14:46] [292]\ttrain-rmse:0.26250\tvalid-rmse:0.46300\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:14:48] [231]\ttrain-rmse:0.30007\tvalid-rmse:0.46444\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:14:49] [293]\ttrain-rmse:0.26211\tvalid-rmse:0.46285\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:14:51] [232]\ttrain-rmse:0.29956\tvalid-rmse:0.46431\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.783 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:14:53] [294]\ttrain-rmse:0.26164\tvalid-rmse:0.46293\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.745 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:14:55] [233]\ttrain-rmse:0.29918\tvalid-rmse:0.46446\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.799 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:14:57] [295]\ttrain-rmse:0.26124\tvalid-rmse:0.46293\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:14:58] [234]\ttrain-rmse:0.29869\tvalid-rmse:0.46444\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.725 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:15:00] [202]\ttrain-rmse:0.25473\tvalid-rmse:0.45328\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.902 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.903 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.903 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.903 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 3 RUNNING | 5 TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:15:00. Total running time: 25min 48s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.45340178915181695 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   RUNNING        0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      294            7.40356       0.262115       0.462851 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      234            4.36955       0.299181       0.464458 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        202            5.9962        0.255297       0.453402 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:15:02] [296]\ttrain-rmse:0.26094\tvalid-rmse:0.46295\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:15:04] [203]\ttrain-rmse:0.25431\tvalid-rmse:0.45326\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.745 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:15:05] [297]\ttrain-rmse:0.26028\tvalid-rmse:0.46257\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:15:07] [204]\ttrain-rmse:0.25374\tvalid-rmse:0.45296\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:15:09] [298]\ttrain-rmse:0.25981\tvalid-rmse:0.46253\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:15:11] [205]\ttrain-rmse:0.25336\tvalid-rmse:0.45282\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=297, ip=100.64.47.109)\u001b[0m [12:15:12] [299]\ttrain-rmse:0.25935\tvalid-rmse:0.46251\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.727 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:15:14] [206]\ttrain-rmse:0.25283\tvalid-rmse:0.45279\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:15:16] [207]\ttrain-rmse:0.25237\tvalid-rmse:0.45280\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.724 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:15:19] [208]\ttrain-rmse:0.25168\tvalid-rmse:0.45248\n",
      "\u001b[36m(RayTrainWorker pid=343, ip=100.64.47.109)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=s3, path=ddl-wadkars/end-to-end/california/air/xgb/xgb_from_s3_irsa/XGBoostTrainer_e6f7faf6_1_alpha=0.0028,colsample_bytree=0.6995,eta=0.0279,eval_metric=rmse,lambda=0.0021,max_depth=8,min_child_wei_2025-09-01_11-49-12/checkpoint_000000)\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.725 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🏃 View run XGBoostTrainer_e6f7faf6 at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265/runs/9ae49067c0aa491a82ca3592ebfc6be3\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🧪 View experiment at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_e6f7faf6 completed after 300 iterations at 2025-09-01 12:15:22. Total running time: 26min 9s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_e6f7faf6 result             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ checkpoint_dir_name                              │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_this_iter_s                         0.00272 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_total_s                             7.42061 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ training_iteration                           300 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ train-rmse                               0.25935 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ valid-rmse                               0.46251 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.725 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:15:23] [209]\ttrain-rmse:0.25130\tvalid-rmse:0.45242\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:15:25] [235]\ttrain-rmse:0.29836\tvalid-rmse:0.46440\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.708 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.708 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.708 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.708 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_43af9c66 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_43af9c66 config                          │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/alpha                                5.127099630669771 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/colsample_bytree                    0.9392705361913928 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eta                               0.014028406505222319 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eval_metric                                       rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/lambda                             0.39282614265692645 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/max_depth                                            6 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/min_child_weight                     7.088653294619334 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/nthread                                              1 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/objective                             reg:squarederror │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/subsample                           0.7539954938921521 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/tree_method                                       hist │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=1645, ip=100.64.27.77)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=1645, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=1691) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=1645, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=1692) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=1645, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=1693) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=1645, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=1694) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.742 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:15:28] [210]\ttrain-rmse:0.25093\tvalid-rmse:0.45240\n",
      "\u001b[36m(RayTrainWorker pid=1691, ip=100.64.27.77)\u001b[0m [12:15:28] Task [xgboost.ray-rank=00000000]:7cee6ccf2adc38d956deef4604000000 got rank 0\n",
      "\u001b[36m(RayTrainWorker pid=1692, ip=100.64.27.77)\u001b[0m [12:15:28] Task [xgboost.ray-rank=00000001]:68ea8173afa20acb703ef4b604000000 got rank 1\n",
      "\u001b[36m(RayTrainWorker pid=1694, ip=100.64.27.77)\u001b[0m [12:15:28] Task [xgboost.ray-rank=00000003]:5a1ca4fad60777775f38e13a04000000 got rank 3\n",
      "\u001b[36m(RayTrainWorker pid=1693, ip=100.64.27.77)\u001b[0m [12:15:28] Task [xgboost.ray-rank=00000002]:52870b409e4feb94cc09c29d04000000 got rank 2\n",
      "\u001b[36m(SplitCoordinator pid=1855, ip=100.64.27.77)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=1855, ip=100.64.27.77)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.733 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:15:30] [236]\ttrain-rmse:0.29797\tvalid-rmse:0.46430\n",
      "\u001b[36m(SplitCoordinator pid=1856, ip=100.64.27.77)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=1856, ip=100.64.27.77)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 6 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:15:32. Total running time: 26min 19s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.4523956132900656 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      236            4.37521       0.298364       0.464402 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        211            6.021         0.250931       0.452396 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   RUNNING        0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271                                                              │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.787 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:15:32] [211]\ttrain-rmse:0.25062\tvalid-rmse:0.45241\n",
      "\u001b[36m(XGBoostTrainer pid=1645, ip=100.64.27.77)\u001b[0m [12:15:32] [0]\ttrain-rmse:1.14700\tvalid-rmse:1.13158\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.783 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:15:33] [237]\ttrain-rmse:0.29762\tvalid-rmse:0.46422\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:15:35] [212]\ttrain-rmse:0.25012\tvalid-rmse:0.45234\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:15:37] [213]\ttrain-rmse:0.24986\tvalid-rmse:0.45226\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.690 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.690 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.690 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.690 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1645, ip=100.64.27.77)\u001b[0m [12:15:39] [1]\ttrain-rmse:1.13661\tvalid-rmse:1.12173\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:15:40] [238]\ttrain-rmse:0.29685\tvalid-rmse:0.46411\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:15:42] [214]\ttrain-rmse:0.24936\tvalid-rmse:0.45221\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1645, ip=100.64.27.77)\u001b[0m [12:15:44] [2]\ttrain-rmse:1.12619\tvalid-rmse:1.11173\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:15:46] [239]\ttrain-rmse:0.29653\tvalid-rmse:0.46410\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1645, ip=100.64.27.77)\u001b[0m [12:15:47] [3]\ttrain-rmse:1.11619\tvalid-rmse:1.10225\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.790 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:15:49] [240]\ttrain-rmse:0.29603\tvalid-rmse:0.46395\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:15:51] [215]\ttrain-rmse:0.24881\tvalid-rmse:0.45201\n",
      "\u001b[36m(XGBoostTrainer pid=1645, ip=100.64.27.77)\u001b[0m [12:15:53] [4]\ttrain-rmse:1.10641\tvalid-rmse:1.09300\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.780 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:15:54] [241]\ttrain-rmse:0.29551\tvalid-rmse:0.46374\n",
      "\u001b[36m(XGBoostTrainer pid=1645, ip=100.64.27.77)\u001b[0m [12:15:56] [5]\ttrain-rmse:1.09681\tvalid-rmse:1.08402\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1645, ip=100.64.27.77)\u001b[0m [12:15:58] [6]\ttrain-rmse:1.08741\tvalid-rmse:1.07522\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.787 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:16:00] [242]\ttrain-rmse:0.29513\tvalid-rmse:0.46353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 6 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:16:02. Total running time: 26min 50s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.4520076294103494 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      242            4.39172       0.295513       0.463743 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        216            6.03446       0.248814       0.452008 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   RUNNING        0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271           6            5.42571       1.09681        1.08402  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.830 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.830 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.830 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.830 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:16:02] [216]\ttrain-rmse:0.24825\tvalid-rmse:0.45200\n",
      "\u001b[36m(XGBoostTrainer pid=1645, ip=100.64.27.77)\u001b[0m [12:16:03] [7]\ttrain-rmse:1.07789\tvalid-rmse:1.06618\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:16:05] [217]\ttrain-rmse:0.24786\tvalid-rmse:0.45183\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1645, ip=100.64.27.77)\u001b[0m [12:16:07] [8]\ttrain-rmse:1.06938\tvalid-rmse:1.05834\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:16:09] [218]\ttrain-rmse:0.24736\tvalid-rmse:0.45159\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.745 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1645, ip=100.64.27.77)\u001b[0m [12:16:10] [9]\ttrain-rmse:1.06016\tvalid-rmse:1.04960\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:16:12] [219]\ttrain-rmse:0.24694\tvalid-rmse:0.45138\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1645, ip=100.64.27.77)\u001b[0m [12:16:14] [10]\ttrain-rmse:1.05136\tvalid-rmse:1.04132\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:16:16] [220]\ttrain-rmse:0.24638\tvalid-rmse:0.45135\n",
      "\u001b[36m(XGBoostTrainer pid=1645, ip=100.64.27.77)\u001b[0m [12:16:17] [11]\ttrain-rmse:1.04232\tvalid-rmse:1.03269\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.734 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1645, ip=100.64.27.77)\u001b[0m [12:16:19] [12]\ttrain-rmse:1.03381\tvalid-rmse:1.02480\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:16:21] [243]\ttrain-rmse:0.29457\tvalid-rmse:0.46342\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.777 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.944 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.944 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.944 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.944 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1645, ip=100.64.27.77)\u001b[0m [12:16:23] [13]\ttrain-rmse:1.02541\tvalid-rmse:1.01702\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:16:25] [244]\ttrain-rmse:0.29421\tvalid-rmse:0.46335\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1645, ip=100.64.27.77)\u001b[0m [12:16:26] [14]\ttrain-rmse:1.01829\tvalid-rmse:1.01023\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:16:28] [245]\ttrain-rmse:0.29392\tvalid-rmse:0.46332\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1645, ip=100.64.27.77)\u001b[0m [12:16:30] [15]\ttrain-rmse:1.00973\tvalid-rmse:1.00215\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:16:32] [221]\ttrain-rmse:0.24602\tvalid-rmse:0.45130\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 6 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:16:32. Total running time: 27min 20s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.45135078712862176 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      245            4.40065       0.294212       0.463354 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        221            6.04823       0.246377       0.451351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   RUNNING        0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          15            5.4515        1.01829        1.01023  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:16:33] [246]\ttrain-rmse:0.29341\tvalid-rmse:0.46317\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:16:35] [222]\ttrain-rmse:0.24566\tvalid-rmse:0.45127\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:16:37] [247]\ttrain-rmse:0.29311\tvalid-rmse:0.46315\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.776 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:16:39] [223]\ttrain-rmse:0.24516\tvalid-rmse:0.45117\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:16:41] [248]\ttrain-rmse:0.29293\tvalid-rmse:0.46307\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.773 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.739 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1645, ip=100.64.27.77)\u001b[0m [12:16:42] [16]\ttrain-rmse:1.00168\tvalid-rmse:0.99461\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.736 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:16:44] [249]\ttrain-rmse:0.29251\tvalid-rmse:0.46315\n",
      "\u001b[36m(XGBoostTrainer pid=1645, ip=100.64.27.77)\u001b[0m [12:16:46] [17]\ttrain-rmse:0.99489\tvalid-rmse:0.98814\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.777 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:16:48] [250]\ttrain-rmse:0.29188\tvalid-rmse:0.46303\n",
      "\u001b[36m(XGBoostTrainer pid=1645, ip=100.64.27.77)\u001b[0m [12:16:49] [18]\ttrain-rmse:0.98715\tvalid-rmse:0.98095\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1645, ip=100.64.27.77)\u001b[0m [12:16:51] [19]\ttrain-rmse:0.97926\tvalid-rmse:0.97356\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:16:53] [224]\ttrain-rmse:0.24474\tvalid-rmse:0.45107\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.736 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🏃 View run XGBoostTrainer_43af9c66 at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265/runs/c8dd58e392e34a8bb8806f32891bf186\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🧪 View experiment at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_43af9c66 completed after 20 iterations at 2025-09-01 12:16:55. Total running time: 27min 43s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_43af9c66 result             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ checkpoint_dir_name                              │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_this_iter_s                         0.00288 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_total_s                             5.46577 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ training_iteration                            20 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ train-rmse                               0.97926 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ valid-rmse                               0.97356 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:16:57] [251]\ttrain-rmse:0.29130\tvalid-rmse:0.46296\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:16:59] [225]\ttrain-rmse:0.24437\tvalid-rmse:0.45096\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.726 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_98b754ab started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_98b754ab config                          │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/alpha                               2.1385578767046853 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/colsample_bytree                    0.6848543762583863 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eta                                0.07748517670983293 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eval_metric                                       rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/lambda                            0.039292939147372065 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/max_depth                                            5 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/min_child_weight                     0.907939566198879 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/nthread                                              1 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/objective                             reg:squarederror │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/subsample                           0.8575046441243983 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/tree_method                                       hist │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m - (node_id=020c605741033b9152b4c9a349b6d58f62114a723ef561972a9adde1, ip=100.64.47.109, pid=980) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m - (node_id=020c605741033b9152b4c9a349b6d58f62114a723ef561972a9adde1, ip=100.64.47.109, pid=981) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m - (node_id=020c605741033b9152b4c9a349b6d58f62114a723ef561972a9adde1, ip=100.64.47.109, pid=982) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m - (node_id=020c605741033b9152b4c9a349b6d58f62114a723ef561972a9adde1, ip=100.64.47.109, pid=983) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(RayTrainWorker pid=980, ip=100.64.47.109)\u001b[0m [12:17:02] Task [xgboost.ray-rank=00000000]:055e9406f105db1b7ade48ab04000000 got rank 0\n",
      "\u001b[36m(RayTrainWorker pid=982, ip=100.64.47.109)\u001b[0m [12:17:02] Task [xgboost.ray-rank=00000002]:971df123941b87264a9ea8a204000000 got rank 2\n",
      "\u001b[36m(RayTrainWorker pid=983, ip=100.64.47.109)\u001b[0m [12:17:02] Task [xgboost.ray-rank=00000003]:96b2884725e4950eee36116b04000000 got rank 3\n",
      "\u001b[36m(RayTrainWorker pid=981, ip=100.64.47.109)\u001b[0m [12:17:02] Task [xgboost.ray-rank=00000001]:dd6fbae83edd1ce3ad3aa95504000000 got rank 1\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:17:02] [252]\ttrain-rmse:0.29103\tvalid-rmse:0.46292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 7 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:17:02. Total running time: 27min 50s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.45107045475628305 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      252            4.41985       0.291297       0.462962 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        225            6.05899       0.244742       0.45107  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   RUNNING        0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856                                                             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SplitCoordinator pid=1144, ip=100.64.47.109)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=1144, ip=100.64.47.109)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:17:03] [226]\ttrain-rmse:0.24379\tvalid-rmse:0.45096\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(SplitCoordinator pid=1147, ip=100.64.47.109)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=1147, ip=100.64.47.109)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:17:05] [253]\ttrain-rmse:0.29073\tvalid-rmse:0.46290\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:17:05] [0]\ttrain-rmse:1.10283\tvalid-rmse:1.08961\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:17:07] [227]\ttrain-rmse:0.24339\tvalid-rmse:0.45088\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:17:09] [254]\ttrain-rmse:0.29028\tvalid-rmse:0.46294\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.733 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:17:10] [228]\ttrain-rmse:0.24294\tvalid-rmse:0.45076\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.730 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:17:12] [255]\ttrain-rmse:0.28988\tvalid-rmse:0.46313\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.683 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.683 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.683 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.683 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:17:14] [1]\ttrain-rmse:1.07364\tvalid-rmse:1.06168\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.737 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:17:16] [256]\ttrain-rmse:0.28967\tvalid-rmse:0.46310\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.742 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:17:17] [229]\ttrain-rmse:0.24251\tvalid-rmse:0.45070\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:17:19] [2]\ttrain-rmse:1.04290\tvalid-rmse:1.03224\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.733 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:17:21] [230]\ttrain-rmse:0.24193\tvalid-rmse:0.45069\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.798 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:17:23] [3]\ttrain-rmse:1.01403\tvalid-rmse:1.00485\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.713 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.714 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.714 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.714 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:17:24] [231]\ttrain-rmse:0.24148\tvalid-rmse:0.45059\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:17:26] [4]\ttrain-rmse:0.96938\tvalid-rmse:0.96251\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:17:28] [232]\ttrain-rmse:0.24111\tvalid-rmse:0.45049\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.730 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:17:30] [5]\ttrain-rmse:0.93599\tvalid-rmse:0.92949\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:17:31] [233]\ttrain-rmse:0.24069\tvalid-rmse:0.45047\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:17:33] [234]\ttrain-rmse:0.24030\tvalid-rmse:0.45035\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 7 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:17:33. Total running time: 28min 21s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.4504698425596392 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      256            4.43044       0.289883       0.463132 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        234            6.08323       0.240693       0.45047  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   RUNNING        0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856          5            5.57625       0.969382       0.962511 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:17:35] [6]\ttrain-rmse:0.89911\tvalid-rmse:0.89574\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.793 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:17:37] [235]\ttrain-rmse:0.23999\tvalid-rmse:0.45026\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.782 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:17:38] [257]\ttrain-rmse:0.28940\tvalid-rmse:0.46317\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.788 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:17:40] [7]\ttrain-rmse:0.87680\tvalid-rmse:0.87462\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.784 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:17:42] [258]\ttrain-rmse:0.28921\tvalid-rmse:0.46313\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:17:44] [8]\ttrain-rmse:0.84554\tvalid-rmse:0.84640\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.943 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.944 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.944 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.944 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:17:46] [259]\ttrain-rmse:0.28890\tvalid-rmse:0.46314\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.812 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.813 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.813 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.813 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:17:47] [9]\ttrain-rmse:0.82187\tvalid-rmse:0.82307\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:17:49] [260]\ttrain-rmse:0.28859\tvalid-rmse:0.46314\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.789 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.783 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:17:51] [236]\ttrain-rmse:0.23961\tvalid-rmse:0.45017\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.811 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.811 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.811 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.811 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:17:53] [10]\ttrain-rmse:0.79400\tvalid-rmse:0.79804\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.789 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:17:55] [237]\ttrain-rmse:0.23915\tvalid-rmse:0.45021\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:17:56] [11]\ttrain-rmse:0.76998\tvalid-rmse:0.77651\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.796 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:17:58] [238]\ttrain-rmse:0.23878\tvalid-rmse:0.45010\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.788 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.777 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:18:00] [12]\ttrain-rmse:0.74905\tvalid-rmse:0.75834\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.814 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.814 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.814 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.814 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:18:02] [239]\ttrain-rmse:0.23834\tvalid-rmse:0.45014\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:18:04] [13]\ttrain-rmse:0.72823\tvalid-rmse:0.73969\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.783 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 7 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:18:04. Total running time: 28min 52s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.45009925409316515 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      260            4.44183       0.288902       0.463139 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        239            6.0967        0.238778       0.450099 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   RUNNING        0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         13            5.59979       0.74905        0.758336 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:18:05] [261]\ttrain-rmse:0.28823\tvalid-rmse:0.46325\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.785 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:18:07] [240]\ttrain-rmse:0.23809\tvalid-rmse:0.45008\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.787 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:18:09] [262]\ttrain-rmse:0.28780\tvalid-rmse:0.46320\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:18:11] [14]\ttrain-rmse:0.71649\tvalid-rmse:0.72893\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:18:13] [241]\ttrain-rmse:0.23766\tvalid-rmse:0.44997\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:18:14] [263]\ttrain-rmse:0.28738\tvalid-rmse:0.46320\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.783 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:18:16] [264]\ttrain-rmse:0.28698\tvalid-rmse:0.46312\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.786 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:18:18] [242]\ttrain-rmse:0.23715\tvalid-rmse:0.44999\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:18:20] [15]\ttrain-rmse:0.69795\tvalid-rmse:0.71192\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:18:21] [265]\ttrain-rmse:0.28666\tvalid-rmse:0.46298\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.783 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:18:23] [16]\ttrain-rmse:0.68216\tvalid-rmse:0.69706\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:18:25] [266]\ttrain-rmse:0.28620\tvalid-rmse:0.46307\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:18:27] [267]\ttrain-rmse:0.28578\tvalid-rmse:0.46301\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.771 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:18:28] [17]\ttrain-rmse:0.67383\tvalid-rmse:0.68974\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:18:30] [268]\ttrain-rmse:0.28526\tvalid-rmse:0.46301\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:18:32] [18]\ttrain-rmse:0.66671\tvalid-rmse:0.68402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 7 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:18:34. Total running time: 29min 22s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.449971295904189 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      269            4.46698       0.285263       0.463014 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        242            6.10495       0.237664       0.449971 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   RUNNING        0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         18            5.61414       0.673831       0.689744 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:18:34] [269]\ttrain-rmse:0.28492\tvalid-rmse:0.46300\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:18:36] [243]\ttrain-rmse:0.23677\tvalid-rmse:0.44997\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:18:37] [19]\ttrain-rmse:0.65323\tvalid-rmse:0.67182\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.792 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.771 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:18:39] [244]\ttrain-rmse:0.23637\tvalid-rmse:0.44981\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:18:41] [20]\ttrain-rmse:0.64159\tvalid-rmse:0.66117\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:18:43] [245]\ttrain-rmse:0.23597\tvalid-rmse:0.44983\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:18:44] [270]\ttrain-rmse:0.28446\tvalid-rmse:0.46324\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:18:46] [21]\ttrain-rmse:0.63196\tvalid-rmse:0.65267\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.739 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:18:48] [271]\ttrain-rmse:0.28407\tvalid-rmse:0.46344\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:18:50] [246]\ttrain-rmse:0.23550\tvalid-rmse:0.44984\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:18:51] [272]\ttrain-rmse:0.28368\tvalid-rmse:0.46346\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:18:53] [247]\ttrain-rmse:0.23517\tvalid-rmse:0.44993\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:18:55] [273]\ttrain-rmse:0.28315\tvalid-rmse:0.46342\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.784 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:18:57] [248]\ttrain-rmse:0.23495\tvalid-rmse:0.44990\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.742 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:18:58] [249]\ttrain-rmse:0.23469\tvalid-rmse:0.44980\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:19:00] [274]\ttrain-rmse:0.28285\tvalid-rmse:0.46346\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.742 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:19:02] [250]\ttrain-rmse:0.23421\tvalid-rmse:0.44973\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.820 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.820 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.820 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.820 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.732 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:19:04] [275]\ttrain-rmse:0.28246\tvalid-rmse:0.46347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 7 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:19:05. Total running time: 29min 53s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44973008162821987 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      275            4.48678       0.282849       0.463461 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        251            6.12907       0.234206       0.44973  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   RUNNING        0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         21            5.62284       0.641595       0.661172 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.745 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:19:05] [251]\ttrain-rmse:0.23362\tvalid-rmse:0.44958\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:19:07] [276]\ttrain-rmse:0.28205\tvalid-rmse:0.46326\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.935 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.936 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.936 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.936 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:19:09] [22]\ttrain-rmse:0.62028\tvalid-rmse:0.64140\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:19:11] [277]\ttrain-rmse:0.28158\tvalid-rmse:0.46310\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:19:13] [23]\ttrain-rmse:0.61061\tvalid-rmse:0.63282\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.783 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:19:14] [278]\ttrain-rmse:0.28127\tvalid-rmse:0.46316\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:19:16] [24]\ttrain-rmse:0.60293\tvalid-rmse:0.62580\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:19:18] [252]\ttrain-rmse:0.23308\tvalid-rmse:0.44940\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:19:20] [279]\ttrain-rmse:0.28036\tvalid-rmse:0.46259\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:19:22] [25]\ttrain-rmse:0.59550\tvalid-rmse:0.62016\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:19:23] [280]\ttrain-rmse:0.28003\tvalid-rmse:0.46251\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:19:25] [26]\ttrain-rmse:0.58840\tvalid-rmse:0.61399\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:19:27] [281]\ttrain-rmse:0.27974\tvalid-rmse:0.46250\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.781 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:19:29] [27]\ttrain-rmse:0.57637\tvalid-rmse:0.60286\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.794 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:19:30] [28]\ttrain-rmse:0.57103\tvalid-rmse:0.59845\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.811 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.811 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.811 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.811 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:19:32] [282]\ttrain-rmse:0.27929\tvalid-rmse:0.46233\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.810 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.810 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.810 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.810 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:19:34] [29]\ttrain-rmse:0.56353\tvalid-rmse:0.59137\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.812 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.812 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.813 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.813 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 7 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:19:36. Total running time: 30min 24s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44958105439924045 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      283            4.50916       0.279293       0.462327 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        252            6.13169       0.233623       0.449581 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   RUNNING        0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         29            5.64639       0.571032       0.598453 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.811 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.811 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.811 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.811 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:19:36] [283]\ttrain-rmse:0.27885\tvalid-rmse:0.46210\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:19:38] [253]\ttrain-rmse:0.23269\tvalid-rmse:0.44941\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.771 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:19:39] [284]\ttrain-rmse:0.27833\tvalid-rmse:0.46197\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.773 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:19:41] [285]\ttrain-rmse:0.27787\tvalid-rmse:0.46201\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.771 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:19:43] [30]\ttrain-rmse:0.55932\tvalid-rmse:0.58832\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:19:45] [286]\ttrain-rmse:0.27751\tvalid-rmse:0.46206\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:19:47] [31]\ttrain-rmse:0.55490\tvalid-rmse:0.58495\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.787 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:19:48] [254]\ttrain-rmse:0.23250\tvalid-rmse:0.44941\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:19:50] [287]\ttrain-rmse:0.27723\tvalid-rmse:0.46215\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.789 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.823 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.823 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.823 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.823 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:19:52] [32]\ttrain-rmse:0.55118\tvalid-rmse:0.58186\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.822 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.822 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.822 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.823 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:19:54] [255]\ttrain-rmse:0.23207\tvalid-rmse:0.44943\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.794 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:19:56] [33]\ttrain-rmse:0.54645\tvalid-rmse:0.57826\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.808 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.809 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.809 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.809 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:19:57] [256]\ttrain-rmse:0.23166\tvalid-rmse:0.44935\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.798 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:19:59] [288]\ttrain-rmse:0.27646\tvalid-rmse:0.46187\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.785 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:20:01] [257]\ttrain-rmse:0.23126\tvalid-rmse:0.44925\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:20:03] [289]\ttrain-rmse:0.27601\tvalid-rmse:0.46181\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.789 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:20:04] [258]\ttrain-rmse:0.23093\tvalid-rmse:0.44926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 7 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:20:06. Total running time: 30min 54s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.4492485203945615 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      290            4.52851       0.276012       0.461808 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        258            6.14757       0.231264       0.449249 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   RUNNING        0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         33            5.65797       0.551184       0.581864 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.776 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:20:06] [290]\ttrain-rmse:0.27564\tvalid-rmse:0.46188\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:20:08] [259]\ttrain-rmse:0.23058\tvalid-rmse:0.44929\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.771 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:20:10] [291]\ttrain-rmse:0.27526\tvalid-rmse:0.46190\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:20:12] [260]\ttrain-rmse:0.23018\tvalid-rmse:0.44928\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.745 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:20:13] [292]\ttrain-rmse:0.27473\tvalid-rmse:0.46154\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:20:15] [261]\ttrain-rmse:0.22980\tvalid-rmse:0.44922\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:20:17] [34]\ttrain-rmse:0.54259\tvalid-rmse:0.57533\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.776 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:20:19] [262]\ttrain-rmse:0.22962\tvalid-rmse:0.44922\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:20:20] [293]\ttrain-rmse:0.27454\tvalid-rmse:0.46153\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.733 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:20:22] [35]\ttrain-rmse:0.54000\tvalid-rmse:0.57325\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:20:24] [36]\ttrain-rmse:0.53630\tvalid-rmse:0.57011\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:20:26] [294]\ttrain-rmse:0.27415\tvalid-rmse:0.46155\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.794 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:20:27] [37]\ttrain-rmse:0.53323\tvalid-rmse:0.56788\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.806 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.806 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.806 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.806 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.798 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:20:29] [263]\ttrain-rmse:0.22935\tvalid-rmse:0.44926\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:20:31] [38]\ttrain-rmse:0.52996\tvalid-rmse:0.56528\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.928 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.928 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.928 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.928 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.789 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:20:33] [264]\ttrain-rmse:0.22894\tvalid-rmse:0.44927\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.791 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:20:35] [39]\ttrain-rmse:0.52734\tvalid-rmse:0.56351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 7 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:20:37. Total running time: 31min 24s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.4492645765091259 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      295            4.5429        0.274148       0.461554 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        264            6.16427       0.229346       0.449265 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   RUNNING        0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         39            5.6752        0.52996        0.565278 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:20:37] [295]\ttrain-rmse:0.27374\tvalid-rmse:0.46161\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.720 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.721 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.721 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.721 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:20:38] [265]\ttrain-rmse:0.22858\tvalid-rmse:0.44931\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:20:40] [296]\ttrain-rmse:0.27334\tvalid-rmse:0.46162\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:20:42] [266]\ttrain-rmse:0.22818\tvalid-rmse:0.44937\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:20:44] [297]\ttrain-rmse:0.27293\tvalid-rmse:0.46157\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:20:45] [40]\ttrain-rmse:0.52328\tvalid-rmse:0.56001\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:20:47] [267]\ttrain-rmse:0.22781\tvalid-rmse:0.44936\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.782 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:20:49] [41]\ttrain-rmse:0.52138\tvalid-rmse:0.55891\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:20:51] [268]\ttrain-rmse:0.22740\tvalid-rmse:0.44932\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:20:52] [42]\ttrain-rmse:0.51926\tvalid-rmse:0.55754\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:20:54] [269]\ttrain-rmse:0.22705\tvalid-rmse:0.44936\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.777 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:20:56] [43]\ttrain-rmse:0.51726\tvalid-rmse:0.55619\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.777 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:20:58] [270]\ttrain-rmse:0.22666\tvalid-rmse:0.44936\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:20:59] [44]\ttrain-rmse:0.51409\tvalid-rmse:0.55343\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.787 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:21:01] [298]\ttrain-rmse:0.27260\tvalid-rmse:0.46166\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.792 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:21:03] [271]\ttrain-rmse:0.22631\tvalid-rmse:0.44921\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:21:05] [45]\ttrain-rmse:0.51226\tvalid-rmse:0.55246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 7 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:21:07. Total running time: 31min 54s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44921413476884636 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   RUNNING        0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      298            4.5513        0.272926       0.461574 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        272            6.1859        0.226307       0.449214 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   RUNNING        0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         45            5.73591       0.514092       0.553433 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:21:07] [272]\ttrain-rmse:0.22585\tvalid-rmse:0.44905\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.786 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:21:08] [46]\ttrain-rmse:0.51067\tvalid-rmse:0.55151\n",
      "\u001b[36m(XGBoostTrainer pid=1210, ip=100.64.8.234)\u001b[0m [12:21:10] [299]\ttrain-rmse:0.27221\tvalid-rmse:0.46167\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.777 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:21:12] [47]\ttrain-rmse:0.50855\tvalid-rmse:0.55003\n",
      "\u001b[36m(RayTrainWorker pid=1256, ip=100.64.8.234)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=s3, path=ddl-wadkars/end-to-end/california/air/xgb/xgb_from_s3_irsa/XGBoostTrainer_1ef99b81_7_alpha=0.0276,colsample_bytree=0.8024,eta=0.0761,eval_metric=rmse,lambda=0.1115,max_depth=6,min_child_wei_2025-09-01_11-54-48/checkpoint_000000)\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:21:14] [273]\ttrain-rmse:0.22552\tvalid-rmse:0.44896\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:21:15] [48]\ttrain-rmse:0.50699\tvalid-rmse:0.54916\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.713 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.713 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.713 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.713 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:21:17] [274]\ttrain-rmse:0.22506\tvalid-rmse:0.44900\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.735 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.728 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:21:19] [49]\ttrain-rmse:0.50527\tvalid-rmse:0.54817\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:21:21] [275]\ttrain-rmse:0.22467\tvalid-rmse:0.44889\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:21:22] [50]\ttrain-rmse:0.50410\tvalid-rmse:0.54728\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.710 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.710 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.710 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.710 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🏃 View run XGBoostTrainer_1ef99b81 at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265/runs/1f006357297242ccbc06c53b50bbdd39\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🧪 View experiment at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_1ef99b81 completed after 300 iterations at 2025-09-01 12:21:24. Total running time: 32min 12s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_1ef99b81 result             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ checkpoint_dir_name                              │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_this_iter_s                         0.00243 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_total_s                             4.55643 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ training_iteration                           300 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ train-rmse                               0.27221 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ valid-rmse                               0.46167 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:21:26] [51]\ttrain-rmse:0.50258\tvalid-rmse:0.54648\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:21:28] [52]\ttrain-rmse:0.49986\tvalid-rmse:0.54439\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_414a200b started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_414a200b config                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/alpha                                 7.319837848553307 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/colsample_bytree                     0.8887589555784239 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eta                               0.0029118910818443852 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eval_metric                                        rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/lambda                            0.0027046377650259603 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/max_depth                                            10 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/min_child_weight                   0.031035885098939307 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/nthread                                               1 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/objective                              reg:squarederror │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/subsample                            0.9050687125540889 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/tree_method                                        hist │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=2238, ip=100.64.27.77)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=2238, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=2284) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=2238, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=2285) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=2238, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=2286) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=2238, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=2287) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:21:31] [53]\ttrain-rmse:0.49684\tvalid-rmse:0.54180\n",
      "\u001b[36m(RayTrainWorker pid=2285, ip=100.64.27.77)\u001b[0m [12:21:31] Task [xgboost.ray-rank=00000001]:7907a641b648cbe4423ca8b004000000 got rank 1\n",
      "\u001b[36m(RayTrainWorker pid=2284, ip=100.64.27.77)\u001b[0m [12:21:31] Task [xgboost.ray-rank=00000000]:0bd35de6e312f784ab640a7904000000 got rank 0\n",
      "\u001b[36m(RayTrainWorker pid=2286, ip=100.64.27.77)\u001b[0m [12:21:31] Task [xgboost.ray-rank=00000002]:31ff03720e6aff76e7ef2e1304000000 got rank 2\n",
      "\u001b[36m(RayTrainWorker pid=2287, ip=100.64.27.77)\u001b[0m [12:21:31] Task [xgboost.ray-rank=00000003]:6b1584ff10ed6cac55a0aa5b04000000 got rank 3\n",
      "\u001b[36m(SplitCoordinator pid=2448, ip=100.64.27.77)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=2448, ip=100.64.27.77)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:21:33] [276]\ttrain-rmse:0.22435\tvalid-rmse:0.44881\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.734 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:21:34] [54]\ttrain-rmse:0.49559\tvalid-rmse:0.54113\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.735 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:21:36] [277]\ttrain-rmse:0.22382\tvalid-rmse:0.44871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 8 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:21:38. Total running time: 32min 26s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 16.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.4488121860664563 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        277            6.19968       0.224349       0.448812 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   RUNNING        0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         55            5.76399       0.495587       0.541135 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   RUNNING        0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984                                                             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:21:38] [55]\ttrain-rmse:0.49393\tvalid-rmse:0.54005\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:21:40] [56]\ttrain-rmse:0.49274\tvalid-rmse:0.53936\n",
      "\u001b[36m(SplitCoordinator pid=2449, ip=100.64.27.77)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=2449, ip=100.64.27.77)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=2238, ip=100.64.27.77)\u001b[0m [12:21:41] [0]\ttrain-rmse:1.15514\tvalid-rmse:1.13928\n",
      "\u001b[36m(XGBoostTrainer pid=2238, ip=100.64.27.77)\u001b[0m [12:21:41] [1]\ttrain-rmse:1.15275\tvalid-rmse:1.13707\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:21:41] [278]\ttrain-rmse:0.22355\tvalid-rmse:0.44864\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.680 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.681 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.681 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.681 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2238, ip=100.64.27.77)\u001b[0m [12:21:43] [2]\ttrain-rmse:1.15034\tvalid-rmse:1.13480\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:21:45] [279]\ttrain-rmse:0.22311\tvalid-rmse:0.44856\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.730 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2238, ip=100.64.27.77)\u001b[0m [12:21:47] [3]\ttrain-rmse:1.14804\tvalid-rmse:1.13266\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:21:48] [57]\ttrain-rmse:0.49141\tvalid-rmse:0.53910\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.718 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.719 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.719 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.719 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:21:50] [58]\ttrain-rmse:0.48985\tvalid-rmse:0.53780\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:21:52] [280]\ttrain-rmse:0.22281\tvalid-rmse:0.44857\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=934, ip=100.64.47.109)\u001b[0m [12:21:54] [59]\ttrain-rmse:0.48904\tvalid-rmse:0.53735\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.938 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.938 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.938 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.938 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:21:56] [281]\ttrain-rmse:0.22251\tvalid-rmse:0.44863\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.781 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🏃 View run XGBoostTrainer_98b754ab at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265/runs/8dccbbee62284dd69ae95d095060f568\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🧪 View experiment at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_98b754ab completed after 60 iterations at 2025-09-01 12:21:58. Total running time: 32min 46s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_98b754ab result             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ checkpoint_dir_name                              │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_this_iter_s                         0.00276 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_total_s                             5.77824 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ training_iteration                            60 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ train-rmse                               0.48904 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ valid-rmse                               0.53735 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:22:00] [282]\ttrain-rmse:0.22216\tvalid-rmse:0.44862\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.792 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2238, ip=100.64.27.77)\u001b[0m [12:22:01] [4]\ttrain-rmse:1.14569\tvalid-rmse:1.13047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_6092156f started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_6092156f config                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/alpha                              0.010317367265492358 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/colsample_bytree                     0.6518764709084958 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eta                                0.012164537995743827 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eval_metric                                        rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/lambda                            0.0045297716329835746 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/max_depth                                             8 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/min_child_weight                     1.7644633469535227 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/nthread                                               1 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/objective                              reg:squarederror │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/subsample                            0.9029293717465706 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/tree_method                                        hist │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=1763, ip=100.64.8.234)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=1763, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=1809) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=1763, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=1810) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=1763, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=1811) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=1763, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=1812) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:22:04] [283]\ttrain-rmse:0.22182\tvalid-rmse:0.44858\n",
      "\u001b[36m(RayTrainWorker pid=1809, ip=100.64.8.234)\u001b[0m [12:22:04] Task [xgboost.ray-rank=00000000]:b5b7eb2f37ef368accaac80f04000000 got rank 0\n",
      "\u001b[36m(RayTrainWorker pid=1810, ip=100.64.8.234)\u001b[0m [12:22:04] Task [xgboost.ray-rank=00000001]:5a832ef4f3c120b78fa2521f04000000 got rank 1\n",
      "\u001b[36m(RayTrainWorker pid=1812, ip=100.64.8.234)\u001b[0m [12:22:04] Task [xgboost.ray-rank=00000003]:9410d66c948d807024c5832604000000 got rank 3\n",
      "\u001b[36m(RayTrainWorker pid=1811, ip=100.64.8.234)\u001b[0m [12:22:04] Task [xgboost.ray-rank=00000002]:c0572823a43ddb087e164ac304000000 got rank 2\n",
      "\u001b[36m(SplitCoordinator pid=1973, ip=100.64.8.234)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=1973, ip=100.64.8.234)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2238, ip=100.64.27.77)\u001b[0m [12:22:06] [5]\ttrain-rmse:1.14331\tvalid-rmse:1.12826\n",
      "\u001b[36m(SplitCoordinator pid=1974, ip=100.64.8.234)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=1974, ip=100.64.8.234)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=1763, ip=100.64.8.234)\u001b[0m [12:22:08] [0]\ttrain-rmse:1.14715\tvalid-rmse:1.13198\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:22:08] [284]\ttrain-rmse:0.22155\tvalid-rmse:0.44851\n",
      "\u001b[36m(XGBoostTrainer pid=2238, ip=100.64.27.77)\u001b[0m [12:22:10] [6]\ttrain-rmse:1.14104\tvalid-rmse:1.12617\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.780 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 9 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:22:10. Total running time: 32min 58s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.4485765306098917 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        284            6.21863       0.221822       0.448577 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   RUNNING        0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984          5           11.9563        1.14569        1.13047  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   RUNNING        0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.787 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:22:12] [285]\ttrain-rmse:0.22119\tvalid-rmse:0.44851\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.803 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.804 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.804 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.804 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2238, ip=100.64.27.77)\u001b[0m [12:22:13] [7]\ttrain-rmse:1.13861\tvalid-rmse:1.12389\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:22:15] [286]\ttrain-rmse:0.22087\tvalid-rmse:0.44838\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.776 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.731 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1763, ip=100.64.8.234)\u001b[0m [12:22:17] [1]\ttrain-rmse:1.13906\tvalid-rmse:1.12456\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:22:19] [287]\ttrain-rmse:0.22052\tvalid-rmse:0.44843\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.780 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1763, ip=100.64.8.234)\u001b[0m [12:22:20] [2]\ttrain-rmse:1.13139\tvalid-rmse:1.11744\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:22:22] [288]\ttrain-rmse:0.22013\tvalid-rmse:0.44829\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.844 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.845 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.845 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.845 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2238, ip=100.64.27.77)\u001b[0m [12:22:24] [8]\ttrain-rmse:1.13635\tvalid-rmse:1.12183\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.799 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.793 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:22:26] [289]\ttrain-rmse:0.21968\tvalid-rmse:0.44828\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.794 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2238, ip=100.64.27.77)\u001b[0m [12:22:28] [9]\ttrain-rmse:1.13399\tvalid-rmse:1.11965\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.798 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:22:29] [290]\ttrain-rmse:0.21941\tvalid-rmse:0.44824\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.788 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2238, ip=100.64.27.77)\u001b[0m [12:22:31] [10]\ttrain-rmse:1.13174\tvalid-rmse:1.11759\n",
      "\u001b[36m(XGBoostTrainer pid=1763, ip=100.64.8.234)\u001b[0m [12:22:33] [3]\ttrain-rmse:1.12371\tvalid-rmse:1.11024\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.799 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.786 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:22:35] [291]\ttrain-rmse:0.21919\tvalid-rmse:0.44825\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.789 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1763, ip=100.64.8.234)\u001b[0m [12:22:37] [4]\ttrain-rmse:1.11340\tvalid-rmse:1.10064\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.777 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:22:38] [292]\ttrain-rmse:0.21891\tvalid-rmse:0.44828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 9 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:22:40. Total running time: 33min 28s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44824995232515547 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   RUNNING        0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        292            6.24116       0.219186       0.44825  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   RUNNING        0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         10           11.9701        1.13399        1.11965  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   RUNNING        0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174        4            5.26131       1.12371        1.11024  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.787 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2238, ip=100.64.27.77)\u001b[0m [12:22:40] [11]\ttrain-rmse:1.12936\tvalid-rmse:1.11536\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:22:42] [293]\ttrain-rmse:0.21867\tvalid-rmse:0.44825\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:22:44] [294]\ttrain-rmse:0.21826\tvalid-rmse:0.44819\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.796 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1763, ip=100.64.8.234)\u001b[0m [12:22:46] [5]\ttrain-rmse:1.10494\tvalid-rmse:1.09253\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.799 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.791 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:22:47] [295]\ttrain-rmse:0.21782\tvalid-rmse:0.44820\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.808 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.808 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.808 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.808 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1763, ip=100.64.8.234)\u001b[0m [12:22:49] [6]\ttrain-rmse:1.09543\tvalid-rmse:1.08398\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:22:51] [296]\ttrain-rmse:0.21750\tvalid-rmse:0.44822\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.792 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.788 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1763, ip=100.64.8.234)\u001b[0m [12:22:53] [7]\ttrain-rmse:1.08725\tvalid-rmse:1.07623\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:22:55] [297]\ttrain-rmse:0.21709\tvalid-rmse:0.44808\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.794 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1763, ip=100.64.8.234)\u001b[0m [12:22:56] [8]\ttrain-rmse:1.07744\tvalid-rmse:1.06722\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.802 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.802 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.802 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.802 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.787 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:22:58] [298]\ttrain-rmse:0.21672\tvalid-rmse:0.44803\n",
      "\u001b[36m(XGBoostTrainer pid=1763, ip=100.64.8.234)\u001b[0m [12:23:00] [9]\ttrain-rmse:1.06941\tvalid-rmse:1.05957\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.781 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.802 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.803 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.803 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.803 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=869, ip=100.64.25.122)\u001b[0m [12:23:02] [299]\ttrain-rmse:0.21642\tvalid-rmse:0.44805\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1763, ip=100.64.8.234)\u001b[0m [12:23:04] [10]\ttrain-rmse:1.06050\tvalid-rmse:1.05152\n",
      "\u001b[36m(RayTrainWorker pid=915, ip=100.64.25.122)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=s3, path=ddl-wadkars/end-to-end/california/air/xgb/xgb_from_s3_irsa/XGBoostTrainer_ca919a62_8_alpha=1.7026,colsample_bytree=0.7012,eta=0.0409,eval_metric=rmse,lambda=0.0050,max_depth=10,min_child_we_2025-09-01_11-56-26/checkpoint_000000)\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.796 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🏃 View run XGBoostTrainer_ca919a62 at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265/runs/8f596914bac54da381b09b042ee17eaf\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🧪 View experiment at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_ca919a62 completed after 300 iterations at 2025-09-01 12:23:06. Total running time: 33min 54s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_ca919a62 result             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ checkpoint_dir_name                              │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_this_iter_s                         0.00275 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_total_s                              6.2634 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ training_iteration                           300 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ train-rmse                               0.21642 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ valid-rmse                               0.44805 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.789 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2238, ip=100.64.27.77)\u001b[0m [12:23:08] [12]\ttrain-rmse:1.12714\tvalid-rmse:1.11335\n",
      "\u001b[36m(XGBoostTrainer pid=1763, ip=100.64.8.234)\u001b[0m [12:23:10] [11]\ttrain-rmse:1.05126\tvalid-rmse:1.04314\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2238, ip=100.64.27.77)\u001b[0m [12:23:11] [13]\ttrain-rmse:1.12490\tvalid-rmse:1.11129\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.792 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 10 TERMINATED | 2 RUNNING | 1 PENDING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:23:11. Total running time: 33min 59s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   RUNNING        0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         12           11.9759        1.12936        1.11536  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   RUNNING        0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       11            5.28114       1.0605         1.05152  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   PENDING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521                                                             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=1763, ip=100.64.8.234)\u001b[0m [12:23:13] [12]\ttrain-rmse:1.04300\tvalid-rmse:1.03574\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.792 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2238, ip=100.64.27.77)\u001b[0m [12:23:15] [14]\ttrain-rmse:1.12265\tvalid-rmse:1.10918\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_7d9e932d started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_7d9e932d config                         │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/alpha                               7.795208486746143 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/colsample_bytree                   0.7198720350368294 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eta                                0.0649386837151865 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eval_metric                                      rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/lambda                             1.7913683126226772 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/max_depth                                          10 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/min_child_weight                  0.10532032112562299 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/nthread                                             1 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/objective                            reg:squarederror │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/subsample                          0.7804785213514531 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/tree_method                                      hist │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m - (node_id=020c605741033b9152b4c9a349b6d58f62114a723ef561972a9adde1, ip=100.64.47.109, pid=1574) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m - (node_id=020c605741033b9152b4c9a349b6d58f62114a723ef561972a9adde1, ip=100.64.47.109, pid=1575) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m - (node_id=020c605741033b9152b4c9a349b6d58f62114a723ef561972a9adde1, ip=100.64.47.109, pid=1576) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m - (node_id=020c605741033b9152b4c9a349b6d58f62114a723ef561972a9adde1, ip=100.64.47.109, pid=1577) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.781 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2238, ip=100.64.27.77)\u001b[0m [12:23:18] [15]\ttrain-rmse:1.12027\tvalid-rmse:1.10695\n",
      "\u001b[36m(RayTrainWorker pid=1576, ip=100.64.47.109)\u001b[0m [12:23:18] Task [xgboost.ray-rank=00000002]:858afbbc735413051f11862404000000 got rank 2\n",
      "\u001b[36m(RayTrainWorker pid=1574, ip=100.64.47.109)\u001b[0m [12:23:18] Task [xgboost.ray-rank=00000000]:31cf8d64f143c9cc1f29e46704000000 got rank 0\n",
      "\u001b[36m(RayTrainWorker pid=1575, ip=100.64.47.109)\u001b[0m [12:23:18] Task [xgboost.ray-rank=00000001]:e96f1fd2e163d2251903735f04000000 got rank 1\n",
      "\u001b[36m(RayTrainWorker pid=1577, ip=100.64.47.109)\u001b[0m [12:23:18] Task [xgboost.ray-rank=00000003]:e962f81f97f14b3357265e1c04000000 got rank 3\n",
      "\u001b[36m(SplitCoordinator pid=1738, ip=100.64.47.109)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=1738, ip=100.64.47.109)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.801 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.801 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.801 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.801 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1763, ip=100.64.8.234)\u001b[0m [12:23:20] [13]\ttrain-rmse:1.03425\tvalid-rmse:1.02779\n",
      "\u001b[36m(SplitCoordinator pid=1739, ip=100.64.47.109)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=1739, ip=100.64.47.109)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.787 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:23:22] [0]\ttrain-rmse:1.10799\tvalid-rmse:1.09584\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:23:22] [1]\ttrain-rmse:1.07069\tvalid-rmse:1.06224\n",
      "\u001b[36m(XGBoostTrainer pid=2238, ip=100.64.27.77)\u001b[0m [12:23:22] [16]\ttrain-rmse:1.11799\tvalid-rmse:1.10485\n",
      "\u001b[36m(XGBoostTrainer pid=1763, ip=100.64.8.234)\u001b[0m [12:23:23] [14]\ttrain-rmse:1.02747\tvalid-rmse:1.02147\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2238, ip=100.64.27.77)\u001b[0m [12:23:25] [17]\ttrain-rmse:1.11571\tvalid-rmse:1.10271\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.786 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2238, ip=100.64.27.77)\u001b[0m [12:23:27] [18]\ttrain-rmse:1.11353\tvalid-rmse:1.10072\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.781 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1763, ip=100.64.8.234)\u001b[0m [12:23:29] [15]\ttrain-rmse:1.01879\tvalid-rmse:1.01370\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:23:30] [2]\ttrain-rmse:1.03625\tvalid-rmse:1.03063\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.714 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.715 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.715 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.715 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.777 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1763, ip=100.64.8.234)\u001b[0m [12:23:32] [16]\ttrain-rmse:1.01037\tvalid-rmse:1.00592\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.786 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:23:34] [3]\ttrain-rmse:1.00384\tvalid-rmse:1.00038\n",
      "\u001b[36m(XGBoostTrainer pid=1763, ip=100.64.8.234)\u001b[0m [12:23:36] [17]\ttrain-rmse:1.00478\tvalid-rmse:1.00101\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.789 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:23:38] [4]\ttrain-rmse:0.96082\tvalid-rmse:0.96042\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.820 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.821 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.821 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.821 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2238, ip=100.64.27.77)\u001b[0m [12:23:39] [19]\ttrain-rmse:1.11121\tvalid-rmse:1.09857\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:23:41] [5]\ttrain-rmse:0.92646\tvalid-rmse:0.92766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 10 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:23:43. Total running time: 34min 31s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   RUNNING        0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         18           11.9932        1.11571        1.10271  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   RUNNING        0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       18            5.30057       1.00478        1.00101  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521          4            5.37078       1.00384        1.00038  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.777 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1763, ip=100.64.8.234)\u001b[0m [12:23:43] [18]\ttrain-rmse:0.99927\tvalid-rmse:0.99635\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.799 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:23:45] [6]\ttrain-rmse:0.89234\tvalid-rmse:0.89730\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.808 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.809 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.809 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.809 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1763, ip=100.64.8.234)\u001b[0m [12:23:47] [19]\ttrain-rmse:0.99069\tvalid-rmse:0.98848\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.773 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2238, ip=100.64.27.77)\u001b[0m [12:23:48] [20]\ttrain-rmse:1.10896\tvalid-rmse:1.09650\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:23:50] [7]\ttrain-rmse:0.86116\tvalid-rmse:0.86792\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.781 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🏃 View run XGBoostTrainer_414a200b at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265/runs/7c59472b9db74ad0bae76055c62eafb7\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🧪 View experiment at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_414a200b completed after 20 iterations at 2025-09-01 12:23:52. Total running time: 34min 40s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_414a200b result             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ checkpoint_dir_name                              │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_this_iter_s                         0.00278 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_total_s                             11.9988 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ training_iteration                            20 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ train-rmse                               1.11121 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ valid-rmse                               1.09857 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:23:54] [8]\ttrain-rmse:0.82824\tvalid-rmse:0.83749\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.776 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🏃 View run XGBoostTrainer_6092156f at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265/runs/1aec59de82e94b1f8f0396a3fd5ded08\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🧪 View experiment at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_6092156f completed after 20 iterations at 2025-09-01 12:23:57. Total running time: 34min 44s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_6092156f result             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ checkpoint_dir_name                              │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_this_iter_s                          0.0027 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_total_s                              5.3061 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ training_iteration                            20 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ train-rmse                               0.99069 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ valid-rmse                               0.98848 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_7b8248b4 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_7b8248b4 config                          │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/alpha                              0.38649888492379736 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/colsample_bytree                    0.9825694726898957 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eta                               0.008188900951801711 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eval_metric                                       rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/lambda                             0.03229170471694211 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/max_depth                                            5 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/min_child_weight                   0.14291900099918334 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/nthread                                              1 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/objective                             reg:squarederror │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/subsample                           0.9817365839222983 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/tree_method                                       hist │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=1463, ip=100.64.25.122)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=1463, ip=100.64.25.122)\u001b[0m - (node_id=aa7a1be9217ecfac6d99669d9eee6a9281027e3894db76bdace3f284, ip=100.64.25.122, pid=1509) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=1463, ip=100.64.25.122)\u001b[0m - (node_id=aa7a1be9217ecfac6d99669d9eee6a9281027e3894db76bdace3f284, ip=100.64.25.122, pid=1510) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=1463, ip=100.64.25.122)\u001b[0m - (node_id=aa7a1be9217ecfac6d99669d9eee6a9281027e3894db76bdace3f284, ip=100.64.25.122, pid=1511) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=1463, ip=100.64.25.122)\u001b[0m - (node_id=aa7a1be9217ecfac6d99669d9eee6a9281027e3894db76bdace3f284, ip=100.64.25.122, pid=1512) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:24:00] [9]\ttrain-rmse:0.80104\tvalid-rmse:0.81221\n",
      "\u001b[36m(RayTrainWorker pid=1509, ip=100.64.25.122)\u001b[0m [12:24:00] Task [xgboost.ray-rank=00000000]:e643461050e926ea024f6e0c04000000 got rank 0\n",
      "\u001b[36m(RayTrainWorker pid=1512, ip=100.64.25.122)\u001b[0m [12:24:00] Task [xgboost.ray-rank=00000003]:f762b44793eb8a8ad62fe34e04000000 got rank 3\n",
      "\u001b[36m(RayTrainWorker pid=1511, ip=100.64.25.122)\u001b[0m [12:24:00] Task [xgboost.ray-rank=00000002]:626a9cc5cf98e09a2412bf0f04000000 got rank 2\n",
      "\u001b[36m(RayTrainWorker pid=1510, ip=100.64.25.122)\u001b[0m [12:24:00] Task [xgboost.ray-rank=00000001]:4a4119203b6168bebe49ea8204000000 got rank 1\n",
      "\u001b[36m(SplitCoordinator pid=1673, ip=100.64.25.122)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=1673, ip=100.64.25.122)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.814 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.815 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.815 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.815 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:24:01] [10]\ttrain-rmse:0.77526\tvalid-rmse:0.78940\n",
      "\u001b[36m(SplitCoordinator pid=1674, ip=100.64.25.122)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=1674, ip=100.64.25.122)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_e84ac5bb started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_e84ac5bb config                         │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/alpha                               8.254997891897808 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/colsample_bytree                    0.641316371461269 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eta                               0.07038874626050917 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eval_metric                                      rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/lambda                             0.0587241429086339 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/max_depth                                           9 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/min_child_weight                  0.20779826676322807 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/nthread                                             1 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/objective                            reg:squarederror │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/subsample                          0.6722953799951239 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/tree_method                                      hist │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=1463, ip=100.64.25.122)\u001b[0m [12:24:03] [0]\ttrain-rmse:1.15151\tvalid-rmse:1.13577\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.788 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:24:04] [11]\ttrain-rmse:0.74861\tvalid-rmse:0.76545\n",
      "\u001b[36m(XGBoostTrainer pid=1463, ip=100.64.25.122)\u001b[0m [12:24:06] [1]\ttrain-rmse:1.14563\tvalid-rmse:1.13021\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.730 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=2686) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=2687) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=2688) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=2689) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(RayTrainWorker pid=2687, ip=100.64.27.77)\u001b[0m [12:24:07] Task [xgboost.ray-rank=00000001]:23d2cb943db516f956534cbc04000000 got rank 1\n",
      "\u001b[36m(RayTrainWorker pid=2686, ip=100.64.27.77)\u001b[0m [12:24:07] Task [xgboost.ray-rank=00000000]:b6f84ef270f9e98672d106a304000000 got rank 0\n",
      "\u001b[36m(RayTrainWorker pid=2689, ip=100.64.27.77)\u001b[0m [12:24:07] Task [xgboost.ray-rank=00000003]:2b3ac0507d50b353600e9ce604000000 got rank 3\n",
      "\u001b[36m(RayTrainWorker pid=2688, ip=100.64.27.77)\u001b[0m [12:24:07] Task [xgboost.ray-rank=00000002]:51c52ed090b50c31ba74a74204000000 got rank 2\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.786 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:24:08] [12]\ttrain-rmse:0.72740\tvalid-rmse:0.74745\n",
      "\u001b[36m(SplitCoordinator pid=2851, ip=100.64.27.77)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=2851, ip=100.64.27.77)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.780 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1463, ip=100.64.25.122)\u001b[0m [12:24:10] [2]\ttrain-rmse:1.13979\tvalid-rmse:1.12465\n",
      "\u001b[36m(SplitCoordinator pid=2852, ip=100.64.27.77)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=2852, ip=100.64.27.77)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:24:11] [13]\ttrain-rmse:0.70633\tvalid-rmse:0.72876\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.788 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:24:11] [0]\ttrain-rmse:1.10415\tvalid-rmse:1.09176\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:24:12] [1]\ttrain-rmse:1.06338\tvalid-rmse:1.05465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 12 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:24:13. Total running time: 35min 1s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521         12            5.39364       0.748613       0.765453 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   RUNNING        0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499         3            5.36798       1.13979        1.12465  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255                                                               │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.773 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1463, ip=100.64.25.122)\u001b[0m [12:24:13] [3]\ttrain-rmse:1.13401\tvalid-rmse:1.11915\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.723 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:24:15] [2]\ttrain-rmse:1.02777\tvalid-rmse:1.02143\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.781 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1463, ip=100.64.25.122)\u001b[0m [12:24:17] [4]\ttrain-rmse:1.12831\tvalid-rmse:1.11375\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:24:19] [14]\ttrain-rmse:0.69169\tvalid-rmse:0.71566\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:24:20] [15]\ttrain-rmse:0.67026\tvalid-rmse:0.69645\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1463, ip=100.64.25.122)\u001b[0m [12:24:22] [5]\ttrain-rmse:1.12268\tvalid-rmse:1.10852\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.795 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.781 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:24:24] [16]\ttrain-rmse:0.65382\tvalid-rmse:0.68291\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1463, ip=100.64.25.122)\u001b[0m [12:24:26] [6]\ttrain-rmse:1.11709\tvalid-rmse:1.10320\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:24:27] [17]\ttrain-rmse:0.64394\tvalid-rmse:0.67459\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:24:29] [3]\ttrain-rmse:0.99561\tvalid-rmse:0.99191\n",
      "\u001b[36m(XGBoostTrainer pid=1463, ip=100.64.25.122)\u001b[0m [12:24:31] [7]\ttrain-rmse:1.11145\tvalid-rmse:1.09783\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:24:33] [4]\ttrain-rmse:0.95049\tvalid-rmse:0.95006\n",
      "\u001b[36m(XGBoostTrainer pid=1463, ip=100.64.25.122)\u001b[0m [12:24:35] [8]\ttrain-rmse:1.10625\tvalid-rmse:1.09302\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:24:36] [18]\ttrain-rmse:0.63514\tvalid-rmse:0.66773\n",
      "\u001b[36m(XGBoostTrainer pid=1463, ip=100.64.25.122)\u001b[0m [12:24:38] [9]\ttrain-rmse:1.10087\tvalid-rmse:1.08794\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.771 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:24:40] [19]\ttrain-rmse:0.61853\tvalid-rmse:0.65293\n",
      "\u001b[36m(XGBoostTrainer pid=1463, ip=100.64.25.122)\u001b[0m [12:24:42] [10]\ttrain-rmse:1.09551\tvalid-rmse:1.08284\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.925 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.926 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.926 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.926 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 12 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:24:44. Total running time: 35min 31s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521         18            5.41033       0.643937       0.674591 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   RUNNING        0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        10            5.38775       1.10087        1.08794  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255            4            8.91077       0.995608       0.991907 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.782 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:24:44] [5]\ttrain-rmse:0.91474\tvalid-rmse:0.91572\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.773 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1463, ip=100.64.25.122)\u001b[0m [12:24:45] [11]\ttrain-rmse:1.09007\tvalid-rmse:1.07764\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.792 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:24:47] [6]\ttrain-rmse:0.87962\tvalid-rmse:0.88385\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1463, ip=100.64.25.122)\u001b[0m [12:24:49] [12]\ttrain-rmse:1.08482\tvalid-rmse:1.07271\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:24:51] [7]\ttrain-rmse:0.84694\tvalid-rmse:0.85272\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:24:52] [8]\ttrain-rmse:0.81340\tvalid-rmse:0.82207\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.796 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1463, ip=100.64.25.122)\u001b[0m [12:24:54] [13]\ttrain-rmse:1.07961\tvalid-rmse:1.06777\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:24:56] [9]\ttrain-rmse:0.78608\tvalid-rmse:0.79583\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:24:58] [20]\ttrain-rmse:0.60551\tvalid-rmse:0.64239\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:25:00] [10]\ttrain-rmse:0.75979\tvalid-rmse:0.77206\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.801 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.801 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.801 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.801 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:25:01] [21]\ttrain-rmse:0.59501\tvalid-rmse:0.63367\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.786 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:25:03] [11]\ttrain-rmse:0.73383\tvalid-rmse:0.74772\n",
      "\u001b[36m(XGBoostTrainer pid=1463, ip=100.64.25.122)\u001b[0m [12:25:05] [14]\ttrain-rmse:1.07547\tvalid-rmse:1.06383\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.781 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.787 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:25:07] [12]\ttrain-rmse:0.71301\tvalid-rmse:0.72989\n",
      "\u001b[36m(XGBoostTrainer pid=1463, ip=100.64.25.122)\u001b[0m [12:25:08] [15]\ttrain-rmse:1.07027\tvalid-rmse:1.05889\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:25:10] [22]\ttrain-rmse:0.58102\tvalid-rmse:0.62158\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1463, ip=100.64.25.122)\u001b[0m [12:25:12] [16]\ttrain-rmse:1.06518\tvalid-rmse:1.05407\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 12 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:25:14. Total running time: 36min 2s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521         21            5.41846       0.605513       0.642393 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   RUNNING        0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        17            5.40762       1.06518        1.05407  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255           11            8.93113       0.759791       0.772064 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1463, ip=100.64.25.122)\u001b[0m [12:25:14] [17]\ttrain-rmse:1.06141\tvalid-rmse:1.05045\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:25:16] [13]\ttrain-rmse:0.69252\tvalid-rmse:0.71176\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1463, ip=100.64.25.122)\u001b[0m [12:25:17] [18]\ttrain-rmse:1.05644\tvalid-rmse:1.04579\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:25:19] [23]\ttrain-rmse:0.57097\tvalid-rmse:0.61379\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:25:21] [14]\ttrain-rmse:0.67853\tvalid-rmse:0.69903\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.742 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:25:23] [24]\ttrain-rmse:0.55755\tvalid-rmse:0.60202\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:25:24] [15]\ttrain-rmse:0.65778\tvalid-rmse:0.67997\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:25:26] [25]\ttrain-rmse:0.54926\tvalid-rmse:0.59574\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.776 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:25:28] [16]\ttrain-rmse:0.64170\tvalid-rmse:0.66611\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.802 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.802 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.802 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.802 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.800 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.801 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.801 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.801 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:25:30] [26]\ttrain-rmse:0.54113\tvalid-rmse:0.58939\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.783 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:25:32] [17]\ttrain-rmse:0.63276\tvalid-rmse:0.65859\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:25:33] [27]\ttrain-rmse:0.53013\tvalid-rmse:0.57937\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1463, ip=100.64.25.122)\u001b[0m [12:25:35] [19]\ttrain-rmse:1.05139\tvalid-rmse:1.04102\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.785 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.830 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.830 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.830 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.830 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:25:37] [18]\ttrain-rmse:0.62420\tvalid-rmse:0.65176\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.785 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🏃 View run XGBoostTrainer_7b8248b4 at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265/runs/20ea94c6d513412ca9c92b51b98c190b\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🧪 View experiment at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_7b8248b4 completed after 20 iterations at 2025-09-01 12:25:39. Total running time: 36min 27s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_7b8248b4 result             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ checkpoint_dir_name                              │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_this_iter_s                         0.00302 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_total_s                             5.41634 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ training_iteration                            20 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ train-rmse                               1.05139 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ valid-rmse                               1.04102 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:25:41] [19]\ttrain-rmse:0.60955\tvalid-rmse:0.63875\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.788 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.794 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:25:43] [28]\ttrain-rmse:0.52399\tvalid-rmse:0.57449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_5d94a543 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_5d94a543 config                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/alpha                                0.3284997723929736 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/colsample_bytree                     0.6612250212034984 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eta                               0.0027147358864469525 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eval_metric                                        rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/lambda                             0.009227590107763951 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/max_depth                                             6 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/min_child_weight                   0.035588847439729815 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/nthread                                               1 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/objective                              reg:squarederror │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/subsample                            0.6465844493958818 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/tree_method                                        hist │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 13 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:25:44. Total running time: 36min 32s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521         27            5.43609       0.541129       0.589392 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255           18            8.95112       0.632759       0.658588 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   RUNNING        0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285                                                              │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=2317, ip=100.64.8.234)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=2317, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=2363) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=2317, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=2364) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=2317, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=2365) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=2317, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=2366) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:25:46] [29]\ttrain-rmse:0.51413\tvalid-rmse:0.56558\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.792 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(RayTrainWorker pid=2365, ip=100.64.8.234)\u001b[0m [12:25:46] Task [xgboost.ray-rank=00000002]:dbf807559597161ba777305804000000 got rank 2\n",
      "\u001b[36m(RayTrainWorker pid=2366, ip=100.64.8.234)\u001b[0m [12:25:46] Task [xgboost.ray-rank=00000003]:4b6305191b306cbfaded27e204000000 got rank 3\n",
      "\u001b[36m(RayTrainWorker pid=2363, ip=100.64.8.234)\u001b[0m [12:25:46] Task [xgboost.ray-rank=00000000]:1e429e7debcee6009b9af69d04000000 got rank 0\n",
      "\u001b[36m(RayTrainWorker pid=2364, ip=100.64.8.234)\u001b[0m [12:25:46] Task [xgboost.ray-rank=00000001]:16ba034334c4ba97a2d6e3ff04000000 got rank 1\n",
      "\u001b[36m(SplitCoordinator pid=2527, ip=100.64.8.234)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=2527, ip=100.64.8.234)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:25:48] [20]\ttrain-rmse:0.59751\tvalid-rmse:0.62898\n",
      "\u001b[36m(SplitCoordinator pid=2528, ip=100.64.8.234)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=2528, ip=100.64.8.234)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.794 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2317, ip=100.64.8.234)\u001b[0m [12:25:49] [0]\ttrain-rmse:1.15536\tvalid-rmse:1.13942\n",
      "\u001b[36m(XGBoostTrainer pid=2317, ip=100.64.8.234)\u001b[0m [12:25:49] [1]\ttrain-rmse:1.15389\tvalid-rmse:1.13800\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:25:49] [30]\ttrain-rmse:0.50875\tvalid-rmse:0.56180\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.782 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:25:51] [21]\ttrain-rmse:0.58811\tvalid-rmse:0.62127\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:25:53] [31]\ttrain-rmse:0.50360\tvalid-rmse:0.55800\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.786 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:25:55] [22]\ttrain-rmse:0.57608\tvalid-rmse:0.61078\n",
      "\u001b[36m(XGBoostTrainer pid=2317, ip=100.64.8.234)\u001b[0m [12:25:57] [2]\ttrain-rmse:1.15247\tvalid-rmse:1.13665\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.736 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.800 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.800 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.800 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:25:58] [23]\ttrain-rmse:0.56671\tvalid-rmse:0.60340\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2317, ip=100.64.8.234)\u001b[0m [12:26:00] [3]\ttrain-rmse:1.15101\tvalid-rmse:1.13524\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.804 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.805 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.805 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.805 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:26:02] [24]\ttrain-rmse:0.55430\tvalid-rmse:0.59228\n",
      "\u001b[36m(XGBoostTrainer pid=2317, ip=100.64.8.234)\u001b[0m [12:26:04] [4]\ttrain-rmse:1.14888\tvalid-rmse:1.13320\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:26:06] [25]\ttrain-rmse:0.54691\tvalid-rmse:0.58675\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.942 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.943 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.943 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.943 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.794 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:26:07] [26]\ttrain-rmse:0.53974\tvalid-rmse:0.58129\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2317, ip=100.64.8.234)\u001b[0m [12:26:09] [5]\ttrain-rmse:1.14734\tvalid-rmse:1.13167\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.780 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:26:11] [32]\ttrain-rmse:0.49894\tvalid-rmse:0.55504\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:26:13] [27]\ttrain-rmse:0.53018\tvalid-rmse:0.57257\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.790 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 13 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:26:15. Total running time: 37min 2s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521         31            5.44711       0.508749       0.561797 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255           26            8.97417       0.546905       0.586747 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   RUNNING        0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285           5            5.39501       1.14888        1.1332   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.771 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2317, ip=100.64.8.234)\u001b[0m [12:26:15] [6]\ttrain-rmse:1.14534\tvalid-rmse:1.12981\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:26:16] [33]\ttrain-rmse:0.49281\tvalid-rmse:0.55045\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:26:18] [28]\ttrain-rmse:0.52480\tvalid-rmse:0.56830\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.785 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2317, ip=100.64.8.234)\u001b[0m [12:26:20] [7]\ttrain-rmse:1.14385\tvalid-rmse:1.12835\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:26:22] [29]\ttrain-rmse:0.51555\tvalid-rmse:0.56002\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2317, ip=100.64.8.234)\u001b[0m [12:26:23] [8]\ttrain-rmse:1.14187\tvalid-rmse:1.12651\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:26:25] [30]\ttrain-rmse:0.51083\tvalid-rmse:0.55663\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:26:27] [34]\ttrain-rmse:0.48841\tvalid-rmse:0.54700\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.777 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:26:29] [35]\ttrain-rmse:0.48524\tvalid-rmse:0.54484\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:26:30] [31]\ttrain-rmse:0.50638\tvalid-rmse:0.55325\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2317, ip=100.64.8.234)\u001b[0m [12:26:32] [9]\ttrain-rmse:1.14035\tvalid-rmse:1.12502\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.791 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:26:34] [32]\ttrain-rmse:0.50288\tvalid-rmse:0.55069\n",
      "\u001b[36m(XGBoostTrainer pid=2317, ip=100.64.8.234)\u001b[0m [12:26:36] [10]\ttrain-rmse:1.13836\tvalid-rmse:1.12316\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:26:38] [33]\ttrain-rmse:0.49755\tvalid-rmse:0.54672\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:26:39] [36]\ttrain-rmse:0.47877\tvalid-rmse:0.53907\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2317, ip=100.64.8.234)\u001b[0m [12:26:41] [11]\ttrain-rmse:1.13637\tvalid-rmse:1.12130\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:26:43] [34]\ttrain-rmse:0.49370\tvalid-rmse:0.54391\n",
      "\u001b[36m(XGBoostTrainer pid=2317, ip=100.64.8.234)\u001b[0m [12:26:45] [12]\ttrain-rmse:1.13456\tvalid-rmse:1.11965\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 13 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:26:45. Total running time: 37min 32s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521         35            5.46022       0.488414       0.547003 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255           33            8.99491       0.502879       0.550686 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   RUNNING        0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          11            5.41187       1.13836        1.12316  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.781 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:26:46] [35]\ttrain-rmse:0.49054\tvalid-rmse:0.54168\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.781 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2317, ip=100.64.8.234)\u001b[0m [12:26:48] [13]\ttrain-rmse:1.13256\tvalid-rmse:1.11775\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:26:50] [37]\ttrain-rmse:0.47513\tvalid-rmse:0.53657\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2317, ip=100.64.8.234)\u001b[0m [12:26:52] [14]\ttrain-rmse:1.13111\tvalid-rmse:1.11636\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:26:53] [38]\ttrain-rmse:0.46894\tvalid-rmse:0.53114\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.787 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:26:55] [36]\ttrain-rmse:0.48418\tvalid-rmse:0.53616\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2317, ip=100.64.8.234)\u001b[0m [12:26:57] [15]\ttrain-rmse:1.12916\tvalid-rmse:1.11453\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.814 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.815 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.815 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.815 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:26:59] [37]\ttrain-rmse:0.48104\tvalid-rmse:0.53408\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.801 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.801 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.801 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.801 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2317, ip=100.64.8.234)\u001b[0m [12:27:01] [16]\ttrain-rmse:1.12718\tvalid-rmse:1.11266\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.811 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.811 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.811 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.811 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:27:03] [38]\ttrain-rmse:0.47519\tvalid-rmse:0.52861\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.833 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.834 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.834 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.834 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:27:04] [39]\ttrain-rmse:0.46563\tvalid-rmse:0.52898\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.782 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.785 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:27:06] [39]\ttrain-rmse:0.47273\tvalid-rmse:0.52690\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.781 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:27:08] [40]\ttrain-rmse:0.46144\tvalid-rmse:0.52572\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2317, ip=100.64.8.234)\u001b[0m [12:27:10] [17]\ttrain-rmse:1.12594\tvalid-rmse:1.11149\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:27:11] [40]\ttrain-rmse:0.46851\tvalid-rmse:0.52360\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.791 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:27:13] [41]\ttrain-rmse:0.45919\tvalid-rmse:0.52428\n",
      "\u001b[36m(XGBoostTrainer pid=2317, ip=100.64.8.234)\u001b[0m [12:27:15] [18]\ttrain-rmse:1.12470\tvalid-rmse:1.11036\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.773 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 13 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:27:15. Total running time: 38min 3s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521         40            5.47447       0.465633       0.528979 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255           39            9.01135       0.475191       0.528607 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   RUNNING        0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          17            5.42875       1.12718        1.11266  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:27:17] [42]\ttrain-rmse:0.45677\tvalid-rmse:0.52276\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.799 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.800 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:27:19] [41]\ttrain-rmse:0.46642\tvalid-rmse:0.52258\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:27:20] [43]\ttrain-rmse:0.45474\tvalid-rmse:0.52144\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.794 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:27:22] [42]\ttrain-rmse:0.46456\tvalid-rmse:0.52146\n",
      "\u001b[36m(XGBoostTrainer pid=2317, ip=100.64.8.234)\u001b[0m [12:27:24] [19]\ttrain-rmse:1.12275\tvalid-rmse:1.10853\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:27:26] [43]\ttrain-rmse:0.46275\tvalid-rmse:0.52044\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.936 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.936 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.936 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.936 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2317, ip=100.64.8.234)\u001b[0m [12:27:28] [20]\ttrain-rmse:1.12075\tvalid-rmse:1.10668\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:27:29] [44]\ttrain-rmse:0.45803\tvalid-rmse:0.51625\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:27:31] [44]\ttrain-rmse:0.44983\tvalid-rmse:0.51714\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.776 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:27:33] [45]\ttrain-rmse:0.45651\tvalid-rmse:0.51530\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.801 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.801 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.801 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.802 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.805 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.806 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.806 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.806 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🏃 View run XGBoostTrainer_5d94a543 at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265/runs/e4808aef9c0f4e8e9794064ffdec84bc\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🧪 View experiment at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_5d94a543 completed after 20 iterations at 2025-09-01 12:27:35. Total running time: 38min 23s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_5d94a543 result             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ checkpoint_dir_name                              │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_this_iter_s                         0.00272 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_total_s                             5.43721 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ training_iteration                            20 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ train-rmse                               1.12275 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ valid-rmse                               1.10853 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:27:37] [46]\ttrain-rmse:0.45467\tvalid-rmse:0.51433\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:27:39] [45]\ttrain-rmse:0.44793\tvalid-rmse:0.51599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_56e7b182 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_56e7b182 config                          │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/alpha                             0.007115703583417678 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/colsample_bytree                     0.896391490611445 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eta                                0.02133004377115732 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eval_metric                                       rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/lambda                             0.02259367511715624 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/max_depth                                            7 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/min_child_weight                    1.2522745117834435 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/nthread                                              1 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/objective                             reg:squarederror │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/subsample                           0.8106492869830579 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/tree_method                                       hist │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=2012, ip=100.64.25.122)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=2012, ip=100.64.25.122)\u001b[0m - (node_id=aa7a1be9217ecfac6d99669d9eee6a9281027e3894db76bdace3f284, ip=100.64.25.122, pid=2058) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=2012, ip=100.64.25.122)\u001b[0m - (node_id=aa7a1be9217ecfac6d99669d9eee6a9281027e3894db76bdace3f284, ip=100.64.25.122, pid=2059) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=2012, ip=100.64.25.122)\u001b[0m - (node_id=aa7a1be9217ecfac6d99669d9eee6a9281027e3894db76bdace3f284, ip=100.64.25.122, pid=2060) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=2012, ip=100.64.25.122)\u001b[0m - (node_id=aa7a1be9217ecfac6d99669d9eee6a9281027e3894db76bdace3f284, ip=100.64.25.122, pid=2061) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:27:42] [46]\ttrain-rmse:0.44576\tvalid-rmse:0.51491\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(RayTrainWorker pid=2061, ip=100.64.25.122)\u001b[0m [12:27:42] Task [xgboost.ray-rank=00000003]:9fac960510bf3ca815ef7d6304000000 got rank 3\n",
      "\u001b[36m(RayTrainWorker pid=2058, ip=100.64.25.122)\u001b[0m [12:27:42] Task [xgboost.ray-rank=00000000]:bb349fdabb5a0adca734069104000000 got rank 0\n",
      "\u001b[36m(RayTrainWorker pid=2059, ip=100.64.25.122)\u001b[0m [12:27:42] Task [xgboost.ray-rank=00000001]:7e01920a180648aaa5ce34b104000000 got rank 1\n",
      "\u001b[36m(RayTrainWorker pid=2060, ip=100.64.25.122)\u001b[0m [12:27:42] Task [xgboost.ray-rank=00000002]:944e603badb7f81e3160b25504000000 got rank 2\n",
      "\u001b[36m(SplitCoordinator pid=2222, ip=100.64.25.122)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=2222, ip=100.64.25.122)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:27:44] [47]\ttrain-rmse:0.45308\tvalid-rmse:0.51350\n",
      "\u001b[36m(SplitCoordinator pid=2223, ip=100.64.25.122)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=2223, ip=100.64.25.122)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 14 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:27:45. Total running time: 38min 33s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521         46            5.53311       0.447929       0.515993 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255           46            9.07985       0.456512       0.515303 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   TERMINATED     0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          20            5.43721       1.12275        1.10853  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:27:45] [47]\ttrain-rmse:0.44371\tvalid-rmse:0.51385\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.811 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.811 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.811 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.811 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:27:47] [48]\ttrain-rmse:0.45198\tvalid-rmse:0.51295\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:27:49] [48]\ttrain-rmse:0.44201\tvalid-rmse:0.51280\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:27:51] [49]\ttrain-rmse:0.45048\tvalid-rmse:0.51211\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.806 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.806 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.806 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.806 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.783 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:27:53] [49]\ttrain-rmse:0.44034\tvalid-rmse:0.51158\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:27:54] [50]\ttrain-rmse:0.43857\tvalid-rmse:0.51070\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.808 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.808 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.808 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.808 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.815 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.816 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.816 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.816 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:27:56] [50]\ttrain-rmse:0.44905\tvalid-rmse:0.51117\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:27:58] [51]\ttrain-rmse:0.43694\tvalid-rmse:0.50974\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:28:00] [51]\ttrain-rmse:0.44785\tvalid-rmse:0.51023\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.780 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:28:02] [52]\ttrain-rmse:0.43405\tvalid-rmse:0.50740\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.807 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.807 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.807 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.807 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.798 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:28:03] [52]\ttrain-rmse:0.44500\tvalid-rmse:0.50774\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.785 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:28:05] [53]\ttrain-rmse:0.44181\tvalid-rmse:0.50484\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:28:07] [53]\ttrain-rmse:0.43049\tvalid-rmse:0.50422\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:28:09] [54]\ttrain-rmse:0.44046\tvalid-rmse:0.50373\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.786 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:28:11] [54]\ttrain-rmse:0.42902\tvalid-rmse:0.50322\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.815 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.816 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.816 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.816 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.789 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:28:12] [55]\ttrain-rmse:0.43939\tvalid-rmse:0.50321\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:28:14] [55]\ttrain-rmse:0.42773\tvalid-rmse:0.50277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 14 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:28:16. Total running time: 39min 4s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521         54            5.55546       0.430493       0.504223 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255           55            9.10523       0.440457       0.503729 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   TERMINATED     0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          20            5.43721       1.12275        1.10853  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.781 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:28:16] [56]\ttrain-rmse:0.43815\tvalid-rmse:0.50241\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.783 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:28:18] [56]\ttrain-rmse:0.42654\tvalid-rmse:0.50209\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.792 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:28:19] [57]\ttrain-rmse:0.43714\tvalid-rmse:0.50206\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.820 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.821 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.821 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.821 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:28:21] [57]\ttrain-rmse:0.42529\tvalid-rmse:0.50133\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:28:23] [58]\ttrain-rmse:0.43636\tvalid-rmse:0.50157\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.815 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.815 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.815 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.815 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:28:25] [58]\ttrain-rmse:0.42416\tvalid-rmse:0.50083\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.800 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.800 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.800 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.800 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:28:27] [59]\ttrain-rmse:0.42290\tvalid-rmse:0.50015\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.797 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.809 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.810 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.810 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.810 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:28:29] [59]\ttrain-rmse:0.43531\tvalid-rmse:0.50122\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:28:30] [60]\ttrain-rmse:0.42192\tvalid-rmse:0.49964\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.809 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.810 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.810 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.810 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:28:32] [60]\ttrain-rmse:0.43435\tvalid-rmse:0.50067\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.818 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.819 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.819 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.819 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.809 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.809 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.809 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.809 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:28:34] [61]\ttrain-rmse:0.42070\tvalid-rmse:0.49926\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.805 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.806 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.806 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.806 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:28:36] [61]\ttrain-rmse:0.43348\tvalid-rmse:0.50057\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.857 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.857 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.857 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.857 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:28:38] [62]\ttrain-rmse:0.41977\tvalid-rmse:0.49908\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.813 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.813 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.813 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.813 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:28:39] [62]\ttrain-rmse:0.43259\tvalid-rmse:0.50026\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.824 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.824 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.825 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.825 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:28:41] [63]\ttrain-rmse:0.41788\tvalid-rmse:0.49771\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.824 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.825 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.825 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.825 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:28:43] [63]\ttrain-rmse:0.43059\tvalid-rmse:0.49830\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:28:45] [64]\ttrain-rmse:0.41563\tvalid-rmse:0.49586\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.821 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.822 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.822 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.822 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:28:47] [64]\ttrain-rmse:0.42809\tvalid-rmse:0.49610\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.808 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.808 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.808 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.808 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 14 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:28:47. Total running time: 39min 35s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521         63            5.57984       0.419771       0.499076 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255           63            9.12728       0.432589       0.500265 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   TERMINATED     0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          20            5.43721       1.12275        1.10853  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:28:49] [65]\ttrain-rmse:0.41345\tvalid-rmse:0.49421\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.805 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.805 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.805 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.805 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.813 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.813 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.814 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.814 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:28:50] [65]\ttrain-rmse:0.42616\tvalid-rmse:0.49452\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.977 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.977 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.977 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.977 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:28:52] [66]\ttrain-rmse:0.41160\tvalid-rmse:0.49262\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.813 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.814 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.814 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.814 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:28:54] [66]\ttrain-rmse:0.42409\tvalid-rmse:0.49274\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.845 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.845 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.845 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.846 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:28:56] [67]\ttrain-rmse:0.41062\tvalid-rmse:0.49223\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:28:58] [67]\ttrain-rmse:0.42313\tvalid-rmse:0.49230\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.833 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.833 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.834 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.834 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.814 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.814 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.814 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.814 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:29:00] [68]\ttrain-rmse:0.40901\tvalid-rmse:0.49133\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:29:02] [68]\ttrain-rmse:0.42159\tvalid-rmse:0.49106\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.848 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.848 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.848 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.849 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:29:03] [69]\ttrain-rmse:0.40810\tvalid-rmse:0.49114\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.805 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.805 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.805 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.805 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:29:05] [69]\ttrain-rmse:0.42083\tvalid-rmse:0.49086\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.828 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.828 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.828 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.828 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:29:07] [70]\ttrain-rmse:0.40729\tvalid-rmse:0.49069\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.819 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.819 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.819 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.820 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.826 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.826 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.826 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.826 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:29:09] [70]\ttrain-rmse:0.42008\tvalid-rmse:0.49047\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.800 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.800 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.800 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.800 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:29:11] [71]\ttrain-rmse:0.40558\tvalid-rmse:0.48929\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:29:12] [71]\ttrain-rmse:0.41818\tvalid-rmse:0.48892\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.802 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.802 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.802 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.802 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:29:14] [72]\ttrain-rmse:0.40413\tvalid-rmse:0.48827\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.791 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.800 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.800 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.800 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.800 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:29:16] [72]\ttrain-rmse:0.41728\tvalid-rmse:0.48817\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:29:18] [73]\ttrain-rmse:0.40248\tvalid-rmse:0.48698\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.836 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.836 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.836 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.836 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 14 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:29:18. Total running time: 40min 6s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521         72            5.60483       0.40558        0.489289 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255           71            9.1507        0.420077       0.490468 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   TERMINATED     0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          20            5.43721       1.12275        1.10853  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:29:20] [73]\ttrain-rmse:0.41558\tvalid-rmse:0.48689\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.798 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.844 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.845 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.845 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.845 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:29:21] [74]\ttrain-rmse:0.40179\tvalid-rmse:0.48672\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.802 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.802 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.802 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.802 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:29:23] [74]\ttrain-rmse:0.41497\tvalid-rmse:0.48668\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:29:25] [75]\ttrain-rmse:0.40036\tvalid-rmse:0.48574\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:29:27] [75]\ttrain-rmse:0.41348\tvalid-rmse:0.48539\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.802 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.802 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.802 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.802 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.824 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.825 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.825 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.825 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:29:29] [76]\ttrain-rmse:0.39892\tvalid-rmse:0.48461\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:29:30] [76]\ttrain-rmse:0.41212\tvalid-rmse:0.48437\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.810 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.811 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.811 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.811 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:29:32] [77]\ttrain-rmse:0.39830\tvalid-rmse:0.48440\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.795 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.788 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:29:34] [77]\ttrain-rmse:0.41144\tvalid-rmse:0.48403\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:29:36] [78]\ttrain-rmse:0.39776\tvalid-rmse:0.48422\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.831 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.831 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.831 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.831 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:29:38] [78]\ttrain-rmse:0.41091\tvalid-rmse:0.48389\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.807 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.807 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.807 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.807 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.790 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:29:40] [79]\ttrain-rmse:0.39698\tvalid-rmse:0.48379\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.817 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.818 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.818 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.818 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:29:41] [79]\ttrain-rmse:0.41014\tvalid-rmse:0.48335\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.796 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:29:43] [80]\ttrain-rmse:0.39630\tvalid-rmse:0.48366\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.812 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.812 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.812 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.812 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:29:45] [80]\ttrain-rmse:0.40965\tvalid-rmse:0.48337\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.806 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.807 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.807 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.807 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:29:47] [81]\ttrain-rmse:0.39565\tvalid-rmse:0.48337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 14 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:29:49. Total running time: 40min 36s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521         80            5.62679       0.396982       0.483787 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255           80            9.17547       0.41014        0.483354 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   TERMINATED     0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          20            5.43721       1.12275        1.10853  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.790 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:29:49] [81]\ttrain-rmse:0.40897\tvalid-rmse:0.48314\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.808 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.809 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.809 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.809 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:29:50] [82]\ttrain-rmse:0.39443\tvalid-rmse:0.48239\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.842 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.842 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.842 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.842 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:29:52] [82]\ttrain-rmse:0.40812\tvalid-rmse:0.48246\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:29:54] [83]\ttrain-rmse:0.40758\tvalid-rmse:0.48211\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.807 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.808 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.808 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.808 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.798 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:29:56] [83]\ttrain-rmse:0.39377\tvalid-rmse:0.48213\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.808 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.808 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.808 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.808 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:29:58] [84]\ttrain-rmse:0.40694\tvalid-rmse:0.48199\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.788 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:29:59] [84]\ttrain-rmse:0.39324\tvalid-rmse:0.48184\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.810 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.811 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.811 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.811 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:30:01] [85]\ttrain-rmse:0.40612\tvalid-rmse:0.48123\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.825 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.825 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.825 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.825 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:30:03] [85]\ttrain-rmse:0.39168\tvalid-rmse:0.48064\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.798 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:30:05] [86]\ttrain-rmse:0.39106\tvalid-rmse:0.48043\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.826 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.827 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.827 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.827 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:30:07] [86]\ttrain-rmse:0.40546\tvalid-rmse:0.48104\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.792 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:30:08] [87]\ttrain-rmse:0.39029\tvalid-rmse:0.48017\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:30:10] [87]\ttrain-rmse:0.40477\tvalid-rmse:0.48075\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.793 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.800 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.800 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.800 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:30:12] [88]\ttrain-rmse:0.38884\tvalid-rmse:0.47918\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.846 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.846 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.846 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.846 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:30:14] [88]\ttrain-rmse:0.40365\tvalid-rmse:0.47965\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.782 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:30:16] [89]\ttrain-rmse:0.38754\tvalid-rmse:0.47821\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:30:18] [89]\ttrain-rmse:0.40268\tvalid-rmse:0.47878\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.966 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.967 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.967 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.967 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:30:19] [90]\ttrain-rmse:0.38650\tvalid-rmse:0.47735\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.797 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 14 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:30:19. Total running time: 41min 7s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521         89            5.65175       0.388842       0.479178 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255           88            9.19784       0.404769       0.480746 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   TERMINATED     0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          20            5.43721       1.12275        1.10853  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.785 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:30:21] [90]\ttrain-rmse:0.40182\tvalid-rmse:0.47818\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.800 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.801 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.801 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.801 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:30:23] [91]\ttrain-rmse:0.38581\tvalid-rmse:0.47707\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.783 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:30:25] [91]\ttrain-rmse:0.40119\tvalid-rmse:0.47786\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:30:27] [92]\ttrain-rmse:0.38516\tvalid-rmse:0.47694\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:30:28] [92]\ttrain-rmse:0.40056\tvalid-rmse:0.47770\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.771 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.796 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:30:30] [93]\ttrain-rmse:0.38465\tvalid-rmse:0.47681\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.789 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:30:32] [93]\ttrain-rmse:0.40017\tvalid-rmse:0.47763\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:30:34] [94]\ttrain-rmse:0.38425\tvalid-rmse:0.47678\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.782 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.783 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:30:36] [94]\ttrain-rmse:0.39986\tvalid-rmse:0.47748\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:30:37] [95]\ttrain-rmse:0.39938\tvalid-rmse:0.47741\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:30:39] [95]\ttrain-rmse:0.38381\tvalid-rmse:0.47665\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.789 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:30:41] [96]\ttrain-rmse:0.39834\tvalid-rmse:0.47655\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.792 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.797 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:30:43] [96]\ttrain-rmse:0.38280\tvalid-rmse:0.47618\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.790 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:30:44] [97]\ttrain-rmse:0.39798\tvalid-rmse:0.47639\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.806 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.807 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.807 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.807 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:30:46] [97]\ttrain-rmse:0.38223\tvalid-rmse:0.47614\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:30:48] [98]\ttrain-rmse:0.39751\tvalid-rmse:0.47629\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.825 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.825 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.825 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.825 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 14 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:30:50. Total running time: 41min 38s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521         97            5.67317       0.382803       0.476183 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255           97            9.22318       0.398341       0.476547 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   TERMINATED     0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          20            5.43721       1.12275        1.10853  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.804 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.804 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.804 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.804 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:30:50] [98]\ttrain-rmse:0.38158\tvalid-rmse:0.47609\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:30:52] [99]\ttrain-rmse:0.39661\tvalid-rmse:0.47551\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.836 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.837 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.837 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.837 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:30:54] [99]\ttrain-rmse:0.38055\tvalid-rmse:0.47527\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.829 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.829 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.829 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.829 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.826 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.827 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.827 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.827 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:30:55] [100]\ttrain-rmse:0.39593\tvalid-rmse:0.47495\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:30:57] [100]\ttrain-rmse:0.37950\tvalid-rmse:0.47437\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.895 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.896 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.896 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.896 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.814 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.814 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.814 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.815 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:30:59] [101]\ttrain-rmse:0.37889\tvalid-rmse:0.47429\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.829 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.829 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.829 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.829 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:31:01] [101]\ttrain-rmse:0.39549\tvalid-rmse:0.47486\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.831 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.831 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.831 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.831 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:31:03] [102]\ttrain-rmse:0.37837\tvalid-rmse:0.47428\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.796 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:31:05] [102]\ttrain-rmse:0.39506\tvalid-rmse:0.47474\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.806 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.807 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.807 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.807 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:31:06] [103]\ttrain-rmse:0.37763\tvalid-rmse:0.47375\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:31:08] [103]\ttrain-rmse:0.39456\tvalid-rmse:0.47437\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.871 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.871 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.871 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.871 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.817 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.818 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.818 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.818 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:31:10] [104]\ttrain-rmse:0.37725\tvalid-rmse:0.47373\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.812 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.812 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.812 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.812 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:31:12] [104]\ttrain-rmse:0.39414\tvalid-rmse:0.47431\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.819 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.820 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.820 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.820 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:31:14] [105]\ttrain-rmse:0.37673\tvalid-rmse:0.47366\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.832 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.833 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.833 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.833 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:31:16] [105]\ttrain-rmse:0.39380\tvalid-rmse:0.47430\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.848 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.848 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.848 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.848 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:31:17] [106]\ttrain-rmse:0.37581\tvalid-rmse:0.47305\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.799 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:31:19] [106]\ttrain-rmse:0.39292\tvalid-rmse:0.47363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 14 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:31:21. Total running time: 42min 9s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521        106            5.69823       0.376728       0.473662 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255          105            9.24616       0.394143       0.474311 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   TERMINATED     0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          20            5.43721       1.12275        1.10853  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.829 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.829 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.829 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.830 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:31:21] [107]\ttrain-rmse:0.37542\tvalid-rmse:0.47300\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.821 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.822 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.822 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.822 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:31:23] [107]\ttrain-rmse:0.39236\tvalid-rmse:0.47347\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.789 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:31:25] [108]\ttrain-rmse:0.37486\tvalid-rmse:0.47248\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:31:26] [108]\ttrain-rmse:0.39132\tvalid-rmse:0.47258\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.788 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.788 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:31:28] [109]\ttrain-rmse:0.37414\tvalid-rmse:0.47188\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.812 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.812 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.812 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.812 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:31:30] [109]\ttrain-rmse:0.39059\tvalid-rmse:0.47212\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:31:32] [110]\ttrain-rmse:0.39012\tvalid-rmse:0.47208\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.819 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.819 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.819 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.819 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:31:34] [110]\ttrain-rmse:0.37379\tvalid-rmse:0.47184\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.834 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.835 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.835 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.835 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.829 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.829 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.829 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.829 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:31:36] [111]\ttrain-rmse:0.38953\tvalid-rmse:0.47170\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.833 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.833 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.833 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.833 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:31:37] [111]\ttrain-rmse:0.37331\tvalid-rmse:0.47137\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.819 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.819 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.820 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.820 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:31:39] [112]\ttrain-rmse:0.38910\tvalid-rmse:0.47175\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.947 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.947 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.947 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.947 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:31:41] [112]\ttrain-rmse:0.37291\tvalid-rmse:0.47127\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:31:43] [113]\ttrain-rmse:0.38867\tvalid-rmse:0.47173\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.821 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.821 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.822 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.822 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:31:45] [113]\ttrain-rmse:0.37244\tvalid-rmse:0.47113\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.798 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:31:47] [114]\ttrain-rmse:0.38813\tvalid-rmse:0.47124\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.806 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.806 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.806 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.806 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.788 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:31:48] [114]\ttrain-rmse:0.37183\tvalid-rmse:0.47049\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.794 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:31:50] [115]\ttrain-rmse:0.38766\tvalid-rmse:0.47112\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.824 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.824 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.824 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.824 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:31:52] [115]\ttrain-rmse:0.37130\tvalid-rmse:0.47039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 14 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:31:52. Total running time: 42min 40s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521        114            5.72063       0.372441       0.471126 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255          114            9.27035       0.388674       0.471734 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   TERMINATED     0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          20            5.43721       1.12275        1.10853  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.804 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.804 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.804 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.804 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:31:54] [116]\ttrain-rmse:0.38720\tvalid-rmse:0.47065\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:31:56] [116]\ttrain-rmse:0.37086\tvalid-rmse:0.47032\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.816 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.817 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.817 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.817 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:31:57] [117]\ttrain-rmse:0.38680\tvalid-rmse:0.47065\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.825 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.826 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.826 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.826 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.797 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:31:59] [117]\ttrain-rmse:0.37041\tvalid-rmse:0.47020\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.813 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.813 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.813 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.813 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:32:01] [118]\ttrain-rmse:0.38602\tvalid-rmse:0.47007\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:32:03] [118]\ttrain-rmse:0.36953\tvalid-rmse:0.46943\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.812 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.812 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.812 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.813 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:32:05] [119]\ttrain-rmse:0.38552\tvalid-rmse:0.46986\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.797 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.788 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:32:06] [119]\ttrain-rmse:0.36896\tvalid-rmse:0.46904\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:32:08] [120]\ttrain-rmse:0.38517\tvalid-rmse:0.46974\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:32:10] [120]\ttrain-rmse:0.36866\tvalid-rmse:0.46893\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:32:12] [121]\ttrain-rmse:0.38468\tvalid-rmse:0.46926\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:32:14] [121]\ttrain-rmse:0.36804\tvalid-rmse:0.46845\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:32:15] [122]\ttrain-rmse:0.36766\tvalid-rmse:0.46829\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.803 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.803 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.803 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.803 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.786 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:32:17] [122]\ttrain-rmse:0.38432\tvalid-rmse:0.46917\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.776 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:32:19] [123]\ttrain-rmse:0.36706\tvalid-rmse:0.46794\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:32:21] [123]\ttrain-rmse:0.38371\tvalid-rmse:0.46877\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 14 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:32:23. Total running time: 43min 10s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521        123            5.74497       0.367663       0.468292 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255          122            9.29346       0.384682       0.469265 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   TERMINATED     0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          20            5.43721       1.12275        1.10853  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.812 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.812 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.812 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.812 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:32:23] [124]\ttrain-rmse:0.36655\tvalid-rmse:0.46779\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:32:24] [124]\ttrain-rmse:0.38339\tvalid-rmse:0.46855\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.786 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.786 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:32:26] [125]\ttrain-rmse:0.38299\tvalid-rmse:0.46842\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:32:28] [125]\ttrain-rmse:0.36622\tvalid-rmse:0.46782\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:32:30] [126]\ttrain-rmse:0.38248\tvalid-rmse:0.46832\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.788 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:32:31] [126]\ttrain-rmse:0.36573\tvalid-rmse:0.46777\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.785 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.784 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:32:33] [127]\ttrain-rmse:0.38205\tvalid-rmse:0.46817\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.799 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:32:35] [127]\ttrain-rmse:0.36532\tvalid-rmse:0.46770\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:32:37] [128]\ttrain-rmse:0.38172\tvalid-rmse:0.46812\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:32:39] [128]\ttrain-rmse:0.36497\tvalid-rmse:0.46760\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:32:40] [129]\ttrain-rmse:0.38107\tvalid-rmse:0.46762\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:32:42] [129]\ttrain-rmse:0.36430\tvalid-rmse:0.46699\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:32:44] [130]\ttrain-rmse:0.38078\tvalid-rmse:0.46747\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:32:46] [130]\ttrain-rmse:0.36391\tvalid-rmse:0.46696\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:32:47] [131]\ttrain-rmse:0.36330\tvalid-rmse:0.46660\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:32:49] [131]\ttrain-rmse:0.38004\tvalid-rmse:0.46691\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:32:51] [132]\ttrain-rmse:0.36304\tvalid-rmse:0.46654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 14 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:32:53. Total running time: 43min 41s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521        131            5.76658       0.363911       0.466961 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255          131            9.31863       0.380775       0.467466 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   TERMINATED     0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          20            5.43721       1.12275        1.10853  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.781 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:32:53] [132]\ttrain-rmse:0.37978\tvalid-rmse:0.46699\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:32:55] [133]\ttrain-rmse:0.36278\tvalid-rmse:0.46641\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:32:56] [133]\ttrain-rmse:0.37953\tvalid-rmse:0.46684\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.824 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.825 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.825 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.825 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.784 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:32:58] [134]\ttrain-rmse:0.37885\tvalid-rmse:0.46621\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.804 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.804 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.804 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.804 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:33:00] [134]\ttrain-rmse:0.36210\tvalid-rmse:0.46585\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:33:02] [135]\ttrain-rmse:0.37846\tvalid-rmse:0.46617\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.822 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.823 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.823 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.823 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.935 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.935 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.935 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.935 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:33:04] [135]\ttrain-rmse:0.36166\tvalid-rmse:0.46574\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:33:05] [136]\ttrain-rmse:0.37813\tvalid-rmse:0.46604\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.788 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:33:07] [136]\ttrain-rmse:0.36124\tvalid-rmse:0.46549\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:33:09] [137]\ttrain-rmse:0.37778\tvalid-rmse:0.46584\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:33:11] [137]\ttrain-rmse:0.36094\tvalid-rmse:0.46537\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:33:13] [138]\ttrain-rmse:0.37718\tvalid-rmse:0.46534\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:33:14] [138]\ttrain-rmse:0.36042\tvalid-rmse:0.46503\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.805 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.806 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.806 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.806 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:33:16] [139]\ttrain-rmse:0.37678\tvalid-rmse:0.46533\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.788 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:33:18] [139]\ttrain-rmse:0.36006\tvalid-rmse:0.46498\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.793 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:33:20] [140]\ttrain-rmse:0.35950\tvalid-rmse:0.46474\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:33:22] [140]\ttrain-rmse:0.37637\tvalid-rmse:0.46502\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.798 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 14 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:33:23. Total running time: 44min 11s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521        140            5.79078       0.360056       0.464977 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255          139            9.3412        0.377179       0.465345 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   TERMINATED     0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          20            5.43721       1.12275        1.10853  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:33:23] [141]\ttrain-rmse:0.35904\tvalid-rmse:0.46461\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.780 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:33:25] [141]\ttrain-rmse:0.37603\tvalid-rmse:0.46486\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.782 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:33:27] [142]\ttrain-rmse:0.35874\tvalid-rmse:0.46468\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.849 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.849 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.849 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.849 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:33:29] [142]\ttrain-rmse:0.37576\tvalid-rmse:0.46480\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.773 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:33:30] [143]\ttrain-rmse:0.37531\tvalid-rmse:0.46475\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:33:32] [143]\ttrain-rmse:0.35840\tvalid-rmse:0.46455\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:33:34] [144]\ttrain-rmse:0.37493\tvalid-rmse:0.46458\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.802 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.803 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.803 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.803 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:33:36] [144]\ttrain-rmse:0.35804\tvalid-rmse:0.46442\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:33:38] [145]\ttrain-rmse:0.37454\tvalid-rmse:0.46451\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.825 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.825 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.825 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.825 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:33:39] [145]\ttrain-rmse:0.35739\tvalid-rmse:0.46403\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:33:41] [146]\ttrain-rmse:0.35708\tvalid-rmse:0.46404\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.788 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:33:43] [146]\ttrain-rmse:0.37417\tvalid-rmse:0.46454\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.791 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:33:45] [147]\ttrain-rmse:0.35677\tvalid-rmse:0.46398\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.783 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:33:47] [147]\ttrain-rmse:0.37386\tvalid-rmse:0.46445\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:33:48] [148]\ttrain-rmse:0.35648\tvalid-rmse:0.46394\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.815 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.815 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.815 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.815 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:33:50] [148]\ttrain-rmse:0.37360\tvalid-rmse:0.46437\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:33:52] [149]\ttrain-rmse:0.37330\tvalid-rmse:0.46419\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 14 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:33:54. Total running time: 44min 41s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521        148            5.81274       0.356775       0.463982 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255          148            9.36575       0.373859       0.464448 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   TERMINATED     0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          20            5.43721       1.12275        1.10853  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.732 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:33:54] [149]\ttrain-rmse:0.35608\tvalid-rmse:0.46394\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:33:55] [150]\ttrain-rmse:0.37262\tvalid-rmse:0.46383\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:33:57] [150]\ttrain-rmse:0.35556\tvalid-rmse:0.46367\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:33:59] [151]\ttrain-rmse:0.37229\tvalid-rmse:0.46374\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:34:01] [151]\ttrain-rmse:0.35519\tvalid-rmse:0.46343\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:34:02] [152]\ttrain-rmse:0.37197\tvalid-rmse:0.46364\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.799 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:34:04] [152]\ttrain-rmse:0.35482\tvalid-rmse:0.46315\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:34:06] [153]\ttrain-rmse:0.37174\tvalid-rmse:0.46364\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.785 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:34:08] [153]\ttrain-rmse:0.35443\tvalid-rmse:0.46319\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:34:09] [154]\ttrain-rmse:0.37140\tvalid-rmse:0.46345\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:34:11] [154]\ttrain-rmse:0.35402\tvalid-rmse:0.46292\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:34:13] [155]\ttrain-rmse:0.37107\tvalid-rmse:0.46344\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:34:15] [155]\ttrain-rmse:0.35377\tvalid-rmse:0.46284\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:34:17] [156]\ttrain-rmse:0.37081\tvalid-rmse:0.46340\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:34:18] [156]\ttrain-rmse:0.35335\tvalid-rmse:0.46286\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:34:20] [157]\ttrain-rmse:0.37031\tvalid-rmse:0.46320\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:34:22] [157]\ttrain-rmse:0.35286\tvalid-rmse:0.46256\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.789 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:34:24] [158]\ttrain-rmse:0.37000\tvalid-rmse:0.46322\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:34:25] [158]\ttrain-rmse:0.35253\tvalid-rmse:0.46262\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 14 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:34:25. Total running time: 45min 13s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521        157            5.83728       0.353346       0.462858 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255          157            9.39102       0.370809       0.463404 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   TERMINATED     0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          20            5.43721       1.12275        1.10853  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.948 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.948 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.948 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.948 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:34:27] [159]\ttrain-rmse:0.36977\tvalid-rmse:0.46318\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:34:29] [159]\ttrain-rmse:0.35225\tvalid-rmse:0.46257\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:34:31] [160]\ttrain-rmse:0.36946\tvalid-rmse:0.46312\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.781 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:34:33] [160]\ttrain-rmse:0.35191\tvalid-rmse:0.46257\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:34:34] [161]\ttrain-rmse:0.36922\tvalid-rmse:0.46307\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.777 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.793 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:34:36] [161]\ttrain-rmse:0.35159\tvalid-rmse:0.46262\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:34:38] [162]\ttrain-rmse:0.36896\tvalid-rmse:0.46319\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:34:40] [162]\ttrain-rmse:0.35131\tvalid-rmse:0.46260\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:34:42] [163]\ttrain-rmse:0.36865\tvalid-rmse:0.46304\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:34:43] [163]\ttrain-rmse:0.35112\tvalid-rmse:0.46262\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.781 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:34:45] [164]\ttrain-rmse:0.35086\tvalid-rmse:0.46261\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.783 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:34:47] [164]\ttrain-rmse:0.36840\tvalid-rmse:0.46300\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:34:49] [165]\ttrain-rmse:0.35047\tvalid-rmse:0.46244\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.787 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:34:50] [165]\ttrain-rmse:0.36811\tvalid-rmse:0.46289\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.791 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:34:52] [166]\ttrain-rmse:0.35008\tvalid-rmse:0.46226\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.784 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:34:54] [166]\ttrain-rmse:0.36762\tvalid-rmse:0.46254\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:34:56] [167]\ttrain-rmse:0.36722\tvalid-rmse:0.46235\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 14 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:34:56. Total running time: 45min 44s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521        165            5.85962       0.350855       0.462608 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255          166            9.41648       0.368109       0.462885 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   TERMINATED     0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          20            5.43721       1.12275        1.10853  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.797 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:34:58] [167]\ttrain-rmse:0.34955\tvalid-rmse:0.46199\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.798 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:34:59] [168]\ttrain-rmse:0.36703\tvalid-rmse:0.46232\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.800 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.801 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.801 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.801 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:35:01] [168]\ttrain-rmse:0.34921\tvalid-rmse:0.46203\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.794 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:35:03] [169]\ttrain-rmse:0.36662\tvalid-rmse:0.46209\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:35:05] [169]\ttrain-rmse:0.34881\tvalid-rmse:0.46185\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.783 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:35:07] [170]\ttrain-rmse:0.36616\tvalid-rmse:0.46182\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:35:08] [170]\ttrain-rmse:0.34843\tvalid-rmse:0.46176\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.771 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.771 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:35:10] [171]\ttrain-rmse:0.36588\tvalid-rmse:0.46178\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:35:12] [171]\ttrain-rmse:0.34817\tvalid-rmse:0.46173\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:35:14] [172]\ttrain-rmse:0.36556\tvalid-rmse:0.46181\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:35:15] [172]\ttrain-rmse:0.34796\tvalid-rmse:0.46174\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:35:17] [173]\ttrain-rmse:0.36525\tvalid-rmse:0.46175\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:35:19] [173]\ttrain-rmse:0.34774\tvalid-rmse:0.46175\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.782 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:35:21] [174]\ttrain-rmse:0.36492\tvalid-rmse:0.46153\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:35:22] [174]\ttrain-rmse:0.34742\tvalid-rmse:0.46159\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:35:24] [175]\ttrain-rmse:0.36474\tvalid-rmse:0.46144\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:35:26] [175]\ttrain-rmse:0.34719\tvalid-rmse:0.46153\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 14 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:35:26. Total running time: 46min 14s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521        174            5.88431       0.347739       0.461749 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255          174            9.43898       0.365248       0.461751 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   TERMINATED     0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          20            5.43721       1.12275        1.10853  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.777 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:35:28] [176]\ttrain-rmse:0.34677\tvalid-rmse:0.46155\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.785 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:35:30] [176]\ttrain-rmse:0.36442\tvalid-rmse:0.46140\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:35:31] [177]\ttrain-rmse:0.34653\tvalid-rmse:0.46156\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:35:33] [177]\ttrain-rmse:0.36418\tvalid-rmse:0.46142\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:35:35] [178]\ttrain-rmse:0.34625\tvalid-rmse:0.46138\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.795 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:35:37] [178]\ttrain-rmse:0.36386\tvalid-rmse:0.46117\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:35:38] [179]\ttrain-rmse:0.34584\tvalid-rmse:0.46123\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.797 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.793 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:35:40] [179]\ttrain-rmse:0.36350\tvalid-rmse:0.46092\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:35:42] [180]\ttrain-rmse:0.34544\tvalid-rmse:0.46111\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:35:44] [180]\ttrain-rmse:0.36316\tvalid-rmse:0.46070\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:35:46] [181]\ttrain-rmse:0.34505\tvalid-rmse:0.46089\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.799 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.800 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:35:47] [181]\ttrain-rmse:0.36282\tvalid-rmse:0.46052\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.802 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.802 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.802 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.802 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:35:49] [182]\ttrain-rmse:0.36236\tvalid-rmse:0.46025\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.974 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.974 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.974 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.974 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:35:51] [182]\ttrain-rmse:0.34455\tvalid-rmse:0.46051\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:35:53] [183]\ttrain-rmse:0.36204\tvalid-rmse:0.46002\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.785 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.796 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:35:55] [183]\ttrain-rmse:0.34418\tvalid-rmse:0.46038\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:35:57] [184]\ttrain-rmse:0.36182\tvalid-rmse:0.46000\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.826 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.826 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.826 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.826 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 14 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:35:57. Total running time: 46min 44s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521        182            5.90617       0.345053       0.46089  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255          183            9.46462       0.362358       0.460254 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   TERMINATED     0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          20            5.43721       1.12275        1.10853  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.785 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:35:58] [184]\ttrain-rmse:0.34375\tvalid-rmse:0.45999\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.811 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.811 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.811 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.811 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:36:00] [185]\ttrain-rmse:0.34348\tvalid-rmse:0.46005\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:36:02] [185]\ttrain-rmse:0.36139\tvalid-rmse:0.45991\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.821 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.821 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.821 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.821 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.796 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:36:04] [186]\ttrain-rmse:0.34311\tvalid-rmse:0.45981\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:36:06] [186]\ttrain-rmse:0.36098\tvalid-rmse:0.45980\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.804 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.804 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.804 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.805 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:36:07] [187]\ttrain-rmse:0.34276\tvalid-rmse:0.45973\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.784 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:36:09] [187]\ttrain-rmse:0.36066\tvalid-rmse:0.45993\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.782 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:36:11] [188]\ttrain-rmse:0.34248\tvalid-rmse:0.45964\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.785 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:36:13] [188]\ttrain-rmse:0.36043\tvalid-rmse:0.45992\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:36:14] [189]\ttrain-rmse:0.34216\tvalid-rmse:0.45956\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:36:16] [189]\ttrain-rmse:0.36020\tvalid-rmse:0.45990\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:36:18] [190]\ttrain-rmse:0.34198\tvalid-rmse:0.45950\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:36:20] [190]\ttrain-rmse:0.35997\tvalid-rmse:0.45992\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.792 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:36:22] [191]\ttrain-rmse:0.34170\tvalid-rmse:0.45945\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.790 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:36:23] [191]\ttrain-rmse:0.35960\tvalid-rmse:0.45974\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:36:25] [192]\ttrain-rmse:0.34131\tvalid-rmse:0.45916\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.793 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 14 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:36:27. Total running time: 47min 15s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521        191            5.93092       0.341985       0.459495 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255          191            9.48671       0.359974       0.459923 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   TERMINATED     0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          20            5.43721       1.12275        1.10853  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.797 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:36:27] [192]\ttrain-rmse:0.35928\tvalid-rmse:0.45958\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.783 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:36:29] [193]\ttrain-rmse:0.34100\tvalid-rmse:0.45917\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:36:31] [193]\ttrain-rmse:0.35905\tvalid-rmse:0.45961\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.794 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:36:32] [194]\ttrain-rmse:0.35874\tvalid-rmse:0.45943\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.783 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:36:34] [194]\ttrain-rmse:0.34075\tvalid-rmse:0.45902\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.780 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:36:36] [195]\ttrain-rmse:0.35847\tvalid-rmse:0.45945\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.788 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:36:38] [195]\ttrain-rmse:0.34055\tvalid-rmse:0.45904\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.798 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:36:39] [196]\ttrain-rmse:0.35824\tvalid-rmse:0.45942\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:36:41] [196]\ttrain-rmse:0.34025\tvalid-rmse:0.45900\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.781 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:36:43] [197]\ttrain-rmse:0.33987\tvalid-rmse:0.45881\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.776 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.781 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:36:45] [197]\ttrain-rmse:0.35790\tvalid-rmse:0.45913\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.812 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.812 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.812 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.812 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:36:47] [198]\ttrain-rmse:0.33955\tvalid-rmse:0.45858\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.808 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.808 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.809 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.809 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:36:48] [198]\ttrain-rmse:0.35757\tvalid-rmse:0.45904\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:36:50] [199]\ttrain-rmse:0.33937\tvalid-rmse:0.45856\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.784 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:36:52] [199]\ttrain-rmse:0.35727\tvalid-rmse:0.45906\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:36:54] [200]\ttrain-rmse:0.33914\tvalid-rmse:0.45855\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.813 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.813 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.813 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.813 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:36:56] [200]\ttrain-rmse:0.35708\tvalid-rmse:0.45910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 14 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:36:57. Total running time: 47min 45s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521        200            5.9556        0.339369       0.458561 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255          199            9.5086        0.357573       0.459045 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   TERMINATED     0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          20            5.43721       1.12275        1.10853  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:36:57] [201]\ttrain-rmse:0.33892\tvalid-rmse:0.45854\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:36:59] [201]\ttrain-rmse:0.35677\tvalid-rmse:0.45907\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.773 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:37:01] [202]\ttrain-rmse:0.33856\tvalid-rmse:0.45839\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.791 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.781 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:37:03] [202]\ttrain-rmse:0.35649\tvalid-rmse:0.45883\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:37:04] [203]\ttrain-rmse:0.33830\tvalid-rmse:0.45831\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:37:06] [203]\ttrain-rmse:0.35628\tvalid-rmse:0.45872\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.789 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:37:08] [204]\ttrain-rmse:0.33789\tvalid-rmse:0.45817\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:37:10] [204]\ttrain-rmse:0.35605\tvalid-rmse:0.45852\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:37:12] [205]\ttrain-rmse:0.33770\tvalid-rmse:0.45814\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.789 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:37:13] [205]\ttrain-rmse:0.35587\tvalid-rmse:0.45856\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.937 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.937 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.937 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.937 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:37:15] [206]\ttrain-rmse:0.35560\tvalid-rmse:0.45858\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.780 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:37:17] [206]\ttrain-rmse:0.33747\tvalid-rmse:0.45806\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:37:19] [207]\ttrain-rmse:0.35539\tvalid-rmse:0.45849\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:37:21] [207]\ttrain-rmse:0.33718\tvalid-rmse:0.45793\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.805 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.805 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.805 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.806 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:37:22] [208]\ttrain-rmse:0.35511\tvalid-rmse:0.45837\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:37:24] [208]\ttrain-rmse:0.33688\tvalid-rmse:0.45773\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.776 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:37:26] [209]\ttrain-rmse:0.35484\tvalid-rmse:0.45834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 14 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:37:28. Total running time: 48min 16s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521        208            5.97747       0.33718        0.457933 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255          208            9.53372       0.355385       0.45849  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   TERMINATED     0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          20            5.43721       1.12275        1.10853  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.799 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:37:28] [209]\ttrain-rmse:0.33662\tvalid-rmse:0.45766\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.780 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:37:30] [210]\ttrain-rmse:0.35469\tvalid-rmse:0.45832\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.781 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:37:31] [210]\ttrain-rmse:0.33645\tvalid-rmse:0.45759\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:37:33] [211]\ttrain-rmse:0.35448\tvalid-rmse:0.45832\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.792 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:37:35] [211]\ttrain-rmse:0.33624\tvalid-rmse:0.45746\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.793 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:37:37] [212]\ttrain-rmse:0.35415\tvalid-rmse:0.45825\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:37:38] [212]\ttrain-rmse:0.33598\tvalid-rmse:0.45739\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:37:40] [213]\ttrain-rmse:0.35399\tvalid-rmse:0.45823\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:37:42] [213]\ttrain-rmse:0.33577\tvalid-rmse:0.45737\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.773 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:37:44] [214]\ttrain-rmse:0.35378\tvalid-rmse:0.45827\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:37:46] [214]\ttrain-rmse:0.33552\tvalid-rmse:0.45734\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.794 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:37:47] [215]\ttrain-rmse:0.35348\tvalid-rmse:0.45805\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.776 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:37:49] [215]\ttrain-rmse:0.33529\tvalid-rmse:0.45724\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.784 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:37:51] [216]\ttrain-rmse:0.35326\tvalid-rmse:0.45802\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.798 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:37:53] [216]\ttrain-rmse:0.33507\tvalid-rmse:0.45717\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.785 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:37:54] [217]\ttrain-rmse:0.35297\tvalid-rmse:0.45798\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:37:56] [217]\ttrain-rmse:0.33479\tvalid-rmse:0.45714\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.800 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.801 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.801 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.801 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:37:58] [218]\ttrain-rmse:0.35272\tvalid-rmse:0.45784\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.790 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 14 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:37:58. Total running time: 48min 46s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521        216            5.99934       0.335291       0.45724  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255          217            9.55876       0.35326        0.458016 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   TERMINATED     0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          20            5.43721       1.12275        1.10853  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:38:00] [218]\ttrain-rmse:0.33451\tvalid-rmse:0.45695\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.798 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:38:02] [219]\ttrain-rmse:0.35241\tvalid-rmse:0.45780\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.846 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.847 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.847 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.847 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:38:03] [219]\ttrain-rmse:0.33424\tvalid-rmse:0.45693\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:38:05] [220]\ttrain-rmse:0.35224\tvalid-rmse:0.45774\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.790 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:38:07] [220]\ttrain-rmse:0.33406\tvalid-rmse:0.45693\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:38:09] [221]\ttrain-rmse:0.35212\tvalid-rmse:0.45771\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.777 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:38:11] [221]\ttrain-rmse:0.33394\tvalid-rmse:0.45690\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:38:12] [222]\ttrain-rmse:0.35189\tvalid-rmse:0.45753\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:38:14] [222]\ttrain-rmse:0.33368\tvalid-rmse:0.45679\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.789 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:38:16] [223]\ttrain-rmse:0.35164\tvalid-rmse:0.45753\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:38:18] [223]\ttrain-rmse:0.33330\tvalid-rmse:0.45659\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:38:20] [224]\ttrain-rmse:0.33296\tvalid-rmse:0.45629\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.789 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.790 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:38:21] [224]\ttrain-rmse:0.35140\tvalid-rmse:0.45742\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:38:23] [225]\ttrain-rmse:0.33273\tvalid-rmse:0.45632\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:38:25] [225]\ttrain-rmse:0.35117\tvalid-rmse:0.45744\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.784 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:38:27] [226]\ttrain-rmse:0.33242\tvalid-rmse:0.45623\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:38:28] [226]\ttrain-rmse:0.35092\tvalid-rmse:0.45738\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 14 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:38:28. Total running time: 49min 16s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521        225            6.0249        0.332955       0.456294 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255          225            9.58114       0.351397       0.457418 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   TERMINATED     0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          20            5.43721       1.12275        1.10853  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:38:30] [227]\ttrain-rmse:0.35079\tvalid-rmse:0.45739\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:38:32] [227]\ttrain-rmse:0.33221\tvalid-rmse:0.45620\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.792 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:38:34] [228]\ttrain-rmse:0.35056\tvalid-rmse:0.45725\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:38:35] [228]\ttrain-rmse:0.33189\tvalid-rmse:0.45608\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.771 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:38:37] [229]\ttrain-rmse:0.35020\tvalid-rmse:0.45723\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.948 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.949 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.949 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.949 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:38:39] [229]\ttrain-rmse:0.33159\tvalid-rmse:0.45594\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:38:41] [230]\ttrain-rmse:0.33144\tvalid-rmse:0.45599\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:38:43] [230]\ttrain-rmse:0.35000\tvalid-rmse:0.45725\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:38:44] [231]\ttrain-rmse:0.33111\tvalid-rmse:0.45577\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:38:46] [231]\ttrain-rmse:0.34977\tvalid-rmse:0.45709\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.771 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:38:48] [232]\ttrain-rmse:0.33094\tvalid-rmse:0.45577\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:38:50] [232]\ttrain-rmse:0.34955\tvalid-rmse:0.45707\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:38:52] [233]\ttrain-rmse:0.33069\tvalid-rmse:0.45573\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.782 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:38:53] [233]\ttrain-rmse:0.34938\tvalid-rmse:0.45704\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:38:55] [234]\ttrain-rmse:0.33042\tvalid-rmse:0.45557\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:38:57] [234]\ttrain-rmse:0.34917\tvalid-rmse:0.45690\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.806 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.807 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.807 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.807 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:38:59] [235]\ttrain-rmse:0.33023\tvalid-rmse:0.45553\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 14 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:38:59. Total running time: 49min 47s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521        234            6.04992       0.330687       0.455727 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255          233            9.60401       0.349548       0.457072 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   TERMINATED     0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          20            5.43721       1.12275        1.10853  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:39:00] [235]\ttrain-rmse:0.34894\tvalid-rmse:0.45684\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.773 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:39:02] [236]\ttrain-rmse:0.34873\tvalid-rmse:0.45682\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.786 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:39:04] [236]\ttrain-rmse:0.33000\tvalid-rmse:0.45548\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.784 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:39:06] [237]\ttrain-rmse:0.34851\tvalid-rmse:0.45669\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:39:08] [237]\ttrain-rmse:0.32980\tvalid-rmse:0.45554\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:39:09] [238]\ttrain-rmse:0.34821\tvalid-rmse:0.45658\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:39:11] [238]\ttrain-rmse:0.32945\tvalid-rmse:0.45536\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.776 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:39:13] [239]\ttrain-rmse:0.32924\tvalid-rmse:0.45532\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.781 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:39:15] [239]\ttrain-rmse:0.34798\tvalid-rmse:0.45666\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:39:16] [240]\ttrain-rmse:0.32899\tvalid-rmse:0.45515\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.791 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:39:18] [240]\ttrain-rmse:0.34783\tvalid-rmse:0.45659\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.795 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:39:20] [241]\ttrain-rmse:0.32881\tvalid-rmse:0.45509\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.797 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:39:22] [241]\ttrain-rmse:0.34756\tvalid-rmse:0.45642\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:39:24] [242]\ttrain-rmse:0.32858\tvalid-rmse:0.45498\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:39:25] [242]\ttrain-rmse:0.34733\tvalid-rmse:0.45633\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.791 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.794 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:39:27] [243]\ttrain-rmse:0.32838\tvalid-rmse:0.45487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 14 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:39:29. Total running time: 50min 17s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521        242            6.07155       0.328812       0.455087 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255          242            9.62881       0.347564       0.456422 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   TERMINATED     0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          20            5.43721       1.12275        1.10853  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.790 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:39:29] [243]\ttrain-rmse:0.34718\tvalid-rmse:0.45621\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.785 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:39:31] [244]\ttrain-rmse:0.32812\tvalid-rmse:0.45481\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:39:33] [244]\ttrain-rmse:0.34692\tvalid-rmse:0.45617\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.784 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:39:34] [245]\ttrain-rmse:0.34678\tvalid-rmse:0.45620\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:39:36] [245]\ttrain-rmse:0.32791\tvalid-rmse:0.45491\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.788 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.787 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:39:38] [246]\ttrain-rmse:0.34661\tvalid-rmse:0.45614\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:39:40] [246]\ttrain-rmse:0.32772\tvalid-rmse:0.45487\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:39:41] [247]\ttrain-rmse:0.34645\tvalid-rmse:0.45615\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:39:43] [247]\ttrain-rmse:0.32755\tvalid-rmse:0.45491\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:39:45] [248]\ttrain-rmse:0.34624\tvalid-rmse:0.45604\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:39:47] [248]\ttrain-rmse:0.32739\tvalid-rmse:0.45485\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.791 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.776 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:39:48] [249]\ttrain-rmse:0.34603\tvalid-rmse:0.45590\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:39:50] [249]\ttrain-rmse:0.32723\tvalid-rmse:0.45474\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:39:52] [250]\ttrain-rmse:0.34575\tvalid-rmse:0.45583\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.796 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.773 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:39:54] [250]\ttrain-rmse:0.32705\tvalid-rmse:0.45464\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.790 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:39:56] [251]\ttrain-rmse:0.32672\tvalid-rmse:0.45443\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.797 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:39:57] [251]\ttrain-rmse:0.34558\tvalid-rmse:0.45588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 14 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:39:59. Total running time: 50min 47s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521        251            6.09648       0.327051       0.454644 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255          250            9.65094       0.346034       0.455903 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   TERMINATED     0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          20            5.43721       1.12275        1.10853  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.936 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.937 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.937 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.937 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:39:59] [252]\ttrain-rmse:0.32652\tvalid-rmse:0.45435\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:40:01] [252]\ttrain-rmse:0.34525\tvalid-rmse:0.45569\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:40:03] [253]\ttrain-rmse:0.32635\tvalid-rmse:0.45436\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:40:05] [253]\ttrain-rmse:0.34500\tvalid-rmse:0.45571\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.784 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:40:06] [254]\ttrain-rmse:0.34476\tvalid-rmse:0.45577\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.799 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:40:08] [254]\ttrain-rmse:0.32615\tvalid-rmse:0.45427\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:40:10] [255]\ttrain-rmse:0.34452\tvalid-rmse:0.45577\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:40:12] [255]\ttrain-rmse:0.32595\tvalid-rmse:0.45429\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:40:14] [256]\ttrain-rmse:0.34431\tvalid-rmse:0.45567\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:40:15] [256]\ttrain-rmse:0.32578\tvalid-rmse:0.45424\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.788 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:40:17] [257]\ttrain-rmse:0.32560\tvalid-rmse:0.45423\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:40:19] [257]\ttrain-rmse:0.34404\tvalid-rmse:0.45565\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.782 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:40:21] [258]\ttrain-rmse:0.32530\tvalid-rmse:0.45408\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:40:22] [258]\ttrain-rmse:0.34378\tvalid-rmse:0.45561\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:40:24] [259]\ttrain-rmse:0.32515\tvalid-rmse:0.45409\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.794 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:40:26] [259]\ttrain-rmse:0.34360\tvalid-rmse:0.45554\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:40:28] [260]\ttrain-rmse:0.32493\tvalid-rmse:0.45409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 14 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:40:30. Total running time: 51min 17s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521        259            6.11836       0.325301       0.454082 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255          259            9.67607       0.343784       0.455607 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   TERMINATED     0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          20            5.43721       1.12275        1.10853  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.771 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:40:30] [260]\ttrain-rmse:0.34339\tvalid-rmse:0.45543\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:40:31] [261]\ttrain-rmse:0.32474\tvalid-rmse:0.45406\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.790 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:40:33] [261]\ttrain-rmse:0.34317\tvalid-rmse:0.45530\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:40:35] [262]\ttrain-rmse:0.32459\tvalid-rmse:0.45401\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.781 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:40:37] [262]\ttrain-rmse:0.34297\tvalid-rmse:0.45533\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:40:38] [263]\ttrain-rmse:0.34282\tvalid-rmse:0.45530\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:40:40] [263]\ttrain-rmse:0.32433\tvalid-rmse:0.45406\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:40:42] [264]\ttrain-rmse:0.34267\tvalid-rmse:0.45524\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:40:44] [264]\ttrain-rmse:0.32411\tvalid-rmse:0.45403\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.771 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:40:46] [265]\ttrain-rmse:0.34249\tvalid-rmse:0.45515\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:40:47] [265]\ttrain-rmse:0.32390\tvalid-rmse:0.45401\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.777 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.790 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:40:49] [266]\ttrain-rmse:0.34230\tvalid-rmse:0.45511\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:40:51] [266]\ttrain-rmse:0.32372\tvalid-rmse:0.45400\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.784 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:40:53] [267]\ttrain-rmse:0.34212\tvalid-rmse:0.45509\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:40:54] [267]\ttrain-rmse:0.32353\tvalid-rmse:0.45393\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.796 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:40:56] [268]\ttrain-rmse:0.34200\tvalid-rmse:0.45504\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:40:58] [268]\ttrain-rmse:0.32335\tvalid-rmse:0.45387\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.813 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.813 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.813 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.813 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 14 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:41:00. Total running time: 51min 48s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521        268            6.14359       0.323533       0.453929 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255          267            9.69819       0.342297       0.455108 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   TERMINATED     0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          20            5.43721       1.12275        1.10853  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.773 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:41:00] [269]\ttrain-rmse:0.32314\tvalid-rmse:0.45388\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.821 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.821 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.821 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.821 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:41:02] [269]\ttrain-rmse:0.34184\tvalid-rmse:0.45504\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.792 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:41:03] [270]\ttrain-rmse:0.32301\tvalid-rmse:0.45384\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:41:05] [270]\ttrain-rmse:0.34160\tvalid-rmse:0.45499\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.856 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.856 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.856 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.856 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:41:07] [271]\ttrain-rmse:0.32277\tvalid-rmse:0.45371\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.792 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:41:09] [271]\ttrain-rmse:0.34133\tvalid-rmse:0.45479\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:41:11] [272]\ttrain-rmse:0.32249\tvalid-rmse:0.45359\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:41:12] [272]\ttrain-rmse:0.34106\tvalid-rmse:0.45460\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:41:14] [273]\ttrain-rmse:0.32231\tvalid-rmse:0.45357\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.782 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:41:16] [273]\ttrain-rmse:0.34088\tvalid-rmse:0.45454\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:41:18] [274]\ttrain-rmse:0.32211\tvalid-rmse:0.45355\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:41:20] [274]\ttrain-rmse:0.34075\tvalid-rmse:0.45457\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.847 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.848 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.848 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.848 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:41:22] [275]\ttrain-rmse:0.32200\tvalid-rmse:0.45356\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 2.004 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 2.005 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 2.005 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 2.005 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:41:23] [275]\ttrain-rmse:0.34057\tvalid-rmse:0.45456\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:41:25] [276]\ttrain-rmse:0.32183\tvalid-rmse:0.45350\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:41:27] [276]\ttrain-rmse:0.34035\tvalid-rmse:0.45445\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.783 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.782 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:41:29] [277]\ttrain-rmse:0.32160\tvalid-rmse:0.45339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 14 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:41:30. Total running time: 52min 18s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521        276            6.16543       0.321997       0.453557 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255          276            9.72257       0.340573       0.454556 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   TERMINATED     0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          20            5.43721       1.12275        1.10853  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.795 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:41:30] [277]\ttrain-rmse:0.34013\tvalid-rmse:0.45430\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.787 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:41:32] [278]\ttrain-rmse:0.33990\tvalid-rmse:0.45419\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.777 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:41:34] [278]\ttrain-rmse:0.32137\tvalid-rmse:0.45320\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:41:36] [279]\ttrain-rmse:0.33965\tvalid-rmse:0.45416\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.821 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.821 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.821 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.822 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.823 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.823 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.823 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.823 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:41:38] [279]\ttrain-rmse:0.32113\tvalid-rmse:0.45314\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.771 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:41:39] [280]\ttrain-rmse:0.33944\tvalid-rmse:0.45402\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:41:41] [280]\ttrain-rmse:0.32092\tvalid-rmse:0.45316\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:41:43] [281]\ttrain-rmse:0.32080\tvalid-rmse:0.45318\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.776 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:41:45] [281]\ttrain-rmse:0.33928\tvalid-rmse:0.45401\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:41:47] [282]\ttrain-rmse:0.32061\tvalid-rmse:0.45313\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.776 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:41:48] [282]\ttrain-rmse:0.33911\tvalid-rmse:0.45392\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:41:50] [283]\ttrain-rmse:0.32042\tvalid-rmse:0.45312\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:41:52] [283]\ttrain-rmse:0.33892\tvalid-rmse:0.45397\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.777 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:41:54] [284]\ttrain-rmse:0.32017\tvalid-rmse:0.45292\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:41:55] [284]\ttrain-rmse:0.33864\tvalid-rmse:0.45386\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:41:57] [285]\ttrain-rmse:0.32001\tvalid-rmse:0.45289\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.794 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:41:59] [285]\ttrain-rmse:0.33849\tvalid-rmse:0.45382\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.780 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 14 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:42:01. Total running time: 52min 49s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521        285            6.18961       0.320169       0.452919 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255          284            9.74507       0.338917       0.453972 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   TERMINATED     0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          20            5.43721       1.12275        1.10853  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.789 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:42:01] [286]\ttrain-rmse:0.31979\tvalid-rmse:0.45287\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.789 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:42:03] [286]\ttrain-rmse:0.33826\tvalid-rmse:0.45373\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:42:04] [287]\ttrain-rmse:0.33811\tvalid-rmse:0.45371\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.773 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:42:06] [287]\ttrain-rmse:0.31968\tvalid-rmse:0.45284\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.789 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:42:08] [288]\ttrain-rmse:0.33789\tvalid-rmse:0.45357\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:42:10] [288]\ttrain-rmse:0.31938\tvalid-rmse:0.45261\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:42:11] [289]\ttrain-rmse:0.33772\tvalid-rmse:0.45353\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.773 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.833 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.833 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.833 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.833 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:42:13] [289]\ttrain-rmse:0.31922\tvalid-rmse:0.45257\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:42:15] [290]\ttrain-rmse:0.31906\tvalid-rmse:0.45256\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:42:17] [290]\ttrain-rmse:0.33762\tvalid-rmse:0.45352\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:42:19] [291]\ttrain-rmse:0.31892\tvalid-rmse:0.45256\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:42:20] [291]\ttrain-rmse:0.33751\tvalid-rmse:0.45354\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.839 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.839 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.839 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.839 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:42:22] [292]\ttrain-rmse:0.31874\tvalid-rmse:0.45249\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.788 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:42:24] [292]\ttrain-rmse:0.33736\tvalid-rmse:0.45350\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.780 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:42:26] [293]\ttrain-rmse:0.31855\tvalid-rmse:0.45242\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:42:28] [293]\ttrain-rmse:0.33713\tvalid-rmse:0.45338\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.787 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.783 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:42:29] [294]\ttrain-rmse:0.31839\tvalid-rmse:0.45244\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:42:31] [294]\ttrain-rmse:0.33696\tvalid-rmse:0.45328\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.776 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 14 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:42:31. Total running time: 53min 19s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   RUNNING        0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521        293            6.21159       0.318737       0.452493 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   RUNNING        0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255          293            9.77001       0.337362       0.453502 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   TERMINATED     0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          20            5.43721       1.12275        1.10853  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:42:33] [295]\ttrain-rmse:0.31819\tvalid-rmse:0.45234\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:42:35] [295]\ttrain-rmse:0.33674\tvalid-rmse:0.45320\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:42:36] [296]\ttrain-rmse:0.33662\tvalid-rmse:0.45321\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:42:38] [296]\ttrain-rmse:0.31803\tvalid-rmse:0.45241\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.800 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.801 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.801 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.801 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.793 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:42:40] [297]\ttrain-rmse:0.33646\tvalid-rmse:0.45312\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:42:42] [297]\ttrain-rmse:0.31784\tvalid-rmse:0.45235\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.790 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:42:44] [298]\ttrain-rmse:0.33625\tvalid-rmse:0.45309\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.923 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.923 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.923 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.923 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:42:46] [298]\ttrain-rmse:0.31761\tvalid-rmse:0.45238\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.791 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2640, ip=100.64.27.77)\u001b[0m [12:42:47] [299]\ttrain-rmse:0.33614\tvalid-rmse:0.45308\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.771 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=1527, ip=100.64.47.109)\u001b[0m [12:42:49] [299]\ttrain-rmse:0.31746\tvalid-rmse:0.45246\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.789 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(RayTrainWorker pid=2686, ip=100.64.27.77)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=s3, path=ddl-wadkars/end-to-end/california/air/xgb/xgb_from_s3_irsa/XGBoostTrainer_e84ac5bb_15_alpha=8.2550,colsample_bytree=0.6413,eta=0.0704,eval_metric=rmse,lambda=0.0587,max_depth=9,min_child_we_2025-09-01_12-23-58/checkpoint_000000)\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.795 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(RayTrainWorker pid=1574, ip=100.64.47.109)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=s3, path=ddl-wadkars/end-to-end/california/air/xgb/xgb_from_s3_irsa/XGBoostTrainer_7d9e932d_13_alpha=7.7952,colsample_bytree=0.7199,eta=0.0649,eval_metric=rmse,lambda=1.7914,max_depth=10,min_child_w_2025-09-01_12-23-06/checkpoint_000000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🏃 View run XGBoostTrainer_e84ac5bb at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265/runs/129734f0e7904ebf9f67c5cddc481ab8\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🧪 View experiment at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_e84ac5bb completed after 300 iterations at 2025-09-01 12:42:55. Total running time: 53min 43s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_e84ac5bb result             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ checkpoint_dir_name                              │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_this_iter_s                         0.00272 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_total_s                             9.78906 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ training_iteration                           300 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ train-rmse                               0.33614 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ valid-rmse                               0.45308 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.794 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🏃 View run XGBoostTrainer_7d9e932d at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265/runs/33794669231e48e99fdf89ad663571a9\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🧪 View experiment at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_7d9e932d completed after 300 iterations at 2025-09-01 12:42:57. Total running time: 53min 45s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_7d9e932d result             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ checkpoint_dir_name                              │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_this_iter_s                         0.00263 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_total_s                              6.2301 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ training_iteration                           300 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ train-rmse                               0.31746 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ valid-rmse                               0.45246 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_a8e5711c started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_a8e5711c config                          │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/alpha                             0.014747432898781509 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/colsample_bytree                     0.757180082223907 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eta                               0.006053545890871387 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eval_metric                                       rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/lambda                               2.851421002308228 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/max_depth                                           10 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/min_child_weight                     6.989889833674716 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/nthread                                              1 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/objective                             reg:squarederror │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/subsample                           0.8828633035942388 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/tree_method                                       hist │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=2909, ip=100.64.8.234)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=2909, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=2955) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=2909, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=2956) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=2909, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=2957) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=2909, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=2958) world_rank=3, local_rank=3, node_rank=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 16 TERMINATED | 2 RUNNING | 1 PENDING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:43:01. Total running time: 53min 49s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_a8e5711c   RUNNING        0.00605355                   10                6.98989               0.882863                 0.75718         2.85142           0.0147474                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   TERMINATED     0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521        300            6.2301        0.317463       0.452463 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   TERMINATED     0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255          300            9.78906       0.336139       0.453081 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   TERMINATED     0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          20            5.43721       1.12275        1.10853  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_4b5da2d0   PENDING        0.00564263                    6                0.0151896             0.636346                 0.844179        5.00649           0.38215                                                             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=2955, ip=100.64.8.234)\u001b[0m [12:43:02] Task [xgboost.ray-rank=00000000]:d57263e1dddce879ab519b6504000000 got rank 0\n",
      "\u001b[36m(RayTrainWorker pid=2958, ip=100.64.8.234)\u001b[0m [12:43:02] Task [xgboost.ray-rank=00000003]:98fd4728f28c601854639a2404000000 got rank 3\n",
      "\u001b[36m(RayTrainWorker pid=2957, ip=100.64.8.234)\u001b[0m [12:43:02] Task [xgboost.ray-rank=00000002]:3402914b296222e211fde3f904000000 got rank 2\n",
      "\u001b[36m(RayTrainWorker pid=2956, ip=100.64.8.234)\u001b[0m [12:43:02] Task [xgboost.ray-rank=00000001]:1080c082de4e643e53964ce804000000 got rank 1\n",
      "\u001b[36m(SplitCoordinator pid=3119, ip=100.64.8.234)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=3119, ip=100.64.8.234)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_4b5da2d0 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_4b5da2d0 config                          │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/alpha                               0.3821495632494071 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/colsample_bytree                    0.8441793450221524 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eta                               0.005642631650015626 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eval_metric                                       rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/lambda                               5.006486472861132 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/max_depth                                            6 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/min_child_weight                  0.015189623444954697 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/nthread                                              1 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/objective                             reg:squarederror │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/subsample                            0.636345764118148 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/tree_method                                       hist │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=3044, ip=100.64.27.77)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=3044, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=3090) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=3044, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=3091) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=3044, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=3092) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=3044, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=3093) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(SplitCoordinator pid=3121, ip=100.64.8.234)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=3121, ip=100.64.8.234)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(RayTrainWorker pid=3092, ip=100.64.27.77)\u001b[0m [12:43:05] Task [xgboost.ray-rank=00000002]:690ed20cec7052f4b372a15804000000 got rank 2\n",
      "\u001b[36m(RayTrainWorker pid=3090, ip=100.64.27.77)\u001b[0m [12:43:05] Task [xgboost.ray-rank=00000000]:1cbf798e9a23d00998e8668a04000000 got rank 0\n",
      "\u001b[36m(RayTrainWorker pid=3091, ip=100.64.27.77)\u001b[0m [12:43:05] Task [xgboost.ray-rank=00000001]:ef90c2db42eecf3aaecf8c9d04000000 got rank 1\n",
      "\u001b[36m(RayTrainWorker pid=3093, ip=100.64.27.77)\u001b[0m [12:43:05] Task [xgboost.ray-rank=00000003]:70bf15ef20d7edecbde36e4204000000 got rank 3\n",
      "\u001b[36m(XGBoostTrainer pid=2909, ip=100.64.8.234)\u001b[0m [12:43:05] [0]\ttrain-rmse:1.15238\tvalid-rmse:1.13677\n",
      "\u001b[36m(XGBoostTrainer pid=2909, ip=100.64.8.234)\u001b[0m [12:43:05] [1]\ttrain-rmse:1.14728\tvalid-rmse:1.13202\n",
      "\u001b[36m(SplitCoordinator pid=3254, ip=100.64.27.77)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=3254, ip=100.64.27.77)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(SplitCoordinator pid=3255, ip=100.64.27.77)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=3255, ip=100.64.27.77)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=3044, ip=100.64.27.77)\u001b[0m [12:43:07] [0]\ttrain-rmse:1.15325\tvalid-rmse:1.13741\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.699 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.699 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.699 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.699 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2909, ip=100.64.8.234)\u001b[0m [12:43:07] [2]\ttrain-rmse:1.14218\tvalid-rmse:1.12724\n",
      "\u001b[36m(XGBoostTrainer pid=3044, ip=100.64.27.77)\u001b[0m [12:43:09] [1]\ttrain-rmse:1.14994\tvalid-rmse:1.13422\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.688 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.689 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.689 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.689 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3044, ip=100.64.27.77)\u001b[0m [12:43:10] [2]\ttrain-rmse:1.14658\tvalid-rmse:1.13100\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2909, ip=100.64.8.234)\u001b[0m [12:43:12] [3]\ttrain-rmse:1.13719\tvalid-rmse:1.12274\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3044, ip=100.64.27.77)\u001b[0m [12:43:14] [3]\ttrain-rmse:1.14244\tvalid-rmse:1.12705\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2909, ip=100.64.8.234)\u001b[0m [12:43:16] [4]\ttrain-rmse:1.13207\tvalid-rmse:1.11802\n",
      "\u001b[36m(XGBoostTrainer pid=3044, ip=100.64.27.77)\u001b[0m [12:43:17] [4]\ttrain-rmse:1.13829\tvalid-rmse:1.12318\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2909, ip=100.64.8.234)\u001b[0m [12:43:19] [5]\ttrain-rmse:1.12709\tvalid-rmse:1.11337\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.916 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.917 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.917 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.917 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.734 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2909, ip=100.64.8.234)\u001b[0m [12:43:21] [6]\ttrain-rmse:1.12221\tvalid-rmse:1.10896\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.736 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3044, ip=100.64.27.77)\u001b[0m [12:43:23] [5]\ttrain-rmse:1.13511\tvalid-rmse:1.12017\n",
      "\u001b[36m(XGBoostTrainer pid=2909, ip=100.64.8.234)\u001b[0m [12:43:25] [7]\ttrain-rmse:1.11709\tvalid-rmse:1.10417\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.719 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.720 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.720 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.720 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3044, ip=100.64.27.77)\u001b[0m [12:43:26] [6]\ttrain-rmse:1.13115\tvalid-rmse:1.11647\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.745 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2909, ip=100.64.8.234)\u001b[0m [12:43:28] [8]\ttrain-rmse:1.11205\tvalid-rmse:1.09946\n",
      "\u001b[36m(XGBoostTrainer pid=3044, ip=100.64.27.77)\u001b[0m [12:43:30] [7]\ttrain-rmse:1.12704\tvalid-rmse:1.11257\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.734 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3044, ip=100.64.27.77)\u001b[0m [12:43:32] [8]\ttrain-rmse:1.12332\tvalid-rmse:1.10913\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 16 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:43:32. Total running time: 54min 19s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_a8e5711c   RUNNING        0.00605355                   10                6.98989               0.882863                 0.75718         2.85142           0.0147474        7            5.40427       1.12221        1.10896  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_4b5da2d0   RUNNING        0.00564263                    6                0.0151896             0.636346                 0.844179        5.00649           0.38215          8            3.6976        1.12704        1.11257  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   TERMINATED     0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521        300            6.2301        0.317463       0.452463 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   TERMINATED     0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255          300            9.78906       0.336139       0.453081 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   TERMINATED     0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          20            5.43721       1.12275        1.10853  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.737 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2909, ip=100.64.8.234)\u001b[0m [12:43:33] [9]\ttrain-rmse:1.10694\tvalid-rmse:1.09474\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.729 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3044, ip=100.64.27.77)\u001b[0m [12:43:35] [9]\ttrain-rmse:1.11926\tvalid-rmse:1.10531\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.776 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2909, ip=100.64.8.234)\u001b[0m [12:43:37] [10]\ttrain-rmse:1.10218\tvalid-rmse:1.09042\n",
      "\u001b[36m(XGBoostTrainer pid=3044, ip=100.64.27.77)\u001b[0m [12:43:39] [10]\ttrain-rmse:1.11530\tvalid-rmse:1.10157\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.745 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.742 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2909, ip=100.64.8.234)\u001b[0m [12:43:40] [11]\ttrain-rmse:1.09735\tvalid-rmse:1.08597\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2909, ip=100.64.8.234)\u001b[0m [12:43:42] [12]\ttrain-rmse:1.09292\tvalid-rmse:1.08201\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.731 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3044, ip=100.64.27.77)\u001b[0m [12:43:44] [11]\ttrain-rmse:1.11161\tvalid-rmse:1.09812\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2909, ip=100.64.8.234)\u001b[0m [12:43:46] [13]\ttrain-rmse:1.08824\tvalid-rmse:1.07774\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3044, ip=100.64.27.77)\u001b[0m [12:43:47] [12]\ttrain-rmse:1.10799\tvalid-rmse:1.09481\n",
      "\u001b[36m(XGBoostTrainer pid=2909, ip=100.64.8.234)\u001b[0m [12:43:49] [14]\ttrain-rmse:1.08348\tvalid-rmse:1.07333\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.742 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.725 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3044, ip=100.64.27.77)\u001b[0m [12:43:51] [13]\ttrain-rmse:1.10411\tvalid-rmse:1.09117\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.730 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3044, ip=100.64.27.77)\u001b[0m [12:43:53] [14]\ttrain-rmse:1.10090\tvalid-rmse:1.08815\n",
      "\u001b[36m(XGBoostTrainer pid=2909, ip=100.64.8.234)\u001b[0m [12:43:54] [15]\ttrain-rmse:1.07859\tvalid-rmse:1.06878\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3044, ip=100.64.27.77)\u001b[0m [12:43:56] [15]\ttrain-rmse:1.09700\tvalid-rmse:1.08444\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.781 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2909, ip=100.64.8.234)\u001b[0m [12:43:58] [16]\ttrain-rmse:1.07369\tvalid-rmse:1.06428\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3044, ip=100.64.27.77)\u001b[0m [12:44:00] [16]\ttrain-rmse:1.09311\tvalid-rmse:1.08069\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.807 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.807 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.807 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.807 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2909, ip=100.64.8.234)\u001b[0m [12:44:01] [17]\ttrain-rmse:1.06992\tvalid-rmse:1.06088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 16 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:44:03. Total running time: 54min 51s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_a8e5711c   RUNNING        0.00605355                   10                6.98989               0.882863                 0.75718         2.85142           0.0147474       17            5.43262       1.07369        1.06428  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_4b5da2d0   RUNNING        0.00564263                    6                0.0151896             0.636346                 0.844179        5.00649           0.38215         16            3.72014       1.097          1.08444  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6281491e   TERMINATED     0.00298189                    7                0.0121439             0.960127                 0.992755        2.5111            0.0120425       20            5.42193       1.11182        1.09856  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_1ef99b81   TERMINATED     0.076113                      6                0.0176299             0.857262                 0.802389        0.111482          0.0276126      300            4.55643       0.272212       0.461672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ca919a62   TERMINATED     0.0409273                    10                2.69613               0.7424                   0.701198        0.00497485        1.70261        300            6.2634        0.216421       0.448047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_43af9c66   TERMINATED     0.0140284                     6                7.08865               0.753995                 0.939271        0.392826          5.1271          20            5.46577       0.979262       0.973559 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_98b754ab   TERMINATED     0.0774852                     5                0.90794               0.857505                 0.684854        0.0392929         2.13856         60            5.77824       0.489037       0.537351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_414a200b   TERMINATED     0.00291189                   10                0.0310359             0.905069                 0.888759        0.00270464        7.31984         20           11.9988        1.11121        1.09857  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6092156f   TERMINATED     0.0121645                     8                1.76446               0.902929                 0.651876        0.00452977        0.0103174       20            5.3061        0.990694       0.988484 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7d9e932d   TERMINATED     0.0649387                    10                0.10532               0.780479                 0.719872        1.79137           7.79521        300            6.2301        0.317463       0.452463 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_7b8248b4   TERMINATED     0.0081889                     5                0.142919              0.981737                 0.982569        0.0322917         0.386499        20            5.41634       1.05139        1.04102  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e84ac5bb   TERMINATED     0.0703887                     9                0.207798              0.672295                 0.641316        0.0587241         8.255          300            9.78906       0.336139       0.453081 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5d94a543   TERMINATED     0.00271474                    6                0.0355888             0.646584                 0.661225        0.00922759        0.3285          20            5.43721       1.12275        1.10853  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2909, ip=100.64.8.234)\u001b[0m [12:44:03] [18]\ttrain-rmse:1.06546\tvalid-rmse:1.05687\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.736 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3044, ip=100.64.27.77)\u001b[0m [12:44:05] [17]\ttrain-rmse:1.09045\tvalid-rmse:1.07815\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2909, ip=100.64.8.234)\u001b[0m [12:44:07] [19]\ttrain-rmse:1.06073\tvalid-rmse:1.05251\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3044, ip=100.64.27.77)\u001b[0m [12:44:08] [18]\ttrain-rmse:1.08669\tvalid-rmse:1.07457\n",
      "\u001b[36m(XGBoostTrainer pid=2909, ip=100.64.8.234)\u001b[0m [12:44:10] [20]\ttrain-rmse:1.05626\tvalid-rmse:1.04854\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.713 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.713 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.713 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.713 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3044, ip=100.64.27.77)\u001b[0m [12:44:12] [19]\ttrain-rmse:1.08306\tvalid-rmse:1.07119\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🏃 View run XGBoostTrainer_a8e5711c at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265/runs/aa2a0fdee18e4bf7aea604803fdf7c66\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🧪 View experiment at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_a8e5711c completed after 20 iterations at 2025-09-01 12:44:14. Total running time: 55min 2s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_a8e5711c result             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ checkpoint_dir_name                              │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_this_iter_s                          0.0029 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_total_s                             5.44102 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ training_iteration                            20 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ train-rmse                               1.06073 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ valid-rmse                               1.05251 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.736 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🏃 View run XGBoostTrainer_4b5da2d0 at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265/runs/5bd16511e19c4b5fa5d3a99f85515fdc\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🧪 View experiment at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_4b5da2d0 completed after 20 iterations at 2025-09-01 12:44:16. Total running time: 55min 4s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_4b5da2d0 result             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ checkpoint_dir_name                              │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_this_iter_s                         0.00306 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_total_s                             3.73201 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ training_iteration                            20 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ train-rmse                               1.08306 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ valid-rmse                               1.07119 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_103e890b started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_103e890b config                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/alpha                             0.0026049602688051733 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/colsample_bytree                     0.7853204585556789 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eta                               0.0012846968116179173 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eval_metric                                        rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/lambda                                7.023251658859222 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/max_depth                                             8 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/min_child_weight                      7.519420011426378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/nthread                                               1 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/objective                              reg:squarederror │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/subsample                             0.653198186642738 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/tree_method                                        hist │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=2082, ip=100.64.47.109)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=2082, ip=100.64.47.109)\u001b[0m - (node_id=020c605741033b9152b4c9a349b6d58f62114a723ef561972a9adde1, ip=100.64.47.109, pid=2128) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=2082, ip=100.64.47.109)\u001b[0m - (node_id=020c605741033b9152b4c9a349b6d58f62114a723ef561972a9adde1, ip=100.64.47.109, pid=2129) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=2082, ip=100.64.47.109)\u001b[0m - (node_id=020c605741033b9152b4c9a349b6d58f62114a723ef561972a9adde1, ip=100.64.47.109, pid=2130) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=2082, ip=100.64.47.109)\u001b[0m - (node_id=020c605741033b9152b4c9a349b6d58f62114a723ef561972a9adde1, ip=100.64.47.109, pid=2131) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(RayTrainWorker pid=2129, ip=100.64.47.109)\u001b[0m [12:44:21] Task [xgboost.ray-rank=00000001]:2fe3ac8e952e705823f4ab1304000000 got rank 1\n",
      "\u001b[36m(RayTrainWorker pid=2130, ip=100.64.47.109)\u001b[0m [12:44:21] Task [xgboost.ray-rank=00000002]:64964e852022b3a73bfecdf904000000 got rank 2\n",
      "\u001b[36m(RayTrainWorker pid=2131, ip=100.64.47.109)\u001b[0m [12:44:21] Task [xgboost.ray-rank=00000003]:7b537163d0832c344d676fa104000000 got rank 3\n",
      "\u001b[36m(RayTrainWorker pid=2128, ip=100.64.47.109)\u001b[0m [12:44:21] Task [xgboost.ray-rank=00000000]:0288f34adc47c7648182bb0404000000 got rank 0\n",
      "\u001b[36m(SplitCoordinator pid=2292, ip=100.64.47.109)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=2292, ip=100.64.47.109)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_bd74995d started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_bd74995d config                         │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/alpha                             0.11009308036727729 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/colsample_bytree                   0.6076044352383897 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eta                                0.2535891963781231 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eval_metric                                      rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/lambda                             0.5455293626905843 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/max_depth                                          11 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/min_child_weight                  0.09228541789709127 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/nthread                                             1 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/objective                            reg:squarederror │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/subsample                          0.7466734859764124 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/tree_method                                      hist │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=3357) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=3358) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=3359) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=3360) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(SplitCoordinator pid=2295, ip=100.64.47.109)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=2295, ip=100.64.47.109)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(RayTrainWorker pid=3360, ip=100.64.8.234)\u001b[0m [12:44:24] Task [xgboost.ray-rank=00000003]:5593f94b08ecef5370bcc01004000000 got rank 3\n",
      "\u001b[36m(RayTrainWorker pid=3358, ip=100.64.8.234)\u001b[0m [12:44:24] Task [xgboost.ray-rank=00000001]:a9537451d6cbaa19eeb7d8bf04000000 got rank 1\n",
      "\u001b[36m(RayTrainWorker pid=3357, ip=100.64.8.234)\u001b[0m [12:44:24] Task [xgboost.ray-rank=00000000]:d5aa39a9370cb6e46d8a00c604000000 got rank 0\n",
      "\u001b[36m(RayTrainWorker pid=3359, ip=100.64.8.234)\u001b[0m [12:44:24] Task [xgboost.ray-rank=00000002]:efe6386b3bd63b1fe48ed55b04000000 got rank 2\n",
      "\u001b[36m(XGBoostTrainer pid=2082, ip=100.64.47.109)\u001b[0m [12:44:24] [0]\ttrain-rmse:1.15646\tvalid-rmse:1.14046\n",
      "\u001b[36m(SplitCoordinator pid=3521, ip=100.64.8.234)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=3521, ip=100.64.8.234)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=2082, ip=100.64.47.109)\u001b[0m [12:44:24] [1]\ttrain-rmse:1.15557\tvalid-rmse:1.13961\n",
      "\u001b[36m(SplitCoordinator pid=3522, ip=100.64.8.234)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=3522, ip=100.64.8.234)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=2082, ip=100.64.47.109)\u001b[0m [12:44:26] [2]\ttrain-rmse:1.15462\tvalid-rmse:1.13870\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.705 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.706 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.706 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.706 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:44:26] [0]\ttrain-rmse:0.95265\tvalid-rmse:0.97241\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2082, ip=100.64.47.109)\u001b[0m [12:44:28] [3]\ttrain-rmse:1.15363\tvalid-rmse:1.13776\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.717 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.717 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.717 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.717 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:44:30] [1]\ttrain-rmse:0.82926\tvalid-rmse:0.88327\n",
      "\u001b[36m(XGBoostTrainer pid=2082, ip=100.64.47.109)\u001b[0m [12:44:31] [4]\ttrain-rmse:1.15263\tvalid-rmse:1.13682\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:44:33] [2]\ttrain-rmse:0.73235\tvalid-rmse:0.81417\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 18 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:44:33. Total running time: 55min 21s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937        0.0071157                                                            │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_103e890b   RUNNING        0.0012847                     8                7.51942               0.653198                 0.78532         7.02325          0.00260496        3            5.39145       1.15462        1.1387   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_bd74995d   RUNNING        0.253589                     11                0.0922854             0.746673                 0.607604        0.545529         0.110093          2            3.98588       0.829257       0.883272 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306       0.0027673       300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377        0.399132         60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559          0.0462283        20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788         1.04247          20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312         2.95444          20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 13 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:44:35] [3]\ttrain-rmse:0.65115\tvalid-rmse:0.76687\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.771 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2082, ip=100.64.47.109)\u001b[0m [12:44:37] [5]\ttrain-rmse:1.15172\tvalid-rmse:1.13594\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:44:38] [4]\ttrain-rmse:0.56166\tvalid-rmse:0.70592\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2082, ip=100.64.47.109)\u001b[0m [12:44:40] [6]\ttrain-rmse:1.15076\tvalid-rmse:1.13506\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:44:42] [5]\ttrain-rmse:0.48317\tvalid-rmse:0.64362\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2082, ip=100.64.47.109)\u001b[0m [12:44:44] [7]\ttrain-rmse:1.14973\tvalid-rmse:1.13408\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.742 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:44:45] [6]\ttrain-rmse:0.43398\tvalid-rmse:0.61692\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.790 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2082, ip=100.64.47.109)\u001b[0m [12:44:47] [8]\ttrain-rmse:1.14875\tvalid-rmse:1.13316\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.923 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.923 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.923 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.923 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:44:49] [7]\ttrain-rmse:0.38536\tvalid-rmse:0.58265\n",
      "\u001b[36m(XGBoostTrainer pid=2082, ip=100.64.47.109)\u001b[0m [12:44:51] [9]\ttrain-rmse:1.14772\tvalid-rmse:1.13220\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:44:53] [8]\ttrain-rmse:0.35980\tvalid-rmse:0.57185\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2082, ip=100.64.47.109)\u001b[0m [12:44:54] [10]\ttrain-rmse:1.14675\tvalid-rmse:1.13129\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:44:56] [9]\ttrain-rmse:0.34585\tvalid-rmse:0.56659\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2082, ip=100.64.47.109)\u001b[0m [12:44:58] [11]\ttrain-rmse:1.14580\tvalid-rmse:1.13040\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:45:00] [10]\ttrain-rmse:0.32891\tvalid-rmse:0.56094\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2082, ip=100.64.47.109)\u001b[0m [12:45:02] [12]\ttrain-rmse:1.14489\tvalid-rmse:1.12957\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.796 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:45:03] [11]\ttrain-rmse:0.30543\tvalid-rmse:0.54716\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 18 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:45:03. Total running time: 55min 51s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937        0.0071157                                                            │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_103e890b   RUNNING        0.0012847                     8                7.51942               0.653198                 0.78532         7.02325          0.00260496       11            5.41426       1.14675        1.13129  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_bd74995d   RUNNING        0.253589                     11                0.0922854             0.746673                 0.607604        0.545529         0.110093         11            4.01072       0.328913       0.560939 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306       0.0027673       300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377        0.399132         60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559          0.0462283        20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788         1.04247          20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312         2.95444          20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 13 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2082, ip=100.64.47.109)\u001b[0m [12:45:05] [13]\ttrain-rmse:1.14392\tvalid-rmse:1.12865\n",
      "\u001b[36m(XGBoostTrainer pid=2082, ip=100.64.47.109)\u001b[0m [12:45:07] [14]\ttrain-rmse:1.14300\tvalid-rmse:1.12779\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:45:09] [12]\ttrain-rmse:0.29156\tvalid-rmse:0.54266\n",
      "\u001b[36m(XGBoostTrainer pid=2082, ip=100.64.47.109)\u001b[0m [12:45:10] [15]\ttrain-rmse:1.14198\tvalid-rmse:1.12683\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:45:12] [13]\ttrain-rmse:0.27594\tvalid-rmse:0.54081\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2082, ip=100.64.47.109)\u001b[0m [12:45:14] [16]\ttrain-rmse:1.14097\tvalid-rmse:1.12587\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:45:16] [14]\ttrain-rmse:0.26438\tvalid-rmse:0.53884\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:45:17] [15]\ttrain-rmse:0.25025\tvalid-rmse:0.53059\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2082, ip=100.64.47.109)\u001b[0m [12:45:19] [17]\ttrain-rmse:1.14023\tvalid-rmse:1.12516\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.787 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:45:21] [16]\ttrain-rmse:0.24164\tvalid-rmse:0.52956\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2082, ip=100.64.47.109)\u001b[0m [12:45:23] [18]\ttrain-rmse:1.13927\tvalid-rmse:1.12426\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.739 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:45:24] [17]\ttrain-rmse:0.23597\tvalid-rmse:0.52897\n",
      "\u001b[36m(XGBoostTrainer pid=2082, ip=100.64.47.109)\u001b[0m [12:45:26] [19]\ttrain-rmse:1.13829\tvalid-rmse:1.12335\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:45:28] [18]\ttrain-rmse:0.23050\tvalid-rmse:0.52914\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.786 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.776 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2082, ip=100.64.47.109)\u001b[0m [12:45:30] [20]\ttrain-rmse:1.13732\tvalid-rmse:1.12245\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:45:31] [19]\ttrain-rmse:0.22040\tvalid-rmse:0.52441\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🏃 View run XGBoostTrainer_103e890b at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265/runs/76ec93681cfb47ab88adb2df76e32d5e\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🧪 View experiment at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_103e890b completed after 20 iterations at 2025-09-01 12:45:34. Total running time: 56min 22s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_103e890b result             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ checkpoint_dir_name                              │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_this_iter_s                         0.00284 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_total_s                             5.43879 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ training_iteration                            20 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ train-rmse                               1.13829 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ valid-rmse                               1.12335 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 19 TERMINATED | 2 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:45:34. Total running time: 56min 22s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_bd74995d   RUNNING        0.253589                     11                0.0922854             0.746673                 0.607604        0.545529          0.110093        19            4.03466       0.230496       0.529138 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 14 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:45:36] [20]\ttrain-rmse:0.21543\tvalid-rmse:0.52414\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.788 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:45:37] [21]\ttrain-rmse:0.20979\tvalid-rmse:0.52457\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.804 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.805 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.805 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.805 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_b51fcde7 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_b51fcde7 config                          │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/alpha                               1.2181501437319369 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/colsample_bytree                    0.7221454685888608 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eta                                 0.0400581731980573 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eval_metric                                       rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/lambda                            0.001251637858488988 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/max_depth                                           11 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/min_child_weight                    0.5713673642505706 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/nthread                                              1 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/objective                             reg:squarederror │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/subsample                            0.600197094311514 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/tree_method                                       hist │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=3686) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=3687) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=3688) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=3689) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:45:40] [22]\ttrain-rmse:0.20133\tvalid-rmse:0.52030\n",
      "\u001b[36m(RayTrainWorker pid=3688, ip=100.64.27.77)\u001b[0m [12:45:41] Task [xgboost.ray-rank=00000002]:3e502c25b5ef3fd41ac7367404000000 got rank 2\n",
      "\u001b[36m(RayTrainWorker pid=3686, ip=100.64.27.77)\u001b[0m [12:45:41] Task [xgboost.ray-rank=00000000]:318256128bce2f38a825417704000000 got rank 0\n",
      "\u001b[36m(RayTrainWorker pid=3689, ip=100.64.27.77)\u001b[0m [12:45:41] Task [xgboost.ray-rank=00000003]:6f3ea656f703e4d6058c7e1b04000000 got rank 3\n",
      "\u001b[36m(RayTrainWorker pid=3687, ip=100.64.27.77)\u001b[0m [12:45:41] Task [xgboost.ray-rank=00000001]:9570eb3b41fb4c49693653e804000000 got rank 1\n",
      "\u001b[36m(SplitCoordinator pid=3850, ip=100.64.27.77)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=3850, ip=100.64.27.77)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:45:42] [23]\ttrain-rmse:0.19606\tvalid-rmse:0.51972\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.771 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(SplitCoordinator pid=3851, ip=100.64.27.77)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=3851, ip=100.64.27.77)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.771 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:45:44] [0]\ttrain-rmse:1.12285\tvalid-rmse:1.11043\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:45:44] [1]\ttrain-rmse:1.09451\tvalid-rmse:1.08682\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:45:44] [24]\ttrain-rmse:0.18857\tvalid-rmse:0.51674\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.709 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.709 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.709 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.710 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:45:46] [2]\ttrain-rmse:1.06772\tvalid-rmse:1.06340\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.790 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:45:48] [25]\ttrain-rmse:0.18487\tvalid-rmse:0.51692\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.782 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:45:49] [3]\ttrain-rmse:1.04225\tvalid-rmse:1.04115\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:45:51] [26]\ttrain-rmse:0.18160\tvalid-rmse:0.51702\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:45:53] [4]\ttrain-rmse:1.01050\tvalid-rmse:1.01200\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.735 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:45:55] [27]\ttrain-rmse:0.17656\tvalid-rmse:0.51776\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.773 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:45:56] [5]\ttrain-rmse:0.98359\tvalid-rmse:0.98736\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:45:58] [28]\ttrain-rmse:0.17352\tvalid-rmse:0.51799\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.771 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:46:00] [29]\ttrain-rmse:0.16910\tvalid-rmse:0.51677\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.800 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.800 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.800 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.800 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:46:02] [6]\ttrain-rmse:0.95646\tvalid-rmse:0.96453\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:46:03] [30]\ttrain-rmse:0.16543\tvalid-rmse:0.51680\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 19 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:46:05. Total running time: 56min 53s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_bd74995d   RUNNING        0.253589                     11                0.0922854             0.746673                 0.607604        0.545529          0.110093        30            4.0661        0.169101       0.51677  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b51fcde7   RUNNING        0.0400582                    11                0.571367              0.600197                 0.722145        0.00125164        1.21815          6            5.30841       0.98359        0.987363 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 14 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:46:05] [7]\ttrain-rmse:0.93118\tvalid-rmse:0.94156\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.788 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:46:07] [31]\ttrain-rmse:0.16245\tvalid-rmse:0.51640\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:46:09] [8]\ttrain-rmse:0.90320\tvalid-rmse:0.91607\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:46:11] [9]\ttrain-rmse:0.87984\tvalid-rmse:0.89546\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.732 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:46:12] [32]\ttrain-rmse:0.15839\tvalid-rmse:0.51657\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.773 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:46:14] [10]\ttrain-rmse:0.85715\tvalid-rmse:0.87622\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:46:16] [33]\ttrain-rmse:0.15374\tvalid-rmse:0.51632\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.881 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.881 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.881 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.881 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:46:18] [11]\ttrain-rmse:0.83280\tvalid-rmse:0.85458\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:46:19] [34]\ttrain-rmse:0.15091\tvalid-rmse:0.51618\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:46:21] [35]\ttrain-rmse:0.14776\tvalid-rmse:0.51599\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:46:23] [12]\ttrain-rmse:0.81232\tvalid-rmse:0.83796\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:46:25] [36]\ttrain-rmse:0.14358\tvalid-rmse:0.51471\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:46:27] [13]\ttrain-rmse:0.79210\tvalid-rmse:0.82097\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.777 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:46:28] [37]\ttrain-rmse:0.14077\tvalid-rmse:0.51446\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:46:30] [14]\ttrain-rmse:0.77579\tvalid-rmse:0.80807\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:46:32] [15]\ttrain-rmse:0.75505\tvalid-rmse:0.79031\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:46:34] [38]\ttrain-rmse:0.13750\tvalid-rmse:0.51387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 19 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:46:35. Total running time: 57min 23s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_bd74995d   RUNNING        0.253589                     11                0.0922854             0.746673                 0.607604        0.545529          0.110093        38            4.08808       0.140769       0.514463 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b51fcde7   RUNNING        0.0400582                    11                0.571367              0.600197                 0.722145        0.00125164        1.21815         15            5.33352       0.77579        0.808074 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 14 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:46:35] [16]\ttrain-rmse:0.73725\tvalid-rmse:0.77573\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:46:37] [39]\ttrain-rmse:0.13491\tvalid-rmse:0.51399\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.782 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:46:39] [17]\ttrain-rmse:0.72510\tvalid-rmse:0.76648\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:46:41] [40]\ttrain-rmse:0.13175\tvalid-rmse:0.51389\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:46:42] [41]\ttrain-rmse:0.12816\tvalid-rmse:0.51425\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:46:44] [18]\ttrain-rmse:0.71293\tvalid-rmse:0.75783\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:46:46] [42]\ttrain-rmse:0.12552\tvalid-rmse:0.51437\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:46:48] [19]\ttrain-rmse:0.69496\tvalid-rmse:0.74226\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.786 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:46:49] [43]\ttrain-rmse:0.12291\tvalid-rmse:0.51434\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:46:51] [20]\ttrain-rmse:0.67936\tvalid-rmse:0.72997\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:46:53] [21]\ttrain-rmse:0.66561\tvalid-rmse:0.71976\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.771 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:46:55] [44]\ttrain-rmse:0.12109\tvalid-rmse:0.51385\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.783 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:46:57] [22]\ttrain-rmse:0.64974\tvalid-rmse:0.70614\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.804 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.804 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.804 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.804 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:46:58] [45]\ttrain-rmse:0.11842\tvalid-rmse:0.51411\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.793 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:47:00] [23]\ttrain-rmse:0.63569\tvalid-rmse:0.69554\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:47:02] [46]\ttrain-rmse:0.11587\tvalid-rmse:0.51404\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.784 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:47:04] [24]\ttrain-rmse:0.62024\tvalid-rmse:0.68215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 19 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:47:05. Total running time: 57min 53s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_bd74995d   RUNNING        0.253589                     11                0.0922854             0.746673                 0.607604        0.545529          0.110093        47            4.16165       0.115865       0.514036 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b51fcde7   RUNNING        0.0400582                    11                0.571367              0.600197                 0.722145        0.00125164        1.21815         23            5.35568       0.649742       0.706144 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 14 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:47:05] [47]\ttrain-rmse:0.11375\tvalid-rmse:0.51411\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:47:07] [25]\ttrain-rmse:0.60838\tvalid-rmse:0.67326\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:47:09] [48]\ttrain-rmse:0.11154\tvalid-rmse:0.51406\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:47:11] [26]\ttrain-rmse:0.59621\tvalid-rmse:0.66425\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:47:12] [49]\ttrain-rmse:0.10945\tvalid-rmse:0.51389\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.745 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:47:14] [50]\ttrain-rmse:0.10816\tvalid-rmse:0.51389\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:47:16] [27]\ttrain-rmse:0.58358\tvalid-rmse:0.65334\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:47:18] [51]\ttrain-rmse:0.10596\tvalid-rmse:0.51379\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:47:19] [28]\ttrain-rmse:0.57336\tvalid-rmse:0.64645\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.736 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:47:21] [52]\ttrain-rmse:0.10439\tvalid-rmse:0.51338\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.788 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:47:23] [29]\ttrain-rmse:0.56117\tvalid-rmse:0.63622\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.726 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:47:25] [30]\ttrain-rmse:0.55153\tvalid-rmse:0.62974\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:47:26] [53]\ttrain-rmse:0.10239\tvalid-rmse:0.51362\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.733 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:47:28] [31]\ttrain-rmse:0.54215\tvalid-rmse:0.62299\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:47:30] [54]\ttrain-rmse:0.10024\tvalid-rmse:0.51384\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:47:32] [32]\ttrain-rmse:0.53319\tvalid-rmse:0.61758\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:47:33] [55]\ttrain-rmse:0.09892\tvalid-rmse:0.51373\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:47:35] [33]\ttrain-rmse:0.52292\tvalid-rmse:0.60962\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:47:37] [56]\ttrain-rmse:0.09713\tvalid-rmse:0.51377\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.786 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 19 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:47:37. Total running time: 58min 25s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_bd74995d   RUNNING        0.253589                     11                0.0922854             0.746673                 0.607604        0.545529          0.110093        56            4.18594      0.0989228       0.513729 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b51fcde7   RUNNING        0.0400582                    11                0.571367              0.600197                 0.722145        0.00125164        1.21815         32            5.38167      0.542153        0.622986 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061      0.259345        0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066      0.791622        0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221      1.11827         1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041      1.05956         1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938      1.01147         1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 14 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.933 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.933 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.933 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.933 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:47:39] [34]\ttrain-rmse:0.51434\tvalid-rmse:0.60376\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:47:41] [57]\ttrain-rmse:0.09530\tvalid-rmse:0.51363\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:47:43] [35]\ttrain-rmse:0.50727\tvalid-rmse:0.59876\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:47:44] [58]\ttrain-rmse:0.09373\tvalid-rmse:0.51382\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.780 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.785 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3311, ip=100.64.8.234)\u001b[0m [12:47:46] [59]\ttrain-rmse:0.09161\tvalid-rmse:0.51444\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:47:48] [36]\ttrain-rmse:0.49835\tvalid-rmse:0.59159\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.803 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.803 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.803 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.803 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🏃 View run XGBoostTrainer_bd74995d at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265/runs/0221194f0a8745b9b9c3c83dc35c1cd9\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🧪 View experiment at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_bd74995d completed after 60 iterations at 2025-09-01 12:47:50. Total running time: 58min 38s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_bd74995d result             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ checkpoint_dir_name                              │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_this_iter_s                         0.00277 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_total_s                             4.19689 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ training_iteration                            60 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ train-rmse                               0.09161 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ valid-rmse                               0.51444 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.808 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.808 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.808 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.808 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:47:52] [37]\ttrain-rmse:0.49027\tvalid-rmse:0.58650\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:47:54] [38]\ttrain-rmse:0.48140\tvalid-rmse:0.57943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_ba0f3311 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_ba0f3311 config                          │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/alpha                              0.15376827479731753 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/colsample_bytree                    0.6032540200748999 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eta                                0.23932741065515184 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eval_metric                                       rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/lambda                            0.013485431972754312 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/max_depth                                           10 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/min_child_weight                   0.08226308501762901 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/nthread                                              1 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/objective                             reg:squarederror │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/subsample                            0.777258908618109 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/tree_method                                       hist │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m - (node_id=020c605741033b9152b4c9a349b6d58f62114a723ef561972a9adde1, ip=100.64.47.109, pid=2677) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m - (node_id=020c605741033b9152b4c9a349b6d58f62114a723ef561972a9adde1, ip=100.64.47.109, pid=2678) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m - (node_id=020c605741033b9152b4c9a349b6d58f62114a723ef561972a9adde1, ip=100.64.47.109, pid=2679) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m - (node_id=020c605741033b9152b4c9a349b6d58f62114a723ef561972a9adde1, ip=100.64.47.109, pid=2680) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:47:57] [39]\ttrain-rmse:0.47429\tvalid-rmse:0.57474\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(RayTrainWorker pid=2677, ip=100.64.47.109)\u001b[0m [12:47:57] Task [xgboost.ray-rank=00000000]:59cd7242eaade0aebcfdd2e304000000 got rank 0\n",
      "\u001b[36m(RayTrainWorker pid=2680, ip=100.64.47.109)\u001b[0m [12:47:57] Task [xgboost.ray-rank=00000003]:dd77addeb5d01eb0b41093da04000000 got rank 3\n",
      "\u001b[36m(RayTrainWorker pid=2679, ip=100.64.47.109)\u001b[0m [12:47:57] Task [xgboost.ray-rank=00000002]:63231fe565545984d19a8db704000000 got rank 2\n",
      "\u001b[36m(RayTrainWorker pid=2678, ip=100.64.47.109)\u001b[0m [12:47:57] Task [xgboost.ray-rank=00000001]:fbf856c2f770c457b7f44b9204000000 got rank 1\n",
      "\u001b[36m(SplitCoordinator pid=2842, ip=100.64.47.109)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=2842, ip=100.64.47.109)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:47:59] [40]\ttrain-rmse:0.46678\tvalid-rmse:0.56925\n",
      "\u001b[36m(SplitCoordinator pid=2845, ip=100.64.47.109)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=2845, ip=100.64.47.109)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:48:00] [41]\ttrain-rmse:0.46110\tvalid-rmse:0.56592\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:48:00] [0]\ttrain-rmse:0.96620\tvalid-rmse:0.97904\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:48:00] [1]\ttrain-rmse:0.85456\tvalid-rmse:0.89896\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:48:02] [42]\ttrain-rmse:0.45503\tvalid-rmse:0.56235\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.798 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.706 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.706 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.706 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.706 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:48:04] [2]\ttrain-rmse:0.76428\tvalid-rmse:0.82994\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:48:06] [43]\ttrain-rmse:0.44958\tvalid-rmse:0.55948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 20 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:48:07. Total running time: 58min 55s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b51fcde7   RUNNING        0.0400582                    11                0.571367              0.600197                 0.722145        0.00125164        1.21815         42            5.40968       0.461101       0.565918 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ba0f3311   RUNNING        0.239327                     10                0.0822631             0.777259                 0.603254        0.0134854         0.153768         2            5.40066       0.854557       0.898958 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 15 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:48:07] [3]\ttrain-rmse:0.68509\tvalid-rmse:0.77944\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:48:09] [44]\ttrain-rmse:0.44307\tvalid-rmse:0.55432\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:48:11] [4]\ttrain-rmse:0.59405\tvalid-rmse:0.71445\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.742 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:48:13] [45]\ttrain-rmse:0.43801\tvalid-rmse:0.55152\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:48:14] [5]\ttrain-rmse:0.51518\tvalid-rmse:0.65034\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:48:16] [46]\ttrain-rmse:0.43333\tvalid-rmse:0.54909\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:48:18] [6]\ttrain-rmse:0.46551\tvalid-rmse:0.62645\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:48:20] [47]\ttrain-rmse:0.42850\tvalid-rmse:0.54641\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.737 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:48:21] [7]\ttrain-rmse:0.41472\tvalid-rmse:0.58809\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:48:23] [48]\ttrain-rmse:0.42389\tvalid-rmse:0.54416\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:48:25] [8]\ttrain-rmse:0.38849\tvalid-rmse:0.57583\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:48:27] [49]\ttrain-rmse:0.41922\tvalid-rmse:0.54196\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:48:28] [9]\ttrain-rmse:0.37463\tvalid-rmse:0.57092\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:48:30] [50]\ttrain-rmse:0.41478\tvalid-rmse:0.53964\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:48:32] [10]\ttrain-rmse:0.35727\tvalid-rmse:0.56586\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:48:34] [51]\ttrain-rmse:0.41028\tvalid-rmse:0.53742\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:48:35] [11]\ttrain-rmse:0.32766\tvalid-rmse:0.54990\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.796 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:48:37] [52]\ttrain-rmse:0.40463\tvalid-rmse:0.53355\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:48:39] [12]\ttrain-rmse:0.31444\tvalid-rmse:0.54530\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 20 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:48:39. Total running time: 59min 27s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b51fcde7   RUNNING        0.0400582                    11                0.571367              0.600197                 0.722145        0.00125164        1.21815         51            5.47756       0.414778       0.539642 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ba0f3311   RUNNING        0.239327                     10                0.0822631             0.777259                 0.603254        0.0134854         0.153768        11            5.42587       0.357269       0.565859 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 15 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:48:41] [53]\ttrain-rmse:0.39928\tvalid-rmse:0.52968\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:48:43] [13]\ttrain-rmse:0.30153\tvalid-rmse:0.54294\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.735 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:48:44] [54]\ttrain-rmse:0.39609\tvalid-rmse:0.52778\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:48:46] [14]\ttrain-rmse:0.29102\tvalid-rmse:0.53981\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:48:48] [55]\ttrain-rmse:0.39232\tvalid-rmse:0.52640\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:48:50] [15]\ttrain-rmse:0.27604\tvalid-rmse:0.53015\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:48:51] [56]\ttrain-rmse:0.38852\tvalid-rmse:0.52442\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:48:53] [16]\ttrain-rmse:0.26830\tvalid-rmse:0.52989\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.731 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:48:55] [57]\ttrain-rmse:0.38562\tvalid-rmse:0.52314\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:48:57] [17]\ttrain-rmse:0.26338\tvalid-rmse:0.53018\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.799 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:48:58] [58]\ttrain-rmse:0.38255\tvalid-rmse:0.52148\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:49:00] [18]\ttrain-rmse:0.25756\tvalid-rmse:0.53078\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.793 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:49:02] [59]\ttrain-rmse:0.37934\tvalid-rmse:0.52022\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:49:04] [19]\ttrain-rmse:0.24739\tvalid-rmse:0.52570\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.932 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.933 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.933 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.933 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3640, ip=100.64.27.77)\u001b[0m [12:49:06] [60]\ttrain-rmse:0.37642\tvalid-rmse:0.51872\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.737 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:49:07] [20]\ttrain-rmse:0.24122\tvalid-rmse:0.52616\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🏃 View run XGBoostTrainer_b51fcde7 at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265/runs/dbcf8d11718b49b1a5b4e51ce83839d6\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🧪 View experiment at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_b51fcde7 completed after 60 iterations at 2025-09-01 12:49:10. Total running time: 59min 57s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_b51fcde7 result             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ checkpoint_dir_name                              │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_this_iter_s                         0.00276 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_total_s                             5.50231 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ training_iteration                            60 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ train-rmse                               0.37934 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ valid-rmse                               0.52022 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 21 TERMINATED | 2 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:49:10. Total running time: 59min 57s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ba0f3311   RUNNING        0.239327                     10                0.0822631             0.777259                 0.603254        0.0134854         0.153768        19            5.44752       0.257564       0.530781 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 16 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:49:11] [21]\ttrain-rmse:0.23546\tvalid-rmse:0.52562\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:49:13] [22]\ttrain-rmse:0.22760\tvalid-rmse:0.52244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_64b9ca23 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_64b9ca23 config                         │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/alpha                              3.2141757569445795 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/colsample_bytree                     0.72902550375206 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eta                               0.13565590211497947 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eval_metric                                      rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/lambda                             0.3032685891492452 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/max_depth                                           9 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/min_child_weight                   3.3729198638389333 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/nthread                                             1 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/objective                            reg:squarederror │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/subsample                          0.7129108082481826 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/tree_method                                      hist │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=3906) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=3907) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=3908) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=3909) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:49:16] [23]\ttrain-rmse:0.22332\tvalid-rmse:0.52250\n",
      "\u001b[36m(RayTrainWorker pid=3907, ip=100.64.8.234)\u001b[0m [12:49:16] Task [xgboost.ray-rank=00000001]:a6cdc65110c1c053d8e5933f04000000 got rank 1\n",
      "\u001b[36m(RayTrainWorker pid=3906, ip=100.64.8.234)\u001b[0m [12:49:16] Task [xgboost.ray-rank=00000000]:100bb08b59c31ada55d2163804000000 got rank 0\n",
      "\u001b[36m(RayTrainWorker pid=3908, ip=100.64.8.234)\u001b[0m [12:49:16] Task [xgboost.ray-rank=00000002]:0550f2de4c2e4a895eb479d604000000 got rank 2\n",
      "\u001b[36m(RayTrainWorker pid=3909, ip=100.64.8.234)\u001b[0m [12:49:16] Task [xgboost.ray-rank=00000003]:0550415fcf5fc8518fb7064604000000 got rank 3\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(SplitCoordinator pid=4070, ip=100.64.8.234)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=4070, ip=100.64.8.234)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:49:18] [24]\ttrain-rmse:0.21608\tvalid-rmse:0.52137\n",
      "\u001b[36m(SplitCoordinator pid=4071, ip=100.64.8.234)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=4071, ip=100.64.8.234)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.735 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:49:20] [0]\ttrain-rmse:1.05028\tvalid-rmse:1.04276\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:49:20] [1]\ttrain-rmse:0.97312\tvalid-rmse:0.97423\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:49:20] [25]\ttrain-rmse:0.21328\tvalid-rmse:0.52152\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.692 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.692 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.692 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.692 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:49:21] [2]\ttrain-rmse:0.91098\tvalid-rmse:0.91860\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:49:23] [26]\ttrain-rmse:0.20804\tvalid-rmse:0.52084\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:49:25] [3]\ttrain-rmse:0.85840\tvalid-rmse:0.87141\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.722 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.722 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.722 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.722 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:49:27] [27]\ttrain-rmse:0.20353\tvalid-rmse:0.52145\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:49:28] [4]\ttrain-rmse:0.78635\tvalid-rmse:0.80645\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:49:30] [28]\ttrain-rmse:0.20010\tvalid-rmse:0.52131\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.728 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:49:32] [29]\ttrain-rmse:0.19580\tvalid-rmse:0.51891\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:49:34] [5]\ttrain-rmse:0.73251\tvalid-rmse:0.75491\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:49:35] [30]\ttrain-rmse:0.19108\tvalid-rmse:0.51847\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.787 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:49:37] [6]\ttrain-rmse:0.68640\tvalid-rmse:0.71615\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:49:39] [31]\ttrain-rmse:0.18720\tvalid-rmse:0.51849\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 21 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:49:41. Total running time: 1hr 0min 29s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ba0f3311   RUNNING        0.239327                     10                0.0822631             0.777259                 0.603254        0.0134854         0.153768        30            5.47843       0.195803       0.518906 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_64b9ca23   RUNNING        0.135656                      9                3.37292               0.712911                 0.729026        0.303269          3.21418          6            5.26795       0.732512       0.754913 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 16 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:49:41] [7]\ttrain-rmse:0.64359\tvalid-rmse:0.67621\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:49:42] [8]\ttrain-rmse:0.60468\tvalid-rmse:0.64356\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:49:44] [32]\ttrain-rmse:0.18401\tvalid-rmse:0.51824\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:49:46] [9]\ttrain-rmse:0.57213\tvalid-rmse:0.61442\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:49:48] [33]\ttrain-rmse:0.18061\tvalid-rmse:0.51740\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:49:50] [10]\ttrain-rmse:0.54805\tvalid-rmse:0.59504\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:49:51] [34]\ttrain-rmse:0.17851\tvalid-rmse:0.51729\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.773 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:49:53] [35]\ttrain-rmse:0.17489\tvalid-rmse:0.51709\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:49:55] [11]\ttrain-rmse:0.52346\tvalid-rmse:0.57456\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.784 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:49:57] [36]\ttrain-rmse:0.17186\tvalid-rmse:0.51619\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:49:58] [12]\ttrain-rmse:0.50718\tvalid-rmse:0.56253\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:50:00] [37]\ttrain-rmse:0.16830\tvalid-rmse:0.51640\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.789 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:50:02] [13]\ttrain-rmse:0.49324\tvalid-rmse:0.55207\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.789 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:50:04] [38]\ttrain-rmse:0.16414\tvalid-rmse:0.51528\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:50:05] [14]\ttrain-rmse:0.48283\tvalid-rmse:0.54544\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:50:07] [39]\ttrain-rmse:0.16052\tvalid-rmse:0.51539\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:50:09] [15]\ttrain-rmse:0.46885\tvalid-rmse:0.53553\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:50:11] [40]\ttrain-rmse:0.15728\tvalid-rmse:0.51530\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:50:12] [16]\ttrain-rmse:0.45959\tvalid-rmse:0.52949\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 21 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:50:12. Total running time: 1hr 1min 0s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ba0f3311   RUNNING        0.239327                     10                0.0822631             0.777259                 0.603254        0.0134854         0.153768        39            5.50349       0.164139       0.515284 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_64b9ca23   RUNNING        0.135656                      9                3.37292               0.712911                 0.729026        0.303269          3.21418         15            5.29359       0.482827       0.545444 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 16 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:50:14] [17]\ttrain-rmse:0.45359\tvalid-rmse:0.52634\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:50:16] [41]\ttrain-rmse:0.15409\tvalid-rmse:0.51583\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:50:18] [18]\ttrain-rmse:0.44835\tvalid-rmse:0.52411\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:50:19] [42]\ttrain-rmse:0.15099\tvalid-rmse:0.51578\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:50:21] [19]\ttrain-rmse:0.43857\tvalid-rmse:0.51655\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:50:23] [43]\ttrain-rmse:0.14843\tvalid-rmse:0.51517\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.788 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:50:25] [20]\ttrain-rmse:0.43292\tvalid-rmse:0.51338\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:50:27] [44]\ttrain-rmse:0.14586\tvalid-rmse:0.51414\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:50:28] [21]\ttrain-rmse:0.42714\tvalid-rmse:0.51055\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.792 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.971 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.971 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.971 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.971 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:50:30] [45]\ttrain-rmse:0.14370\tvalid-rmse:0.51412\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:50:32] [22]\ttrain-rmse:0.41771\tvalid-rmse:0.50293\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:50:34] [46]\ttrain-rmse:0.14095\tvalid-rmse:0.51435\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:50:36] [47]\ttrain-rmse:0.13926\tvalid-rmse:0.51468\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:50:37] [23]\ttrain-rmse:0.41378\tvalid-rmse:0.50156\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:50:39] [48]\ttrain-rmse:0.13678\tvalid-rmse:0.51481\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:50:41] [24]\ttrain-rmse:0.40504\tvalid-rmse:0.49517\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.773 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 21 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:50:43. Total running time: 1hr 1min 31s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ba0f3311   RUNNING        0.239327                     10                0.0822631             0.777259                 0.603254        0.0134854         0.153768        48            5.57017       0.139261       0.514683 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_64b9ca23   RUNNING        0.135656                      9                3.37292               0.712911                 0.729026        0.303269          3.21418         23            5.31652       0.417712       0.502933 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 16 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:50:43] [49]\ttrain-rmse:0.13498\tvalid-rmse:0.51456\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:50:44] [25]\ttrain-rmse:0.40225\tvalid-rmse:0.49433\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:50:46] [50]\ttrain-rmse:0.13220\tvalid-rmse:0.51438\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:50:48] [26]\ttrain-rmse:0.39945\tvalid-rmse:0.49326\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:50:50] [51]\ttrain-rmse:0.13041\tvalid-rmse:0.51428\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:50:51] [27]\ttrain-rmse:0.39387\tvalid-rmse:0.48823\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.788 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:50:53] [52]\ttrain-rmse:0.12750\tvalid-rmse:0.51363\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:50:55] [28]\ttrain-rmse:0.39115\tvalid-rmse:0.48735\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:50:57] [29]\ttrain-rmse:0.38747\tvalid-rmse:0.48457\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.797 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:50:59] [53]\ttrain-rmse:0.12483\tvalid-rmse:0.51394\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.788 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:51:00] [30]\ttrain-rmse:0.38561\tvalid-rmse:0.48373\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.814 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.815 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.815 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.815 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:51:02] [54]\ttrain-rmse:0.12292\tvalid-rmse:0.51404\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:51:04] [31]\ttrain-rmse:0.38350\tvalid-rmse:0.48352\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:51:06] [55]\ttrain-rmse:0.12124\tvalid-rmse:0.51426\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.805 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.806 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.806 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.806 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:51:08] [32]\ttrain-rmse:0.38137\tvalid-rmse:0.48327\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:51:09] [56]\ttrain-rmse:0.11941\tvalid-rmse:0.51435\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.771 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:51:11] [33]\ttrain-rmse:0.37879\tvalid-rmse:0.48204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 21 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:51:13. Total running time: 1hr 2min 1s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ba0f3311   RUNNING        0.239327                     10                0.0822631             0.777259                 0.603254        0.0134854         0.153768        56            5.59208       0.121235       0.514257 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_64b9ca23   RUNNING        0.135656                      9                3.37292               0.712911                 0.729026        0.303269          3.21418         32            5.34226       0.383496       0.483524 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 16 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:51:13] [57]\ttrain-rmse:0.11774\tvalid-rmse:0.51393\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:51:15] [34]\ttrain-rmse:0.37641\tvalid-rmse:0.48153\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:51:16] [58]\ttrain-rmse:0.11639\tvalid-rmse:0.51403\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:51:18] [35]\ttrain-rmse:0.37486\tvalid-rmse:0.48112\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.737 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:51:20] [59]\ttrain-rmse:0.11483\tvalid-rmse:0.51412\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:51:22] [36]\ttrain-rmse:0.37251\tvalid-rmse:0.47955\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.734 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=2631, ip=100.64.47.109)\u001b[0m [12:51:23] [60]\ttrain-rmse:0.11316\tvalid-rmse:0.51396\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:51:25] [37]\ttrain-rmse:0.37076\tvalid-rmse:0.47927\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🏃 View run XGBoostTrainer_ba0f3311 at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265/runs/6bf53f8d38ab447994791bbdb9605a1f\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🧪 View experiment at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_ba0f3311 completed after 60 iterations at 2025-09-01 12:51:27. Total running time: 1hr 2min 15s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_ba0f3311 result             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ checkpoint_dir_name                              │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_this_iter_s                         0.00265 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_total_s                             5.60282 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ training_iteration                            60 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ train-rmse                               0.11483 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ valid-rmse                               0.51412 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:51:29] [38]\ttrain-rmse:0.36757\tvalid-rmse:0.47712\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:51:31] [39]\ttrain-rmse:0.36582\tvalid-rmse:0.47624\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_640034a0 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_640034a0 config                         │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/alpha                               1.254777152503567 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/colsample_bytree                   0.7315701272401014 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eta                               0.03803492828743528 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eval_metric                                      rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/lambda                             1.0276248602164253 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/max_depth                                           9 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/min_child_weight                   0.4922638540547889 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/nthread                                             1 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/objective                            reg:squarederror │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/subsample                          0.7621429092907877 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/tree_method                                      hist │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=4189, ip=100.64.27.77)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=4189, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=4235) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=4189, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=4236) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=4189, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=4237) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=4189, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=4238) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:51:34] [40]\ttrain-rmse:0.36336\tvalid-rmse:0.47456\n",
      "\u001b[36m(RayTrainWorker pid=4235, ip=100.64.27.77)\u001b[0m [12:51:34] Task [xgboost.ray-rank=00000000]:1ae960360e3d9e3ddfece18a04000000 got rank 0\n",
      "\u001b[36m(RayTrainWorker pid=4238, ip=100.64.27.77)\u001b[0m [12:51:34] Task [xgboost.ray-rank=00000003]:1e65b134c7193f61d2bf1a9804000000 got rank 3\n",
      "\u001b[36m(RayTrainWorker pid=4236, ip=100.64.27.77)\u001b[0m [12:51:34] Task [xgboost.ray-rank=00000001]:1039d7f17697e7d9e39481ec04000000 got rank 1\n",
      "\u001b[36m(RayTrainWorker pid=4237, ip=100.64.27.77)\u001b[0m [12:51:34] Task [xgboost.ray-rank=00000002]:bf81a550d18387dc2787076404000000 got rank 2\n",
      "\u001b[36m(SplitCoordinator pid=4399, ip=100.64.27.77)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=4399, ip=100.64.27.77)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:51:36] [41]\ttrain-rmse:0.36172\tvalid-rmse:0.47447\n",
      "\u001b[36m(SplitCoordinator pid=4400, ip=100.64.27.77)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=4400, ip=100.64.27.77)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:51:38] [42]\ttrain-rmse:0.36043\tvalid-rmse:0.47421\n",
      "\u001b[36m(XGBoostTrainer pid=4189, ip=100.64.27.77)\u001b[0m [12:51:38] [0]\ttrain-rmse:1.12596\tvalid-rmse:1.11272\n",
      "\u001b[36m(XGBoostTrainer pid=4189, ip=100.64.27.77)\u001b[0m [12:51:38] [1]\ttrain-rmse:1.10131\tvalid-rmse:1.09103\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:51:39] [43]\ttrain-rmse:0.35902\tvalid-rmse:0.47399\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.687 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.688 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.688 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.688 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4189, ip=100.64.27.77)\u001b[0m [12:51:41] [2]\ttrain-rmse:1.07883\tvalid-rmse:1.07033\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:51:43] [44]\ttrain-rmse:0.35688\tvalid-rmse:0.47194\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 22 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:51:45. Total running time: 1hr 2min 32s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_64b9ca23   RUNNING        0.135656                      9                3.37292               0.712911                 0.729026        0.303269          3.21418         43            5.41681       0.360427       0.474209 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_640034a0   RUNNING        0.0380349                     9                0.492264              0.762143                 0.73157         1.02762           1.25478          2            5.45998       1.10131        1.09103  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 17 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.780 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4189, ip=100.64.27.77)\u001b[0m [12:51:45] [3]\ttrain-rmse:1.05622\tvalid-rmse:1.04979\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:51:46] [45]\ttrain-rmse:0.35558\tvalid-rmse:0.47171\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4189, ip=100.64.27.77)\u001b[0m [12:51:48] [4]\ttrain-rmse:1.02679\tvalid-rmse:1.02277\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:51:50] [46]\ttrain-rmse:0.35398\tvalid-rmse:0.47172\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4189, ip=100.64.27.77)\u001b[0m [12:51:52] [5]\ttrain-rmse:1.00293\tvalid-rmse:0.99992\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:51:53] [47]\ttrain-rmse:0.35270\tvalid-rmse:0.47127\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.948 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.948 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.948 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.948 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4189, ip=100.64.27.77)\u001b[0m [12:51:55] [6]\ttrain-rmse:0.97776\tvalid-rmse:0.97772\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:51:57] [48]\ttrain-rmse:0.35088\tvalid-rmse:0.47082\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4189, ip=100.64.27.77)\u001b[0m [12:51:59] [7]\ttrain-rmse:0.95521\tvalid-rmse:0.95629\n",
      "\u001b[36m(XGBoostTrainer pid=4189, ip=100.64.27.77)\u001b[0m [12:52:01] [8]\ttrain-rmse:0.92992\tvalid-rmse:0.93290\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:52:02] [49]\ttrain-rmse:0.34952\tvalid-rmse:0.47054\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4189, ip=100.64.27.77)\u001b[0m [12:52:04] [9]\ttrain-rmse:0.90899\tvalid-rmse:0.91332\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:52:06] [50]\ttrain-rmse:0.34848\tvalid-rmse:0.47067\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4189, ip=100.64.27.77)\u001b[0m [12:52:08] [10]\ttrain-rmse:0.88740\tvalid-rmse:0.89394\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:52:09] [51]\ttrain-rmse:0.34717\tvalid-rmse:0.47031\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4189, ip=100.64.27.77)\u001b[0m [12:52:11] [11]\ttrain-rmse:0.86458\tvalid-rmse:0.87329\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:52:13] [52]\ttrain-rmse:0.34473\tvalid-rmse:0.46869\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 22 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:52:15. Total running time: 1hr 3min 3s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_64b9ca23   RUNNING        0.135656                      9                3.37292               0.712911                 0.729026        0.303269          3.21418         51            5.4388        0.348479       0.470672 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_640034a0   RUNNING        0.0380349                     9                0.492264              0.762143                 0.73157         1.02762           1.25478         11            5.48559       0.887403       0.89394  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 17 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4189, ip=100.64.27.77)\u001b[0m [12:52:15] [12]\ttrain-rmse:0.84596\tvalid-rmse:0.85742\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:52:17] [53]\ttrain-rmse:0.34217\tvalid-rmse:0.46746\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4189, ip=100.64.27.77)\u001b[0m [12:52:18] [13]\ttrain-rmse:0.82669\tvalid-rmse:0.84047\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.784 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:52:20] [54]\ttrain-rmse:0.34083\tvalid-rmse:0.46733\n",
      "\u001b[36m(XGBoostTrainer pid=4189, ip=100.64.27.77)\u001b[0m [12:52:22] [14]\ttrain-rmse:0.81192\tvalid-rmse:0.82743\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.792 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:52:24] [55]\ttrain-rmse:0.33970\tvalid-rmse:0.46717\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.798 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.771 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4189, ip=100.64.27.77)\u001b[0m [12:52:25] [15]\ttrain-rmse:0.79299\tvalid-rmse:0.81085\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:52:27] [56]\ttrain-rmse:0.33875\tvalid-rmse:0.46693\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.794 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4189, ip=100.64.27.77)\u001b[0m [12:52:29] [16]\ttrain-rmse:0.77603\tvalid-rmse:0.79612\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.782 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:52:31] [57]\ttrain-rmse:0.33780\tvalid-rmse:0.46689\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4189, ip=100.64.27.77)\u001b[0m [12:52:33] [17]\ttrain-rmse:0.76544\tvalid-rmse:0.78721\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:52:34] [58]\ttrain-rmse:0.33666\tvalid-rmse:0.46682\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.782 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.781 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4189, ip=100.64.27.77)\u001b[0m [12:52:36] [18]\ttrain-rmse:0.75448\tvalid-rmse:0.77893\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:52:38] [59]\ttrain-rmse:0.33507\tvalid-rmse:0.46661\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.776 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4189, ip=100.64.27.77)\u001b[0m [12:52:40] [19]\ttrain-rmse:0.73782\tvalid-rmse:0.76399\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:52:41] [60]\ttrain-rmse:0.33397\tvalid-rmse:0.46620\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:52:43] [61]\ttrain-rmse:0.33247\tvalid-rmse:0.46657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 22 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:52:45. Total running time: 1hr 3min 33s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_64b9ca23   RUNNING        0.135656                      9                3.37292               0.712911                 0.729026        0.303269          3.21418         60            5.46338       0.335075       0.466613 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_640034a0   RUNNING        0.0380349                     9                0.492264              0.762143                 0.73157         1.02762           1.25478         19            5.50829       0.754481       0.778928 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 17 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4189, ip=100.64.27.77)\u001b[0m [12:52:45] [20]\ttrain-rmse:0.72293\tvalid-rmse:0.75160\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:52:47] [62]\ttrain-rmse:0.33103\tvalid-rmse:0.46696\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🏃 View run XGBoostTrainer_640034a0 at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265/runs/829c3e1b7216453f8c6fc97e1885c272\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🧪 View experiment at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_640034a0 completed after 20 iterations at 2025-09-01 12:52:49. Total running time: 1hr 3min 37s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_640034a0 result             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ checkpoint_dir_name                              │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_this_iter_s                         0.00289 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_total_s                             5.51117 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ training_iteration                            20 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ train-rmse                               0.73782 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ valid-rmse                               0.76399 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:52:51] [63]\ttrain-rmse:0.32909\tvalid-rmse:0.46563\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:52:53] [64]\ttrain-rmse:0.32704\tvalid-rmse:0.46452\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_5a5e2e10 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_5a5e2e10 config                         │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/alpha                               8.989580556510875 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/colsample_bytree                   0.6925944022295143 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eta                               0.12599800867024705 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eval_metric                                      rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/lambda                              9.509196682020773 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/max_depth                                          11 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/min_child_weight                   0.0654222265985658 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/nthread                                             1 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/objective                            reg:squarederror │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/subsample                          0.7852380635329604 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/tree_method                                      hist │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m - (node_id=020c605741033b9152b4c9a349b6d58f62114a723ef561972a9adde1, ip=100.64.47.109, pid=3228) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m - (node_id=020c605741033b9152b4c9a349b6d58f62114a723ef561972a9adde1, ip=100.64.47.109, pid=3229) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m - (node_id=020c605741033b9152b4c9a349b6d58f62114a723ef561972a9adde1, ip=100.64.47.109, pid=3230) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m - (node_id=020c605741033b9152b4c9a349b6d58f62114a723ef561972a9adde1, ip=100.64.47.109, pid=3231) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.804 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.804 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.804 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.804 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:52:56] [65]\ttrain-rmse:0.32560\tvalid-rmse:0.46465\n",
      "\u001b[36m(RayTrainWorker pid=3231, ip=100.64.47.109)\u001b[0m [12:52:56] Task [xgboost.ray-rank=00000003]:8e2609b12ab7514157db365904000000 got rank 3\n",
      "\u001b[36m(RayTrainWorker pid=3228, ip=100.64.47.109)\u001b[0m [12:52:56] Task [xgboost.ray-rank=00000000]:7b312696c3cdc734ee91155e04000000 got rank 0\n",
      "\u001b[36m(RayTrainWorker pid=3229, ip=100.64.47.109)\u001b[0m [12:52:56] Task [xgboost.ray-rank=00000001]:3a1c70df7a958329e5ae3d5504000000 got rank 1\n",
      "\u001b[36m(RayTrainWorker pid=3230, ip=100.64.47.109)\u001b[0m [12:52:56] Task [xgboost.ray-rank=00000002]:f97e84728642c176236b2f3304000000 got rank 2\n",
      "\u001b[36m(SplitCoordinator pid=3392, ip=100.64.47.109)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=3392, ip=100.64.47.109)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:52:57] [66]\ttrain-rmse:0.32436\tvalid-rmse:0.46442\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.787 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(SplitCoordinator pid=3395, ip=100.64.47.109)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=3395, ip=100.64.47.109)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:52:59] [67]\ttrain-rmse:0.32330\tvalid-rmse:0.46420\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:52:59] [0]\ttrain-rmse:1.06548\tvalid-rmse:1.05712\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.794 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:53:01] [68]\ttrain-rmse:0.32255\tvalid-rmse:0.46413\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.739 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:53:03] [1]\ttrain-rmse:1.00236\tvalid-rmse:0.99956\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:53:04] [2]\ttrain-rmse:0.94763\tvalid-rmse:0.94994\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.784 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:53:06] [69]\ttrain-rmse:0.32135\tvalid-rmse:0.46390\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.782 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:53:08] [3]\ttrain-rmse:0.90010\tvalid-rmse:0.90603\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:53:10] [70]\ttrain-rmse:0.32024\tvalid-rmse:0.46377\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:53:11] [4]\ttrain-rmse:0.83597\tvalid-rmse:0.84826\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:53:13] [71]\ttrain-rmse:0.31921\tvalid-rmse:0.46324\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 23 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:53:15. Total running time: 1hr 4min 3s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_64b9ca23   RUNNING        0.135656                      9                3.37292               0.712911                 0.729026        0.303269          3.21418         71            5.49318       0.320245       0.463769 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5a5e2e10   RUNNING        0.125998                     11                0.0654222             0.785238                 0.692594        9.5092            8.98958          4            5.40549       0.900103       0.906034 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 18 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:53:15] [72]\ttrain-rmse:0.31750\tvalid-rmse:0.46241\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:53:17] [5]\ttrain-rmse:0.78179\tvalid-rmse:0.79751\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.739 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.739 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:53:19] [73]\ttrain-rmse:0.31594\tvalid-rmse:0.46225\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:53:20] [6]\ttrain-rmse:0.73785\tvalid-rmse:0.75907\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.884 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.884 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.884 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.884 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:53:22] [74]\ttrain-rmse:0.31469\tvalid-rmse:0.46205\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:53:24] [7]\ttrain-rmse:0.69713\tvalid-rmse:0.72150\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.745 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:53:26] [75]\ttrain-rmse:0.31312\tvalid-rmse:0.46076\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:53:27] [8]\ttrain-rmse:0.66074\tvalid-rmse:0.68920\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:53:29] [76]\ttrain-rmse:0.31186\tvalid-rmse:0.46066\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:53:31] [9]\ttrain-rmse:0.63007\tvalid-rmse:0.66137\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:53:33] [77]\ttrain-rmse:0.31095\tvalid-rmse:0.46041\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:53:34] [10]\ttrain-rmse:0.60489\tvalid-rmse:0.64035\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.798 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.798 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:53:36] [78]\ttrain-rmse:0.30998\tvalid-rmse:0.46035\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.801 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.802 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.802 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.802 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:53:38] [11]\ttrain-rmse:0.58118\tvalid-rmse:0.62018\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.782 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:53:40] [79]\ttrain-rmse:0.30887\tvalid-rmse:0.46051\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:53:42] [12]\ttrain-rmse:0.56354\tvalid-rmse:0.60637\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:53:43] [80]\ttrain-rmse:0.30778\tvalid-rmse:0.46038\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:53:45] [13]\ttrain-rmse:0.54826\tvalid-rmse:0.59388\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 23 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:53:45. Total running time: 1hr 4min 33s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_64b9ca23   RUNNING        0.135656                      9                3.37292               0.712911                 0.729026        0.303269          3.21418         79            5.51495       0.309982       0.460353 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5a5e2e10   RUNNING        0.125998                     11                0.0654222             0.785238                 0.692594        9.5092            8.98958         13            5.43427       0.563539       0.60637  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 18 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:53:47] [81]\ttrain-rmse:0.30669\tvalid-rmse:0.45995\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:53:49] [14]\ttrain-rmse:0.53800\tvalid-rmse:0.58581\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:53:50] [82]\ttrain-rmse:0.30557\tvalid-rmse:0.45944\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:53:52] [15]\ttrain-rmse:0.52353\tvalid-rmse:0.57363\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.781 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.745 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:53:54] [83]\ttrain-rmse:0.30462\tvalid-rmse:0.45967\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.781 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:53:56] [16]\ttrain-rmse:0.51379\tvalid-rmse:0.56585\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:53:58] [84]\ttrain-rmse:0.30373\tvalid-rmse:0.45967\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:53:59] [17]\ttrain-rmse:0.50791\tvalid-rmse:0.56189\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:54:01] [85]\ttrain-rmse:0.30263\tvalid-rmse:0.45942\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:54:03] [18]\ttrain-rmse:0.50303\tvalid-rmse:0.55928\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:54:05] [86]\ttrain-rmse:0.30194\tvalid-rmse:0.45937\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:54:06] [19]\ttrain-rmse:0.49182\tvalid-rmse:0.55043\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:54:08] [87]\ttrain-rmse:0.30100\tvalid-rmse:0.45935\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:54:10] [20]\ttrain-rmse:0.48556\tvalid-rmse:0.54568\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:54:12] [88]\ttrain-rmse:0.29950\tvalid-rmse:0.45876\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:54:13] [21]\ttrain-rmse:0.47975\tvalid-rmse:0.54164\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 23 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:54:15. Total running time: 1hr 5min 3s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_64b9ca23   RUNNING        0.135656                      9                3.37292               0.712911                 0.729026        0.303269          3.21418         88            5.54037       0.301003       0.459351 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5a5e2e10   RUNNING        0.125998                     11                0.0654222             0.785238                 0.692594        9.5092            8.98958         21            5.45702       0.485555       0.545683 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 18 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:54:15] [89]\ttrain-rmse:0.29866\tvalid-rmse:0.45880\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:54:17] [22]\ttrain-rmse:0.46903\tvalid-rmse:0.53235\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:54:19] [90]\ttrain-rmse:0.29771\tvalid-rmse:0.45871\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:54:20] [23]\ttrain-rmse:0.46444\tvalid-rmse:0.52948\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:54:22] [91]\ttrain-rmse:0.29656\tvalid-rmse:0.45890\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.773 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:54:24] [24]\ttrain-rmse:0.45562\tvalid-rmse:0.52219\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.791 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:54:26] [92]\ttrain-rmse:0.29564\tvalid-rmse:0.45920\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.805 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.805 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.805 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.805 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:54:28] [25]\ttrain-rmse:0.45272\tvalid-rmse:0.52070\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:54:29] [93]\ttrain-rmse:0.29510\tvalid-rmse:0.45913\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.790 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:54:31] [26]\ttrain-rmse:0.44971\tvalid-rmse:0.51874\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.783 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.783 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:54:33] [94]\ttrain-rmse:0.29430\tvalid-rmse:0.45911\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:54:35] [27]\ttrain-rmse:0.44342\tvalid-rmse:0.51339\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.787 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:54:37] [95]\ttrain-rmse:0.29348\tvalid-rmse:0.45921\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:54:38] [28]\ttrain-rmse:0.44122\tvalid-rmse:0.51213\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.795 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.796 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:54:40] [29]\ttrain-rmse:0.43556\tvalid-rmse:0.50724\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:54:42] [96]\ttrain-rmse:0.29272\tvalid-rmse:0.45923\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.777 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:54:44] [30]\ttrain-rmse:0.43339\tvalid-rmse:0.50632\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:54:46] [97]\ttrain-rmse:0.29198\tvalid-rmse:0.45918\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.926 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.927 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.927 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.927 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 23 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:54:46. Total running time: 1hr 5min 33s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_64b9ca23   RUNNING        0.135656                      9                3.37292               0.712911                 0.729026        0.303269          3.21418         96            5.56204       0.293485       0.459212 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5a5e2e10   RUNNING        0.125998                     11                0.0654222             0.785238                 0.692594        9.5092            8.98958         30            5.48312       0.435564       0.507241 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 18 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:54:47] [31]\ttrain-rmse:0.43159\tvalid-rmse:0.50556\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.785 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.788 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:54:49] [98]\ttrain-rmse:0.29105\tvalid-rmse:0.45929\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:54:51] [32]\ttrain-rmse:0.42944\tvalid-rmse:0.50455\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.784 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:54:53] [99]\ttrain-rmse:0.29032\tvalid-rmse:0.45907\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.797 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:54:55] [33]\ttrain-rmse:0.42600\tvalid-rmse:0.50215\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:54:56] [100]\ttrain-rmse:0.28930\tvalid-rmse:0.45894\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:54:58] [34]\ttrain-rmse:0.42404\tvalid-rmse:0.50171\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.780 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:55:00] [101]\ttrain-rmse:0.28829\tvalid-rmse:0.45921\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:55:02] [102]\ttrain-rmse:0.28732\tvalid-rmse:0.45940\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.838 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.838 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.838 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.838 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:55:03] [35]\ttrain-rmse:0.42196\tvalid-rmse:0.50029\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.781 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:55:05] [103]\ttrain-rmse:0.28656\tvalid-rmse:0.45889\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:55:07] [36]\ttrain-rmse:0.41807\tvalid-rmse:0.49710\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:55:09] [104]\ttrain-rmse:0.28580\tvalid-rmse:0.45875\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:55:11] [37]\ttrain-rmse:0.41641\tvalid-rmse:0.49614\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:55:12] [38]\ttrain-rmse:0.41292\tvalid-rmse:0.49356\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:55:14] [105]\ttrain-rmse:0.28518\tvalid-rmse:0.45877\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:55:16] [39]\ttrain-rmse:0.41127\tvalid-rmse:0.49298\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 23 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:55:16. Total running time: 1hr 6min 4s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_64b9ca23   RUNNING        0.135656                      9                3.37292               0.712911                 0.729026        0.303269          3.21418        104            5.58446       0.286561       0.458891 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5a5e2e10   RUNNING        0.125998                     11                0.0654222             0.785238                 0.692594        9.5092            8.98958         39            5.50835       0.412921       0.49356  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 18 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:55:18] [106]\ttrain-rmse:0.28423\tvalid-rmse:0.45837\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:55:19] [40]\ttrain-rmse:0.40842\tvalid-rmse:0.49080\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:55:21] [107]\ttrain-rmse:0.28349\tvalid-rmse:0.45842\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:55:23] [41]\ttrain-rmse:0.40726\tvalid-rmse:0.49019\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:55:25] [108]\ttrain-rmse:0.28294\tvalid-rmse:0.45825\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.730 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:55:26] [42]\ttrain-rmse:0.40614\tvalid-rmse:0.48992\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:55:28] [109]\ttrain-rmse:0.28195\tvalid-rmse:0.45794\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:55:30] [43]\ttrain-rmse:0.40517\tvalid-rmse:0.48948\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:55:32] [110]\ttrain-rmse:0.28149\tvalid-rmse:0.45784\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.777 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:55:33] [111]\ttrain-rmse:0.28048\tvalid-rmse:0.45740\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:55:35] [44]\ttrain-rmse:0.40279\tvalid-rmse:0.48739\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:55:37] [112]\ttrain-rmse:0.27956\tvalid-rmse:0.45761\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.929 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.929 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.929 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.929 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:55:39] [45]\ttrain-rmse:0.40145\tvalid-rmse:0.48687\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:55:41] [113]\ttrain-rmse:0.27895\tvalid-rmse:0.45763\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:55:42] [46]\ttrain-rmse:0.40064\tvalid-rmse:0.48654\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:55:44] [47]\ttrain-rmse:0.39964\tvalid-rmse:0.48613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 23 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:55:46. Total running time: 1hr 6min 34s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_64b9ca23   RUNNING        0.135656                      9                3.37292               0.712911                 0.729026        0.303269          3.21418        113            5.60915       0.27956        0.457608 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5a5e2e10   RUNNING        0.125998                     11                0.0654222             0.785238                 0.692594        9.5092            8.98958         47            5.57261       0.400638       0.486541 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 18 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.786 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:55:46] [114]\ttrain-rmse:0.27837\tvalid-rmse:0.45723\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:55:48] [48]\ttrain-rmse:0.39861\tvalid-rmse:0.48581\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.793 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:55:50] [115]\ttrain-rmse:0.27795\tvalid-rmse:0.45744\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:55:51] [49]\ttrain-rmse:0.39754\tvalid-rmse:0.48536\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.788 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.777 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:55:53] [116]\ttrain-rmse:0.27712\tvalid-rmse:0.45728\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:55:55] [50]\ttrain-rmse:0.39661\tvalid-rmse:0.48501\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.776 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.797 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:55:57] [117]\ttrain-rmse:0.27661\tvalid-rmse:0.45742\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:55:59] [51]\ttrain-rmse:0.39547\tvalid-rmse:0.48479\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.788 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:56:00] [118]\ttrain-rmse:0.27526\tvalid-rmse:0.45684\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.822 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.822 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.822 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.822 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:56:02] [52]\ttrain-rmse:0.39359\tvalid-rmse:0.48330\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:56:04] [119]\ttrain-rmse:0.27453\tvalid-rmse:0.45692\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:56:06] [120]\ttrain-rmse:0.27394\tvalid-rmse:0.45671\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.803 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.803 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.803 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.803 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:56:07] [53]\ttrain-rmse:0.39181\tvalid-rmse:0.48202\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:56:09] [121]\ttrain-rmse:0.27305\tvalid-rmse:0.45633\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.916 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.916 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.916 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.916 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:56:11] [54]\ttrain-rmse:0.39084\tvalid-rmse:0.48170\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:56:13] [122]\ttrain-rmse:0.27245\tvalid-rmse:0.45641\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:56:15] [55]\ttrain-rmse:0.38986\tvalid-rmse:0.48165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 23 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:56:16. Total running time: 1hr 7min 4s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_64b9ca23   RUNNING        0.135656                      9                3.37292               0.712911                 0.729026        0.303269          3.21418        121            5.63071       0.27394        0.456706 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5a5e2e10   RUNNING        0.125998                     11                0.0654222             0.785238                 0.692594        9.5092            8.98958         56            5.59723       0.389859       0.481652 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 18 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:56:16] [56]\ttrain-rmse:0.38901\tvalid-rmse:0.48147\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:56:18] [123]\ttrain-rmse:0.27168\tvalid-rmse:0.45623\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:56:20] [57]\ttrain-rmse:0.38823\tvalid-rmse:0.48117\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:56:22] [124]\ttrain-rmse:0.27105\tvalid-rmse:0.45617\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:56:23] [58]\ttrain-rmse:0.38749\tvalid-rmse:0.48087\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:56:25] [125]\ttrain-rmse:0.27040\tvalid-rmse:0.45612\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:56:27] [59]\ttrain-rmse:0.38687\tvalid-rmse:0.48056\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:56:29] [126]\ttrain-rmse:0.26978\tvalid-rmse:0.45626\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:56:30] [60]\ttrain-rmse:0.38601\tvalid-rmse:0.48026\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:56:32] [127]\ttrain-rmse:0.26921\tvalid-rmse:0.45651\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:56:34] [61]\ttrain-rmse:0.38522\tvalid-rmse:0.48007\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:56:36] [128]\ttrain-rmse:0.26861\tvalid-rmse:0.45653\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:56:38] [62]\ttrain-rmse:0.38443\tvalid-rmse:0.48009\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:56:39] [129]\ttrain-rmse:0.26784\tvalid-rmse:0.45656\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:56:41] [63]\ttrain-rmse:0.38265\tvalid-rmse:0.47865\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:56:43] [130]\ttrain-rmse:0.26747\tvalid-rmse:0.45655\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:56:45] [64]\ttrain-rmse:0.38096\tvalid-rmse:0.47743\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:56:46] [131]\ttrain-rmse:0.26657\tvalid-rmse:0.45652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 23 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:56:48. Total running time: 1hr 7min 36s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_64b9ca23   RUNNING        0.135656                      9                3.37292               0.712911                 0.729026        0.303269          3.21418        130            5.65484       0.26784        0.456562 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5a5e2e10   RUNNING        0.125998                     11                0.0654222             0.785238                 0.692594        9.5092            8.98958         65            5.62165       0.380961       0.477427 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 18 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:56:48] [65]\ttrain-rmse:0.37974\tvalid-rmse:0.47679\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:56:50] [132]\ttrain-rmse:0.26622\tvalid-rmse:0.45653\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:56:52] [66]\ttrain-rmse:0.37831\tvalid-rmse:0.47576\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:56:53] [133]\ttrain-rmse:0.26566\tvalid-rmse:0.45645\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:56:55] [67]\ttrain-rmse:0.37755\tvalid-rmse:0.47541\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.794 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.794 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:56:57] [134]\ttrain-rmse:0.26521\tvalid-rmse:0.45631\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:56:59] [68]\ttrain-rmse:0.37627\tvalid-rmse:0.47493\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:57:00] [135]\ttrain-rmse:0.26461\tvalid-rmse:0.45637\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.791 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:57:02] [69]\ttrain-rmse:0.37547\tvalid-rmse:0.47467\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:57:04] [136]\ttrain-rmse:0.26401\tvalid-rmse:0.45633\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:57:06] [70]\ttrain-rmse:0.37491\tvalid-rmse:0.47438\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:57:08] [137]\ttrain-rmse:0.26362\tvalid-rmse:0.45640\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:57:09] [138]\ttrain-rmse:0.26294\tvalid-rmse:0.45625\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:57:11] [71]\ttrain-rmse:0.37393\tvalid-rmse:0.47347\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:57:13] [139]\ttrain-rmse:0.26206\tvalid-rmse:0.45632\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:57:15] [72]\ttrain-rmse:0.37308\tvalid-rmse:0.47310\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:57:16] [140]\ttrain-rmse:0.26134\tvalid-rmse:0.45596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 23 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:57:18. Total running time: 1hr 8min 6s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_64b9ca23   RUNNING        0.135656                      9                3.37292               0.712911                 0.729026        0.303269          3.21418        139            5.6793        0.262937       0.456247 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5a5e2e10   RUNNING        0.125998                     11                0.0654222             0.785238                 0.692594        9.5092            8.98958         73            5.6431        0.373076       0.473101 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 18 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.745 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:57:18] [73]\ttrain-rmse:0.37200\tvalid-rmse:0.47277\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:57:20] [74]\ttrain-rmse:0.37132\tvalid-rmse:0.47246\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:57:22] [141]\ttrain-rmse:0.26067\tvalid-rmse:0.45587\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.792 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:57:23] [75]\ttrain-rmse:0.37024\tvalid-rmse:0.47153\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.745 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:57:25] [142]\ttrain-rmse:0.26014\tvalid-rmse:0.45588\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.773 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:57:27] [76]\ttrain-rmse:0.36912\tvalid-rmse:0.47074\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:57:29] [143]\ttrain-rmse:0.25973\tvalid-rmse:0.45587\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:57:30] [144]\ttrain-rmse:0.25893\tvalid-rmse:0.45587\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:57:32] [77]\ttrain-rmse:0.36836\tvalid-rmse:0.47067\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.784 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.939 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.940 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.940 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.940 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:57:34] [145]\ttrain-rmse:0.25821\tvalid-rmse:0.45592\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.804 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.804 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.804 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.804 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:57:36] [78]\ttrain-rmse:0.36788\tvalid-rmse:0.47057\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.787 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:57:38] [146]\ttrain-rmse:0.25790\tvalid-rmse:0.45590\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:57:40] [79]\ttrain-rmse:0.36743\tvalid-rmse:0.47031\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.793 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:57:41] [80]\ttrain-rmse:0.36683\tvalid-rmse:0.47021\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:57:43] [147]\ttrain-rmse:0.25736\tvalid-rmse:0.45595\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:57:45] [81]\ttrain-rmse:0.36610\tvalid-rmse:0.47001\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:57:47] [148]\ttrain-rmse:0.25679\tvalid-rmse:0.45586\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.782 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 23 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:57:48. Total running time: 1hr 8min 36s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_64b9ca23   RUNNING        0.135656                      9                3.37292               0.712911                 0.729026        0.303269          3.21418        147            5.70134       0.257899       0.455902 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5a5e2e10   RUNNING        0.125998                     11                0.0654222             0.785238                 0.692594        9.5092            8.98958         82            5.66779       0.366104       0.470006 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 18 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:57:48] [82]\ttrain-rmse:0.36513\tvalid-rmse:0.46910\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:57:50] [149]\ttrain-rmse:0.25639\tvalid-rmse:0.45576\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:57:52] [150]\ttrain-rmse:0.25567\tvalid-rmse:0.45559\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:57:54] [83]\ttrain-rmse:0.36452\tvalid-rmse:0.46892\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:57:55] [151]\ttrain-rmse:0.25521\tvalid-rmse:0.45564\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:57:57] [84]\ttrain-rmse:0.36408\tvalid-rmse:0.46888\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:57:59] [152]\ttrain-rmse:0.25471\tvalid-rmse:0.45549\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:58:01] [85]\ttrain-rmse:0.36321\tvalid-rmse:0.46862\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:58:02] [86]\ttrain-rmse:0.36269\tvalid-rmse:0.46850\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.773 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:58:04] [153]\ttrain-rmse:0.25429\tvalid-rmse:0.45542\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.742 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.776 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:58:06] [87]\ttrain-rmse:0.36202\tvalid-rmse:0.46853\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:58:08] [154]\ttrain-rmse:0.25382\tvalid-rmse:0.45543\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:58:10] [88]\ttrain-rmse:0.36130\tvalid-rmse:0.46797\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.742 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:58:11] [155]\ttrain-rmse:0.25320\tvalid-rmse:0.45537\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:58:13] [89]\ttrain-rmse:0.36074\tvalid-rmse:0.46759\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:58:15] [156]\ttrain-rmse:0.25263\tvalid-rmse:0.45550\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.730 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:58:16] [90]\ttrain-rmse:0.36031\tvalid-rmse:0.46743\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:58:18] [157]\ttrain-rmse:0.25196\tvalid-rmse:0.45561\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:58:20] [91]\ttrain-rmse:0.35973\tvalid-rmse:0.46740\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 23 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:58:20. Total running time: 1hr 9min 8s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_64b9ca23   RUNNING        0.135656                      9                3.37292               0.712911                 0.729026        0.303269          3.21418        156            5.72614       0.253197       0.45537  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5a5e2e10   RUNNING        0.125998                     11                0.0654222             0.785238                 0.692594        9.5092            8.98958         91            5.69228       0.360307       0.467431 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 18 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:58:22] [158]\ttrain-rmse:0.25166\tvalid-rmse:0.45575\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:58:24] [92]\ttrain-rmse:0.35933\tvalid-rmse:0.46750\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.731 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:58:25] [159]\ttrain-rmse:0.25113\tvalid-rmse:0.45586\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:58:27] [93]\ttrain-rmse:0.35896\tvalid-rmse:0.46737\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:58:29] [160]\ttrain-rmse:0.25065\tvalid-rmse:0.45585\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:58:31] [94]\ttrain-rmse:0.35845\tvalid-rmse:0.46722\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:58:32] [161]\ttrain-rmse:0.25013\tvalid-rmse:0.45599\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:58:34] [95]\ttrain-rmse:0.35794\tvalid-rmse:0.46722\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:58:36] [162]\ttrain-rmse:0.24985\tvalid-rmse:0.45601\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:58:38] [96]\ttrain-rmse:0.35740\tvalid-rmse:0.46701\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.790 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.745 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:58:39] [163]\ttrain-rmse:0.24919\tvalid-rmse:0.45600\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:58:41] [97]\ttrain-rmse:0.35691\tvalid-rmse:0.46714\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:58:43] [164]\ttrain-rmse:0.24879\tvalid-rmse:0.45596\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:58:45] [165]\ttrain-rmse:0.24832\tvalid-rmse:0.45604\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:58:46] [98]\ttrain-rmse:0.35639\tvalid-rmse:0.46722\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:58:48] [166]\ttrain-rmse:0.24784\tvalid-rmse:0.45601\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.733 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:58:50] [99]\ttrain-rmse:0.35580\tvalid-rmse:0.46673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 23 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:58:52. Total running time: 1hr 9min 39s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_64b9ca23   RUNNING        0.135656                      9                3.37292               0.712911                 0.729026        0.303269          3.21418        166            5.75413       0.24832        0.456043 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5a5e2e10   RUNNING        0.125998                     11                0.0654222             0.785238                 0.692594        9.5092            8.98958         99            5.71411       0.356392       0.467217 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 18 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:58:52] [167]\ttrain-rmse:0.24737\tvalid-rmse:0.45581\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:58:53] [100]\ttrain-rmse:0.35502\tvalid-rmse:0.46618\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:58:55] [101]\ttrain-rmse:0.35457\tvalid-rmse:0.46613\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.922 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.923 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.923 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.923 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:58:57] [168]\ttrain-rmse:0.24691\tvalid-rmse:0.45594\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:58:59] [102]\ttrain-rmse:0.35416\tvalid-rmse:0.46604\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:59:01] [169]\ttrain-rmse:0.24650\tvalid-rmse:0.45590\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.745 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:59:02] [103]\ttrain-rmse:0.35364\tvalid-rmse:0.46577\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:59:04] [170]\ttrain-rmse:0.24599\tvalid-rmse:0.45573\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:59:06] [171]\ttrain-rmse:0.24552\tvalid-rmse:0.45565\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:59:08] [104]\ttrain-rmse:0.35325\tvalid-rmse:0.46568\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:59:09] [172]\ttrain-rmse:0.24510\tvalid-rmse:0.45566\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:59:11] [105]\ttrain-rmse:0.35282\tvalid-rmse:0.46566\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:59:13] [173]\ttrain-rmse:0.24455\tvalid-rmse:0.45572\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:59:15] [106]\ttrain-rmse:0.35205\tvalid-rmse:0.46513\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:59:16] [174]\ttrain-rmse:0.24398\tvalid-rmse:0.45570\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:59:18] [107]\ttrain-rmse:0.35157\tvalid-rmse:0.46519\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:59:20] [175]\ttrain-rmse:0.24355\tvalid-rmse:0.45576\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 23 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:59:22. Total running time: 1hr 10min 10s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_64b9ca23   RUNNING        0.135656                      9                3.37292               0.712911                 0.729026        0.303269          3.21418        174            5.7762        0.244552       0.455717 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5a5e2e10   RUNNING        0.125998                     11                0.0654222             0.785238                 0.692594        9.5092            8.98958        108            5.73954       0.351574       0.465189 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 18 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:59:22] [108]\ttrain-rmse:0.35090\tvalid-rmse:0.46492\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:59:23] [176]\ttrain-rmse:0.24307\tvalid-rmse:0.45586\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:59:25] [109]\ttrain-rmse:0.35042\tvalid-rmse:0.46475\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.734 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:59:27] [177]\ttrain-rmse:0.24283\tvalid-rmse:0.45586\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:59:29] [110]\ttrain-rmse:0.35015\tvalid-rmse:0.46476\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:59:30] [178]\ttrain-rmse:0.24253\tvalid-rmse:0.45568\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:59:32] [111]\ttrain-rmse:0.34963\tvalid-rmse:0.46452\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.742 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:59:34] [179]\ttrain-rmse:0.24195\tvalid-rmse:0.45547\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:59:36] [112]\ttrain-rmse:0.34922\tvalid-rmse:0.46463\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:59:37] [113]\ttrain-rmse:0.34883\tvalid-rmse:0.46460\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:59:39] [180]\ttrain-rmse:0.24131\tvalid-rmse:0.45528\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.736 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:59:41] [114]\ttrain-rmse:0.34828\tvalid-rmse:0.46420\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:59:43] [181]\ttrain-rmse:0.24078\tvalid-rmse:0.45538\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:59:44] [115]\ttrain-rmse:0.34776\tvalid-rmse:0.46418\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.739 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:59:46] [182]\ttrain-rmse:0.24034\tvalid-rmse:0.45522\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:59:48] [183]\ttrain-rmse:0.23993\tvalid-rmse:0.45512\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:59:50] [116]\ttrain-rmse:0.34725\tvalid-rmse:0.46397\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:59:51] [184]\ttrain-rmse:0.23953\tvalid-rmse:0.45509\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 23 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 12:59:53. Total running time: 1hr 10min 41s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_64b9ca23   RUNNING        0.135656                      9                3.37292               0.712911                 0.729026        0.303269          3.21418        183            5.80104       0.240339       0.455225 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5a5e2e10   RUNNING        0.125998                     11                0.0654222             0.785238                 0.692594        9.5092            8.98958        117            5.76507       0.347248       0.463972 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 18 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:59:53] [117]\ttrain-rmse:0.34689\tvalid-rmse:0.46402\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:59:55] [185]\ttrain-rmse:0.23924\tvalid-rmse:0.45503\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.784 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [12:59:57] [118]\ttrain-rmse:0.34627\tvalid-rmse:0.46355\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [12:59:59] [186]\ttrain-rmse:0.23877\tvalid-rmse:0.45473\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:00:00] [119]\ttrain-rmse:0.34569\tvalid-rmse:0.46323\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:00:02] [187]\ttrain-rmse:0.23836\tvalid-rmse:0.45472\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.830 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.831 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.831 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.831 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:00:04] [120]\ttrain-rmse:0.34526\tvalid-rmse:0.46305\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:00:06] [188]\ttrain-rmse:0.23782\tvalid-rmse:0.45485\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.773 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:00:07] [121]\ttrain-rmse:0.34464\tvalid-rmse:0.46281\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:00:09] [122]\ttrain-rmse:0.34415\tvalid-rmse:0.46280\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:00:11] [189]\ttrain-rmse:0.23750\tvalid-rmse:0.45488\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:00:13] [123]\ttrain-rmse:0.34370\tvalid-rmse:0.46246\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:00:14] [190]\ttrain-rmse:0.23712\tvalid-rmse:0.45497\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:00:16] [124]\ttrain-rmse:0.34318\tvalid-rmse:0.46241\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:00:18] [191]\ttrain-rmse:0.23666\tvalid-rmse:0.45507\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.938 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.939 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.939 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.939 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:00:20] [125]\ttrain-rmse:0.34281\tvalid-rmse:0.46219\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.773 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:00:22] [192]\ttrain-rmse:0.23627\tvalid-rmse:0.45493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 23 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:00:23. Total running time: 1hr 11min 11s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_64b9ca23   RUNNING        0.135656                      9                3.37292               0.712911                 0.729026        0.303269          3.21418        191            5.82276       0.237118       0.454972 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5a5e2e10   RUNNING        0.125998                     11                0.0654222             0.785238                 0.692594        9.5092            8.98958        126            5.79019       0.342807       0.462193 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 18 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:00:23] [126]\ttrain-rmse:0.34235\tvalid-rmse:0.46226\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:00:25] [193]\ttrain-rmse:0.23585\tvalid-rmse:0.45494\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:00:27] [127]\ttrain-rmse:0.34200\tvalid-rmse:0.46217\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:00:29] [194]\ttrain-rmse:0.23560\tvalid-rmse:0.45500\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:00:30] [128]\ttrain-rmse:0.34171\tvalid-rmse:0.46218\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:00:32] [195]\ttrain-rmse:0.23517\tvalid-rmse:0.45510\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:00:34] [129]\ttrain-rmse:0.34125\tvalid-rmse:0.46195\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:00:36] [196]\ttrain-rmse:0.23480\tvalid-rmse:0.45509\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:00:38] [130]\ttrain-rmse:0.34103\tvalid-rmse:0.46197\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:00:39] [197]\ttrain-rmse:0.23435\tvalid-rmse:0.45490\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:00:41] [198]\ttrain-rmse:0.23397\tvalid-rmse:0.45483\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:00:43] [131]\ttrain-rmse:0.34048\tvalid-rmse:0.46152\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:00:45] [199]\ttrain-rmse:0.23346\tvalid-rmse:0.45481\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:00:46] [132]\ttrain-rmse:0.34018\tvalid-rmse:0.46152\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:00:48] [200]\ttrain-rmse:0.23311\tvalid-rmse:0.45484\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:00:50] [133]\ttrain-rmse:0.33982\tvalid-rmse:0.46153\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:00:52] [134]\ttrain-rmse:0.33932\tvalid-rmse:0.46116\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:00:53] [201]\ttrain-rmse:0.23260\tvalid-rmse:0.45484\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:00:55] [135]\ttrain-rmse:0.33906\tvalid-rmse:0.46107\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.777 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 23 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:00:55. Total running time: 1hr 11min 43s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_64b9ca23   RUNNING        0.135656                      9                3.37292               0.712911                 0.729026        0.303269          3.21418        200            5.84789       0.233465       0.45481  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5a5e2e10   RUNNING        0.125998                     11                0.0654222             0.785238                 0.692594        9.5092            8.98958        135            5.81527       0.339317       0.461161 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 18 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:00:57] [202]\ttrain-rmse:0.23236\tvalid-rmse:0.45474\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.796 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.797 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:00:59] [136]\ttrain-rmse:0.33874\tvalid-rmse:0.46102\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:01:00] [203]\ttrain-rmse:0.23215\tvalid-rmse:0.45478\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.791 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:01:02] [137]\ttrain-rmse:0.33845\tvalid-rmse:0.46095\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:01:04] [204]\ttrain-rmse:0.23177\tvalid-rmse:0.45481\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:01:06] [138]\ttrain-rmse:0.33806\tvalid-rmse:0.46062\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.780 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:01:08] [205]\ttrain-rmse:0.23145\tvalid-rmse:0.45482\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:01:09] [139]\ttrain-rmse:0.33772\tvalid-rmse:0.46065\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:01:11] [206]\ttrain-rmse:0.23102\tvalid-rmse:0.45487\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:01:13] [207]\ttrain-rmse:0.23062\tvalid-rmse:0.45497\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:01:15] [140]\ttrain-rmse:0.33723\tvalid-rmse:0.46041\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:01:16] [208]\ttrain-rmse:0.23036\tvalid-rmse:0.45483\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:01:18] [141]\ttrain-rmse:0.33680\tvalid-rmse:0.46026\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:01:20] [209]\ttrain-rmse:0.22998\tvalid-rmse:0.45497\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:01:22] [142]\ttrain-rmse:0.33651\tvalid-rmse:0.46029\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:01:23] [210]\ttrain-rmse:0.22953\tvalid-rmse:0.45511\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:01:25] [143]\ttrain-rmse:0.33612\tvalid-rmse:0.46036\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:01:27] [211]\ttrain-rmse:0.22917\tvalid-rmse:0.45505\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 23 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:01:27. Total running time: 1hr 12min 15s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_64b9ca23   RUNNING        0.135656                      9                3.37292               0.712911                 0.729026        0.303269          3.21418        210            5.87509       0.229979       0.45497  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5a5e2e10   RUNNING        0.125998                     11                0.0654222             0.785238                 0.692594        9.5092            8.98958        143            5.83704       0.336508       0.460295 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 18 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:01:29] [144]\ttrain-rmse:0.33591\tvalid-rmse:0.46031\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:01:30] [212]\ttrain-rmse:0.22876\tvalid-rmse:0.45515\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.787 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:01:32] [145]\ttrain-rmse:0.33542\tvalid-rmse:0.46021\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:01:34] [146]\ttrain-rmse:0.33516\tvalid-rmse:0.46027\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:01:36] [213]\ttrain-rmse:0.22848\tvalid-rmse:0.45524\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.776 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:01:37] [147]\ttrain-rmse:0.33487\tvalid-rmse:0.46027\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:01:39] [214]\ttrain-rmse:0.22815\tvalid-rmse:0.45526\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:01:41] [148]\ttrain-rmse:0.33454\tvalid-rmse:0.46026\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:01:43] [215]\ttrain-rmse:0.22773\tvalid-rmse:0.45519\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.938 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.938 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.938 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.938 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:01:45] [216]\ttrain-rmse:0.22730\tvalid-rmse:0.45512\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:01:46] [149]\ttrain-rmse:0.33410\tvalid-rmse:0.46026\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:01:48] [217]\ttrain-rmse:0.22691\tvalid-rmse:0.45516\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:01:50] [150]\ttrain-rmse:0.33365\tvalid-rmse:0.46008\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:01:52] [218]\ttrain-rmse:0.22661\tvalid-rmse:0.45498\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:01:53] [151]\ttrain-rmse:0.33333\tvalid-rmse:0.46005\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:01:55] [219]\ttrain-rmse:0.22623\tvalid-rmse:0.45472\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:01:57] [152]\ttrain-rmse:0.33305\tvalid-rmse:0.46000\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.782 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 23 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:01:57. Total running time: 1hr 12min 45s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_64b9ca23   RUNNING        0.135656                      9                3.37292               0.712911                 0.729026        0.303269          3.21418        218            5.89688       0.226905       0.455163 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5a5e2e10   RUNNING        0.125998                     11                0.0654222             0.785238                 0.692594        9.5092            8.98958        152            5.86276       0.333331       0.460051 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 18 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:01:59] [220]\ttrain-rmse:0.22592\tvalid-rmse:0.45475\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:02:01] [153]\ttrain-rmse:0.33276\tvalid-rmse:0.45987\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:02:02] [221]\ttrain-rmse:0.22563\tvalid-rmse:0.45464\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.790 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:02:04] [154]\ttrain-rmse:0.33248\tvalid-rmse:0.45981\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:02:06] [222]\ttrain-rmse:0.22522\tvalid-rmse:0.45462\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:02:08] [155]\ttrain-rmse:0.33223\tvalid-rmse:0.45982\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:02:09] [223]\ttrain-rmse:0.22476\tvalid-rmse:0.45441\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:02:11] [156]\ttrain-rmse:0.33200\tvalid-rmse:0.45988\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:02:13] [224]\ttrain-rmse:0.22433\tvalid-rmse:0.45420\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:02:15] [157]\ttrain-rmse:0.33159\tvalid-rmse:0.45980\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:02:16] [225]\ttrain-rmse:0.22395\tvalid-rmse:0.45422\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.742 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:02:18] [158]\ttrain-rmse:0.33122\tvalid-rmse:0.45976\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:02:20] [226]\ttrain-rmse:0.22367\tvalid-rmse:0.45440\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.789 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:02:22] [159]\ttrain-rmse:0.33094\tvalid-rmse:0.45979\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:02:23] [227]\ttrain-rmse:0.22334\tvalid-rmse:0.45443\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:02:25] [160]\ttrain-rmse:0.33069\tvalid-rmse:0.45970\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:02:27] [228]\ttrain-rmse:0.22308\tvalid-rmse:0.45439\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 23 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:02:29. Total running time: 1hr 13min 17s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_64b9ca23   RUNNING        0.135656                      9                3.37292               0.712911                 0.729026        0.303269          3.21418        227            5.9211        0.223674       0.454398 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5a5e2e10   RUNNING        0.125998                     11                0.0654222             0.785238                 0.692594        9.5092            8.98958        161            5.88793       0.330688       0.4597   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 18 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:02:29] [161]\ttrain-rmse:0.33048\tvalid-rmse:0.45966\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:02:30] [229]\ttrain-rmse:0.22271\tvalid-rmse:0.45427\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:02:32] [162]\ttrain-rmse:0.33020\tvalid-rmse:0.45978\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:02:34] [230]\ttrain-rmse:0.22243\tvalid-rmse:0.45424\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:02:36] [163]\ttrain-rmse:0.32999\tvalid-rmse:0.45978\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:02:38] [164]\ttrain-rmse:0.32972\tvalid-rmse:0.45977\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:02:39] [231]\ttrain-rmse:0.22208\tvalid-rmse:0.45429\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:02:41] [165]\ttrain-rmse:0.32944\tvalid-rmse:0.45966\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.731 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:02:43] [232]\ttrain-rmse:0.22176\tvalid-rmse:0.45418\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:02:45] [166]\ttrain-rmse:0.32897\tvalid-rmse:0.45934\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:02:46] [233]\ttrain-rmse:0.22139\tvalid-rmse:0.45433\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:02:48] [167]\ttrain-rmse:0.32873\tvalid-rmse:0.45922\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.723 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:02:50] [234]\ttrain-rmse:0.22111\tvalid-rmse:0.45437\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:02:52] [168]\ttrain-rmse:0.32843\tvalid-rmse:0.45922\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:02:53] [235]\ttrain-rmse:0.22086\tvalid-rmse:0.45438\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:02:55] [169]\ttrain-rmse:0.32798\tvalid-rmse:0.45906\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:02:57] [236]\ttrain-rmse:0.22041\tvalid-rmse:0.45442\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:02:59] [170]\ttrain-rmse:0.32758\tvalid-rmse:0.45891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 23 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:03:00. Total running time: 1hr 13min 48s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_64b9ca23   RUNNING        0.135656                      9                3.37292               0.712911                 0.729026        0.303269          3.21418        236            5.94604       0.22086        0.454378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5a5e2e10   RUNNING        0.125998                     11                0.0654222             0.785238                 0.692594        9.5092            8.98958        170            5.91372       0.327984       0.459065 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 18 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:03:00] [237]\ttrain-rmse:0.22016\tvalid-rmse:0.45450\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.790 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:03:02] [171]\ttrain-rmse:0.32732\tvalid-rmse:0.45892\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:03:04] [238]\ttrain-rmse:0.21983\tvalid-rmse:0.45437\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:03:06] [172]\ttrain-rmse:0.32705\tvalid-rmse:0.45894\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.895 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.896 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.896 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.896 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:03:07] [239]\ttrain-rmse:0.21950\tvalid-rmse:0.45433\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:03:09] [240]\ttrain-rmse:0.21914\tvalid-rmse:0.45431\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:03:11] [173]\ttrain-rmse:0.32682\tvalid-rmse:0.45900\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:03:13] [241]\ttrain-rmse:0.21875\tvalid-rmse:0.45432\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:03:14] [174]\ttrain-rmse:0.32651\tvalid-rmse:0.45886\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:03:16] [242]\ttrain-rmse:0.21854\tvalid-rmse:0.45425\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:03:18] [175]\ttrain-rmse:0.32622\tvalid-rmse:0.45891\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:03:20] [176]\ttrain-rmse:0.32594\tvalid-rmse:0.45894\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:03:22] [243]\ttrain-rmse:0.21830\tvalid-rmse:0.45431\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:03:23] [177]\ttrain-rmse:0.32554\tvalid-rmse:0.45896\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.732 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:03:25] [244]\ttrain-rmse:0.21798\tvalid-rmse:0.45423\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:03:27] [178]\ttrain-rmse:0.32528\tvalid-rmse:0.45888\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.739 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:03:29] [245]\ttrain-rmse:0.21765\tvalid-rmse:0.45435\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:03:30] [179]\ttrain-rmse:0.32508\tvalid-rmse:0.45870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 23 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:03:32. Total running time: 1hr 14min 20s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_64b9ca23   RUNNING        0.135656                      9                3.37292               0.712911                 0.729026        0.303269          3.21418        245            5.97098       0.217976       0.454234 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5a5e2e10   RUNNING        0.125998                     11                0.0654222             0.785238                 0.692594        9.5092            8.98958        179            5.93872       0.32528        0.458877 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 18 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.792 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:03:32] [246]\ttrain-rmse:0.21754\tvalid-rmse:0.45432\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:03:34] [180]\ttrain-rmse:0.32478\tvalid-rmse:0.45859\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:03:36] [247]\ttrain-rmse:0.21726\tvalid-rmse:0.45437\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.805 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.805 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.805 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.805 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:03:37] [181]\ttrain-rmse:0.32441\tvalid-rmse:0.45853\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.782 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:03:39] [248]\ttrain-rmse:0.21706\tvalid-rmse:0.45443\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:03:41] [249]\ttrain-rmse:0.21685\tvalid-rmse:0.45441\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:03:43] [182]\ttrain-rmse:0.32405\tvalid-rmse:0.45826\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.782 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:03:45] [250]\ttrain-rmse:0.21666\tvalid-rmse:0.45440\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:03:46] [183]\ttrain-rmse:0.32374\tvalid-rmse:0.45815\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.773 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:03:48] [251]\ttrain-rmse:0.21633\tvalid-rmse:0.45422\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.785 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:03:50] [184]\ttrain-rmse:0.32348\tvalid-rmse:0.45798\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:03:52] [185]\ttrain-rmse:0.32321\tvalid-rmse:0.45796\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:03:53] [252]\ttrain-rmse:0.21586\tvalid-rmse:0.45414\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:03:55] [186]\ttrain-rmse:0.32274\tvalid-rmse:0.45763\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.785 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:03:57] [253]\ttrain-rmse:0.21561\tvalid-rmse:0.45417\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:03:59] [187]\ttrain-rmse:0.32239\tvalid-rmse:0.45763\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:04:00] [254]\ttrain-rmse:0.21535\tvalid-rmse:0.45421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 23 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:04:02. Total running time: 1hr 14min 50s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_64b9ca23   RUNNING        0.135656                      9                3.37292               0.712911                 0.729026        0.303269          3.21418        253            5.99269       0.215857       0.454142 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5a5e2e10   RUNNING        0.125998                     11                0.0654222             0.785238                 0.692594        9.5092            8.98958        188            5.96392       0.32239        0.45763  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 18 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:04:02] [188]\ttrain-rmse:0.32207\tvalid-rmse:0.45763\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.807 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.808 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.808 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.808 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:04:04] [255]\ttrain-rmse:0.21496\tvalid-rmse:0.45425\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:04:06] [189]\ttrain-rmse:0.32172\tvalid-rmse:0.45766\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:04:07] [256]\ttrain-rmse:0.21476\tvalid-rmse:0.45417\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:04:09] [190]\ttrain-rmse:0.32149\tvalid-rmse:0.45757\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:04:11] [257]\ttrain-rmse:0.21442\tvalid-rmse:0.45399\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:04:13] [258]\ttrain-rmse:0.21415\tvalid-rmse:0.45406\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.745 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:04:14] [191]\ttrain-rmse:0.32125\tvalid-rmse:0.45755\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:04:16] [259]\ttrain-rmse:0.21385\tvalid-rmse:0.45413\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.771 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:04:18] [192]\ttrain-rmse:0.32103\tvalid-rmse:0.45757\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:04:20] [260]\ttrain-rmse:0.21367\tvalid-rmse:0.45405\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:04:22] [193]\ttrain-rmse:0.32077\tvalid-rmse:0.45742\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:04:23] [194]\ttrain-rmse:0.32056\tvalid-rmse:0.45745\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:04:25] [261]\ttrain-rmse:0.21341\tvalid-rmse:0.45409\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:04:27] [195]\ttrain-rmse:0.32032\tvalid-rmse:0.45762\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:04:29] [262]\ttrain-rmse:0.21307\tvalid-rmse:0.45415\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.771 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:04:30] [196]\ttrain-rmse:0.32012\tvalid-rmse:0.45756\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:04:32] [263]\ttrain-rmse:0.21275\tvalid-rmse:0.45416\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.939 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.940 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.940 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.940 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 23 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:04:32. Total running time: 1hr 15min 20s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_64b9ca23   RUNNING        0.135656                      9                3.37292               0.712911                 0.729026        0.303269          3.21418        262            6.0171        0.213411       0.45409  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5a5e2e10   RUNNING        0.125998                     11                0.0654222             0.785238                 0.692594        9.5092            8.98958        196            5.98588       0.320321       0.457619 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 18 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:04:34] [197]\ttrain-rmse:0.31978\tvalid-rmse:0.45742\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.737 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:04:36] [264]\ttrain-rmse:0.21252\tvalid-rmse:0.45411\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:04:37] [198]\ttrain-rmse:0.31957\tvalid-rmse:0.45722\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:04:39] [265]\ttrain-rmse:0.21215\tvalid-rmse:0.45420\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.735 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:04:41] [199]\ttrain-rmse:0.31938\tvalid-rmse:0.45715\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:04:43] [266]\ttrain-rmse:0.21194\tvalid-rmse:0.45417\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:04:44] [267]\ttrain-rmse:0.21169\tvalid-rmse:0.45419\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.739 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:04:46] [200]\ttrain-rmse:0.31919\tvalid-rmse:0.45715\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:04:48] [268]\ttrain-rmse:0.21142\tvalid-rmse:0.45425\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.745 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:04:50] [201]\ttrain-rmse:0.31898\tvalid-rmse:0.45724\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:04:51] [269]\ttrain-rmse:0.21115\tvalid-rmse:0.45428\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:04:53] [202]\ttrain-rmse:0.31868\tvalid-rmse:0.45715\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:04:55] [270]\ttrain-rmse:0.21093\tvalid-rmse:0.45434\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:04:57] [203]\ttrain-rmse:0.31845\tvalid-rmse:0.45706\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:04:59] [271]\ttrain-rmse:0.21059\tvalid-rmse:0.45437\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:05:00] [204]\ttrain-rmse:0.31828\tvalid-rmse:0.45701\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.807 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.808 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.808 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.808 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:05:02] [272]\ttrain-rmse:0.21038\tvalid-rmse:0.45437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 23 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:05:04. Total running time: 1hr 15min 52s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_64b9ca23   RUNNING        0.135656                      9                3.37292               0.712911                 0.729026        0.303269          3.21418        271            6.04083       0.210926       0.454341 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5a5e2e10   RUNNING        0.125998                     11                0.0654222             0.785238                 0.692594        9.5092            8.98958        205            6.01167       0.318277       0.457007 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 18 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:05:04] [205]\ttrain-rmse:0.31798\tvalid-rmse:0.45702\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:05:06] [206]\ttrain-rmse:0.31779\tvalid-rmse:0.45701\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:05:07] [273]\ttrain-rmse:0.21017\tvalid-rmse:0.45449\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:05:09] [207]\ttrain-rmse:0.31758\tvalid-rmse:0.45699\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:05:11] [274]\ttrain-rmse:0.20993\tvalid-rmse:0.45458\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:05:13] [208]\ttrain-rmse:0.31733\tvalid-rmse:0.45690\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:05:14] [275]\ttrain-rmse:0.20963\tvalid-rmse:0.45454\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.771 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:05:16] [209]\ttrain-rmse:0.31704\tvalid-rmse:0.45696\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.784 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:05:18] [276]\ttrain-rmse:0.20933\tvalid-rmse:0.45445\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:05:20] [210]\ttrain-rmse:0.31688\tvalid-rmse:0.45703\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:05:22] [277]\ttrain-rmse:0.20909\tvalid-rmse:0.45444\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.790 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:05:23] [211]\ttrain-rmse:0.31668\tvalid-rmse:0.45694\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:05:25] [278]\ttrain-rmse:0.20873\tvalid-rmse:0.45438\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.777 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:05:27] [212]\ttrain-rmse:0.31657\tvalid-rmse:0.45695\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:05:29] [279]\ttrain-rmse:0.20843\tvalid-rmse:0.45419\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:05:30] [213]\ttrain-rmse:0.31634\tvalid-rmse:0.45701\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:05:32] [280]\ttrain-rmse:0.20810\tvalid-rmse:0.45424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 23 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:05:34. Total running time: 1hr 16min 22s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_64b9ca23   RUNNING        0.135656                      9                3.37292               0.712911                 0.729026        0.303269          3.21418        279            6.06297       0.208735       0.454381 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5a5e2e10   RUNNING        0.125998                     11                0.0654222             0.785238                 0.692594        9.5092            8.98958        214            6.03677       0.316339       0.457014 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 18 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:05:34] [214]\ttrain-rmse:0.31614\tvalid-rmse:0.45699\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.793 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.793 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:05:36] [281]\ttrain-rmse:0.20788\tvalid-rmse:0.45429\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:05:38] [215]\ttrain-rmse:0.31596\tvalid-rmse:0.45699\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.808 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.808 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.808 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.808 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:05:39] [282]\ttrain-rmse:0.20765\tvalid-rmse:0.45426\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.773 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:05:41] [216]\ttrain-rmse:0.31582\tvalid-rmse:0.45693\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:05:43] [283]\ttrain-rmse:0.20745\tvalid-rmse:0.45430\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.780 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.788 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:05:45] [217]\ttrain-rmse:0.31543\tvalid-rmse:0.45693\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:05:46] [284]\ttrain-rmse:0.20725\tvalid-rmse:0.45436\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.819 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.819 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.819 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.819 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:05:48] [218]\ttrain-rmse:0.31512\tvalid-rmse:0.45675\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:05:50] [285]\ttrain-rmse:0.20696\tvalid-rmse:0.45430\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:05:52] [219]\ttrain-rmse:0.31484\tvalid-rmse:0.45654\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.789 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:05:54] [286]\ttrain-rmse:0.20668\tvalid-rmse:0.45434\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.948 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.949 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.949 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.949 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:05:56] [220]\ttrain-rmse:0.31467\tvalid-rmse:0.45651\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:05:57] [287]\ttrain-rmse:0.20645\tvalid-rmse:0.45443\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:05:59] [221]\ttrain-rmse:0.31444\tvalid-rmse:0.45640\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:06:01] [288]\ttrain-rmse:0.20621\tvalid-rmse:0.45443\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:06:03] [222]\ttrain-rmse:0.31422\tvalid-rmse:0.45636\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.799 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.800 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.800 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.800 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 23 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:06:04. Total running time: 1hr 16min 52s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_64b9ca23   RUNNING        0.135656                      9                3.37292               0.712911                 0.729026        0.303269          3.21418        288            6.08771       0.206449       0.454429 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5a5e2e10   RUNNING        0.125998                     11                0.0654222             0.785238                 0.692594        9.5092            8.98958        222            6.05837       0.314438       0.456405 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 18 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:06:04] [289]\ttrain-rmse:0.20591\tvalid-rmse:0.45449\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:06:06] [223]\ttrain-rmse:0.31399\tvalid-rmse:0.45621\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.784 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:06:08] [290]\ttrain-rmse:0.20565\tvalid-rmse:0.45449\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.808 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.808 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.808 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.808 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.792 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:06:10] [291]\ttrain-rmse:0.20548\tvalid-rmse:0.45456\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:06:12] [224]\ttrain-rmse:0.31376\tvalid-rmse:0.45618\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.790 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:06:13] [292]\ttrain-rmse:0.20523\tvalid-rmse:0.45461\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.787 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:06:15] [225]\ttrain-rmse:0.31355\tvalid-rmse:0.45618\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.790 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.790 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:06:17] [293]\ttrain-rmse:0.20501\tvalid-rmse:0.45449\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:06:19] [226]\ttrain-rmse:0.31333\tvalid-rmse:0.45617\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:06:20] [294]\ttrain-rmse:0.20474\tvalid-rmse:0.45453\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:06:22] [227]\ttrain-rmse:0.31305\tvalid-rmse:0.45625\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:06:24] [295]\ttrain-rmse:0.20445\tvalid-rmse:0.45452\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:06:26] [228]\ttrain-rmse:0.31280\tvalid-rmse:0.45619\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:06:28] [296]\ttrain-rmse:0.20420\tvalid-rmse:0.45456\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:06:29] [229]\ttrain-rmse:0.31264\tvalid-rmse:0.45617\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:06:31] [297]\ttrain-rmse:0.20388\tvalid-rmse:0.45455\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.780 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:06:33] [230]\ttrain-rmse:0.31241\tvalid-rmse:0.45628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 23 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:06:35. Total running time: 1hr 17min 22s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_64b9ca23   RUNNING        0.135656                      9                3.37292               0.712911                 0.729026        0.303269          3.21418        297            6.11223       0.204199       0.454561 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5a5e2e10   RUNNING        0.125998                     11                0.0654222             0.785238                 0.692594        9.5092            8.98958        230            6.08119       0.312637       0.456172 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 18 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:06:35] [298]\ttrain-rmse:0.20364\tvalid-rmse:0.45460\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:06:36] [231]\ttrain-rmse:0.31217\tvalid-rmse:0.45610\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3860, ip=100.64.8.234)\u001b[0m [13:06:38] [299]\ttrain-rmse:0.20339\tvalid-rmse:0.45469\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:06:40] [232]\ttrain-rmse:0.31184\tvalid-rmse:0.45611\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:06:42] [233]\ttrain-rmse:0.31156\tvalid-rmse:0.45610\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.745 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.774 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:06:45] [234]\ttrain-rmse:0.31126\tvalid-rmse:0.45602\n",
      "\u001b[36m(RayTrainWorker pid=3906, ip=100.64.8.234)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=s3, path=ddl-wadkars/end-to-end/california/air/xgb/xgb_from_s3_irsa/XGBoostTrainer_64b9ca23_24_alpha=3.2142,colsample_bytree=0.7290,eta=0.1357,eval_metric=rmse,lambda=0.3033,max_depth=9,min_child_we_2025-09-01_12-49-10/checkpoint_000000)\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🏃 View run XGBoostTrainer_64b9ca23 at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265/runs/91729f36874f4c43830d8fc8bc4ea155\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🧪 View experiment at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_64b9ca23 completed after 300 iterations at 2025-09-01 13:06:47. Total running time: 1hr 17min 35s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_64b9ca23 result             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ checkpoint_dir_name                              │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_this_iter_s                         0.00262 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_total_s                             6.12046 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ training_iteration                           300 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ train-rmse                               0.20339 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ valid-rmse                               0.45469 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:06:49] [235]\ttrain-rmse:0.31104\tvalid-rmse:0.45607\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:06:51] [236]\ttrain-rmse:0.31092\tvalid-rmse:0.45615\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_19391f24 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_19391f24 config                         │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/alpha                              0.7755526189704338 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/colsample_bytree                   0.6246171333419434 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eta                               0.14706460632678364 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eval_metric                                      rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/lambda                            0.00883145812920971 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/max_depth                                          10 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/min_child_weight                   2.4480325216792984 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/nthread                                             1 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/objective                            reg:squarederror │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/subsample                          0.7178559732321299 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/tree_method                                      hist │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=4827) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=4828) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=4829) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m - (node_id=04d1f20c86f90400fe1f34aba9689cada08035519c1179e74c4293e9, ip=100.64.27.77, pid=4830) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:06:54] [237]\ttrain-rmse:0.31079\tvalid-rmse:0.45618\n",
      "\u001b[36m(RayTrainWorker pid=4828, ip=100.64.27.77)\u001b[0m [13:06:54] Task [xgboost.ray-rank=00000001]:b99fb985b8d727af7946b27804000000 got rank 1\n",
      "\u001b[36m(RayTrainWorker pid=4829, ip=100.64.27.77)\u001b[0m [13:06:54] Task [xgboost.ray-rank=00000002]:bfb9b4577666c0f88c70939704000000 got rank 2\n",
      "\u001b[36m(RayTrainWorker pid=4827, ip=100.64.27.77)\u001b[0m [13:06:54] Task [xgboost.ray-rank=00000000]:e84880ea05d48f98e0c3551004000000 got rank 0\n",
      "\u001b[36m(RayTrainWorker pid=4830, ip=100.64.27.77)\u001b[0m [13:06:54] Task [xgboost.ray-rank=00000003]:b49f68cd1ea2eadbb5c6b0e004000000 got rank 3\n",
      "\u001b[36m(SplitCoordinator pid=4991, ip=100.64.27.77)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=4991, ip=100.64.27.77)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:06:56] [238]\ttrain-rmse:0.31061\tvalid-rmse:0.45612\n",
      "\u001b[36m(SplitCoordinator pid=4992, ip=100.64.27.77)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=4992, ip=100.64.27.77)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:06:58] [239]\ttrain-rmse:0.31030\tvalid-rmse:0.45608\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:06:58] [0]\ttrain-rmse:1.04204\tvalid-rmse:1.04051\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:06:59] [240]\ttrain-rmse:0.31009\tvalid-rmse:0.45606\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:07:01] [1]\ttrain-rmse:0.96391\tvalid-rmse:0.97650\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.742 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:07:03] [241]\ttrain-rmse:0.30993\tvalid-rmse:0.45598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 24 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:07:05. Total running time: 1hr 17min 53s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5a5e2e10   RUNNING        0.125998                     11                0.0654222             0.785238                 0.692594        9.5092            8.98958        241            6.11089       0.310087       0.45606  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_19391f24   RUNNING        0.147065                     10                2.44803               0.717856                 0.624617        0.00883146        0.775553         2            5.41551       0.963906       0.976501 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 19 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:07:05] [2]\ttrain-rmse:0.90159\tvalid-rmse:0.92526\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:07:06] [242]\ttrain-rmse:0.30970\tvalid-rmse:0.45600\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:07:08] [3]\ttrain-rmse:0.84340\tvalid-rmse:0.88041\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:07:10] [243]\ttrain-rmse:0.30954\tvalid-rmse:0.45590\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:07:12] [4]\ttrain-rmse:0.76794\tvalid-rmse:0.81746\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:07:13] [5]\ttrain-rmse:0.70190\tvalid-rmse:0.75749\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:07:15] [244]\ttrain-rmse:0.30934\tvalid-rmse:0.45581\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:07:17] [6]\ttrain-rmse:0.64987\tvalid-rmse:0.71776\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.791 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:07:19] [245]\ttrain-rmse:0.30917\tvalid-rmse:0.45578\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:07:21] [7]\ttrain-rmse:0.59940\tvalid-rmse:0.67319\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.918 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.919 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.919 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.919 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.797 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.797 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:07:22] [246]\ttrain-rmse:0.30902\tvalid-rmse:0.45583\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:07:24] [8]\ttrain-rmse:0.56532\tvalid-rmse:0.64919\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.734 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:07:26] [247]\ttrain-rmse:0.30889\tvalid-rmse:0.45587\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:07:28] [9]\ttrain-rmse:0.54694\tvalid-rmse:0.63661\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.789 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.789 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:07:29] [248]\ttrain-rmse:0.30872\tvalid-rmse:0.45590\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.782 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:07:31] [10]\ttrain-rmse:0.52323\tvalid-rmse:0.62058\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.776 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:07:33] [249]\ttrain-rmse:0.30853\tvalid-rmse:0.45589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 24 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:07:35. Total running time: 1hr 18min 23s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5a5e2e10   RUNNING        0.125998                     11                0.0654222             0.785238                 0.692594        9.5092            8.98958        249            6.13344       0.308724       0.4559   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_19391f24   RUNNING        0.147065                     10                2.44803               0.717856                 0.624617        0.00883146        0.775553        11            5.44157       0.523229       0.62058  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 19 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.791 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.792 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.792 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:07:35] [11]\ttrain-rmse:0.48950\tvalid-rmse:0.59368\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:07:37] [250]\ttrain-rmse:0.30836\tvalid-rmse:0.45579\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:07:38] [12]\ttrain-rmse:0.46775\tvalid-rmse:0.58014\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:07:40] [251]\ttrain-rmse:0.30806\tvalid-rmse:0.45555\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:07:42] [13]\ttrain-rmse:0.44874\tvalid-rmse:0.57068\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:07:44] [252]\ttrain-rmse:0.30782\tvalid-rmse:0.45552\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:07:45] [253]\ttrain-rmse:0.30769\tvalid-rmse:0.45557\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:07:47] [14]\ttrain-rmse:0.43495\tvalid-rmse:0.56238\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:07:49] [254]\ttrain-rmse:0.30746\tvalid-rmse:0.45563\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:07:51] [15]\ttrain-rmse:0.41190\tvalid-rmse:0.54458\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:07:52] [255]\ttrain-rmse:0.30732\tvalid-rmse:0.45569\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:07:54] [16]\ttrain-rmse:0.39926\tvalid-rmse:0.53924\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:07:56] [256]\ttrain-rmse:0.30714\tvalid-rmse:0.45560\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:07:58] [17]\ttrain-rmse:0.39338\tvalid-rmse:0.53711\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:07:59] [257]\ttrain-rmse:0.30705\tvalid-rmse:0.45565\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:08:01] [18]\ttrain-rmse:0.38685\tvalid-rmse:0.53581\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.783 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:08:03] [258]\ttrain-rmse:0.30677\tvalid-rmse:0.45565\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:08:05] [19]\ttrain-rmse:0.37326\tvalid-rmse:0.52722\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 24 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:08:06. Total running time: 1hr 18min 54s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5a5e2e10   RUNNING        0.125998                     11                0.0654222             0.785238                 0.692594        9.5092            8.98958        259            6.16068       0.306767       0.455648 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_19391f24   RUNNING        0.147065                     10                2.44803               0.717856                 0.624617        0.00883146        0.775553        19            5.46408       0.386852       0.535812 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 19 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:08:06] [259]\ttrain-rmse:0.30665\tvalid-rmse:0.45562\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:08:08] [20]\ttrain-rmse:0.36537\tvalid-rmse:0.52466\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.778 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:08:10] [260]\ttrain-rmse:0.30641\tvalid-rmse:0.45566\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:08:12] [21]\ttrain-rmse:0.35819\tvalid-rmse:0.52219\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:08:14] [261]\ttrain-rmse:0.30616\tvalid-rmse:0.45561\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:08:15] [22]\ttrain-rmse:0.34578\tvalid-rmse:0.51351\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.745 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:08:17] [23]\ttrain-rmse:0.33980\tvalid-rmse:0.51218\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:08:19] [262]\ttrain-rmse:0.30603\tvalid-rmse:0.45561\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:08:21] [24]\ttrain-rmse:0.33238\tvalid-rmse:0.50751\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:08:22] [263]\ttrain-rmse:0.30585\tvalid-rmse:0.45564\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.737 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:08:24] [25]\ttrain-rmse:0.32794\tvalid-rmse:0.50693\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:08:26] [264]\ttrain-rmse:0.30572\tvalid-rmse:0.45556\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:08:28] [265]\ttrain-rmse:0.30554\tvalid-rmse:0.45560\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:08:29] [26]\ttrain-rmse:0.32388\tvalid-rmse:0.50639\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.786 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.787 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:08:31] [266]\ttrain-rmse:0.30536\tvalid-rmse:0.45567\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:08:33] [27]\ttrain-rmse:0.31890\tvalid-rmse:0.50539\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.776 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.761 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:08:35] [267]\ttrain-rmse:0.30519\tvalid-rmse:0.45563\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:08:36] [28]\ttrain-rmse:0.31509\tvalid-rmse:0.50404\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 24 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:08:38. Total running time: 1hr 19min 26s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5a5e2e10   RUNNING        0.125998                     11                0.0654222             0.785238                 0.692594        9.5092            8.98958        267            6.18287       0.305362       0.455667 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_19391f24   RUNNING        0.147065                     10                2.44803               0.717856                 0.624617        0.00883146        0.775553        29            5.49417       0.31509        0.504044 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 19 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:08:38] [29]\ttrain-rmse:0.30881\tvalid-rmse:0.49982\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.776 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:08:40] [268]\ttrain-rmse:0.30506\tvalid-rmse:0.45563\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:08:42] [30]\ttrain-rmse:0.30555\tvalid-rmse:0.49901\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:08:43] [269]\ttrain-rmse:0.30480\tvalid-rmse:0.45562\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:08:45] [31]\ttrain-rmse:0.30202\tvalid-rmse:0.49731\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.916 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.916 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.916 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.916 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:08:47] [270]\ttrain-rmse:0.30460\tvalid-rmse:0.45561\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:08:49] [32]\ttrain-rmse:0.29843\tvalid-rmse:0.49676\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:08:51] [271]\ttrain-rmse:0.30446\tvalid-rmse:0.45563\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:08:52] [33]\ttrain-rmse:0.29485\tvalid-rmse:0.49427\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.730 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:08:54] [272]\ttrain-rmse:0.30424\tvalid-rmse:0.45554\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.781 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.782 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.782 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:08:56] [34]\ttrain-rmse:0.29156\tvalid-rmse:0.49424\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:08:58] [273]\ttrain-rmse:0.30408\tvalid-rmse:0.45554\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.732 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:08:59] [35]\ttrain-rmse:0.28904\tvalid-rmse:0.49445\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:09:01] [274]\ttrain-rmse:0.30393\tvalid-rmse:0.45558\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:09:03] [36]\ttrain-rmse:0.28456\tvalid-rmse:0.49188\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.737 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:09:05] [275]\ttrain-rmse:0.30370\tvalid-rmse:0.45549\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:09:06] [37]\ttrain-rmse:0.28170\tvalid-rmse:0.49166\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.742 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:09:08] [276]\ttrain-rmse:0.30357\tvalid-rmse:0.45550\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 24 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:09:10. Total running time: 1hr 19min 58s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5a5e2e10   RUNNING        0.125998                     11                0.0654222             0.785238                 0.692594        9.5092            8.98958        277            6.21004       0.303568       0.455501 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_19391f24   RUNNING        0.147065                     10                2.44803               0.717856                 0.624617        0.00883146        0.775553        37            5.51632       0.284559       0.491882 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 19 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.722 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.723 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:09:10] [277]\ttrain-rmse:0.30343\tvalid-rmse:0.45547\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:09:12] [38]\ttrain-rmse:0.27875\tvalid-rmse:0.48964\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.734 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:09:13] [278]\ttrain-rmse:0.30327\tvalid-rmse:0.45544\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.735 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:09:15] [39]\ttrain-rmse:0.27594\tvalid-rmse:0.48969\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.739 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:09:17] [279]\ttrain-rmse:0.30310\tvalid-rmse:0.45536\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:09:19] [40]\ttrain-rmse:0.27305\tvalid-rmse:0.48917\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.733 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:09:20] [41]\ttrain-rmse:0.27163\tvalid-rmse:0.48921\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:09:22] [280]\ttrain-rmse:0.30298\tvalid-rmse:0.45531\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:09:24] [42]\ttrain-rmse:0.27062\tvalid-rmse:0.48936\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.730 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.724 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:09:26] [281]\ttrain-rmse:0.30271\tvalid-rmse:0.45526\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:09:27] [43]\ttrain-rmse:0.26867\tvalid-rmse:0.48910\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:09:29] [282]\ttrain-rmse:0.30259\tvalid-rmse:0.45512\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:09:31] [283]\ttrain-rmse:0.30239\tvalid-rmse:0.45516\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.736 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:09:33] [44]\ttrain-rmse:0.26482\tvalid-rmse:0.48678\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:09:34] [284]\ttrain-rmse:0.30211\tvalid-rmse:0.45519\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:09:36] [45]\ttrain-rmse:0.26279\tvalid-rmse:0.48727\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:09:38] [285]\ttrain-rmse:0.30198\tvalid-rmse:0.45518\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.735 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:09:40] [46]\ttrain-rmse:0.26053\tvalid-rmse:0.48711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 24 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:09:41. Total running time: 1hr 20min 29s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5a5e2e10   RUNNING        0.125998                     11                0.0654222             0.785238                 0.692594        9.5092            8.98958        286            6.23472       0.301978       0.455184 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_19391f24   RUNNING        0.147065                     10                2.44803               0.717856                 0.624617        0.00883146        0.775553        46            5.58541       0.262788       0.487275 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 19 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:09:41] [286]\ttrain-rmse:0.30181\tvalid-rmse:0.45511\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:09:43] [47]\ttrain-rmse:0.25897\tvalid-rmse:0.48682\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:09:45] [287]\ttrain-rmse:0.30166\tvalid-rmse:0.45517\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:09:47] [48]\ttrain-rmse:0.25685\tvalid-rmse:0.48684\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:09:48] [288]\ttrain-rmse:0.30144\tvalid-rmse:0.45513\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:09:50] [49]\ttrain-rmse:0.25401\tvalid-rmse:0.48626\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:09:52] [50]\ttrain-rmse:0.25265\tvalid-rmse:0.48618\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:09:54] [289]\ttrain-rmse:0.30129\tvalid-rmse:0.45508\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:09:55] [51]\ttrain-rmse:0.25040\tvalid-rmse:0.48614\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:09:57] [290]\ttrain-rmse:0.30116\tvalid-rmse:0.45509\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:09:59] [52]\ttrain-rmse:0.24832\tvalid-rmse:0.48538\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:10:01] [291]\ttrain-rmse:0.30099\tvalid-rmse:0.45510\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.777 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:10:02] [292]\ttrain-rmse:0.30078\tvalid-rmse:0.45513\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:10:04] [53]\ttrain-rmse:0.24690\tvalid-rmse:0.48539\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:10:06] [293]\ttrain-rmse:0.30059\tvalid-rmse:0.45508\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:10:08] [54]\ttrain-rmse:0.24571\tvalid-rmse:0.48527\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.896 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.896 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.896 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.896 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:10:10] [294]\ttrain-rmse:0.30047\tvalid-rmse:0.45507\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.736 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:10:11] [55]\ttrain-rmse:0.24459\tvalid-rmse:0.48518\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.717 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.717 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.717 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.717 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 24 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:10:13. Total running time: 1hr 21min 1s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5a5e2e10   RUNNING        0.125998                     11                0.0654222             0.785238                 0.692594        9.5092            8.98958        295            6.25976       0.300473       0.45507  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_19391f24   RUNNING        0.147065                     10                2.44803               0.717856                 0.624617        0.00883146        0.775553        55            5.61159       0.245707       0.485271 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 19 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:10:13] [295]\ttrain-rmse:0.30029\tvalid-rmse:0.45502\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:10:15] [56]\ttrain-rmse:0.24403\tvalid-rmse:0.48518\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.736 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.728 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:10:16] [296]\ttrain-rmse:0.30016\tvalid-rmse:0.45499\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.723 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:10:18] [57]\ttrain-rmse:0.24264\tvalid-rmse:0.48536\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.739 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:10:20] [297]\ttrain-rmse:0.29994\tvalid-rmse:0.45497\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:10:22] [58]\ttrain-rmse:0.24072\tvalid-rmse:0.48557\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.727 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:10:23] [59]\ttrain-rmse:0.23869\tvalid-rmse:0.48556\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.732 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:10:25] [298]\ttrain-rmse:0.29979\tvalid-rmse:0.45495\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.724 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:10:27] [60]\ttrain-rmse:0.23723\tvalid-rmse:0.48561\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.719 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.720 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.720 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.720 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3182, ip=100.64.47.109)\u001b[0m [13:10:29] [299]\ttrain-rmse:0.29958\tvalid-rmse:0.45498\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.785 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:10:30] [61]\ttrain-rmse:0.23544\tvalid-rmse:0.48604\n",
      "\u001b[36m(RayTrainWorker pid=3228, ip=100.64.47.109)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=s3, path=ddl-wadkars/end-to-end/california/air/xgb/xgb_from_s3_irsa/XGBoostTrainer_5a5e2e10_26_alpha=8.9896,colsample_bytree=0.6926,eta=0.1260,eval_metric=rmse,lambda=9.5092,max_depth=11,min_child_w_2025-09-01_12-52-49/checkpoint_000000)\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🏃 View run XGBoostTrainer_5a5e2e10 at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265/runs/2422427e1fb2431d863124968c550784\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🧪 View experiment at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_5a5e2e10 completed after 300 iterations at 2025-09-01 13:10:33. Total running time: 1hr 21min 20s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_5a5e2e10 result             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ checkpoint_dir_name                              │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_this_iter_s                         0.00271 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_total_s                              6.2736 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ training_iteration                           300 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ train-rmse                               0.29958 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ valid-rmse                               0.45498 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.735 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:10:35] [62]\ttrain-rmse:0.23341\tvalid-rmse:0.48637\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.733 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:10:36] [63]\ttrain-rmse:0.23088\tvalid-rmse:0.48486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_aadbf50e started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_aadbf50e config                         │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/alpha                              3.5152418505121035 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/colsample_bytree                   0.8308389037644801 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eta                               0.04881153661401159 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eval_metric                                      rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/lambda                            0.25484473289953186 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/max_depth                                           9 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/min_child_weight                  0.15713136147800658 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/nthread                                             1 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/objective                            reg:squarederror │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/subsample                          0.8276803410014832 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/tree_method                                      hist │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=4457) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=4458) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=4459) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=4460) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:10:39] [64]\ttrain-rmse:0.22814\tvalid-rmse:0.48370\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.732 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(RayTrainWorker pid=4460, ip=100.64.8.234)\u001b[0m [13:10:39] Task [xgboost.ray-rank=00000003]:fc8ddbee3426a98ad9ce5e1c04000000 got rank 3\n",
      "\u001b[36m(RayTrainWorker pid=4457, ip=100.64.8.234)\u001b[0m [13:10:39] Task [xgboost.ray-rank=00000000]:192eccf37a1e7b1c6989730004000000 got rank 0\n",
      "\u001b[36m(RayTrainWorker pid=4459, ip=100.64.8.234)\u001b[0m [13:10:39] Task [xgboost.ray-rank=00000002]:a411e3b924d4c8e92e6ff2c804000000 got rank 2\n",
      "\u001b[36m(RayTrainWorker pid=4458, ip=100.64.8.234)\u001b[0m [13:10:39] Task [xgboost.ray-rank=00000001]:443dc0f6d90b773da8bfd45004000000 got rank 1\n",
      "\u001b[36m(SplitCoordinator pid=4621, ip=100.64.8.234)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=4621, ip=100.64.8.234)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:10:41] [65]\ttrain-rmse:0.22659\tvalid-rmse:0.48339\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.722 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.723 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(SplitCoordinator pid=4622, ip=100.64.8.234)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=4622, ip=100.64.8.234)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.733 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:10:43] [66]\ttrain-rmse:0.22398\tvalid-rmse:0.48261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 25 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:10:44. Total running time: 1hr 21min 32s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_19391f24   RUNNING        0.147065                     10                2.44803               0.717856                 0.624617        0.00883146        0.775553        67            5.64453       0.223976       0.482609 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_aadbf50e   RUNNING        0.0488115                     9                0.157131              0.82768                  0.830839        0.254845          3.51524                                                             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 20 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.735 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:10:44] [67]\ttrain-rmse:0.22236\tvalid-rmse:0.48263\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:10:46] [68]\ttrain-rmse:0.22088\tvalid-rmse:0.48176\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:10:48] [69]\ttrain-rmse:0.21870\tvalid-rmse:0.48210\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.769 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.769 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:10:50] [70]\ttrain-rmse:0.21731\tvalid-rmse:0.48222\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:10:51] [71]\ttrain-rmse:0.21566\tvalid-rmse:0.48194\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:10:53] [72]\ttrain-rmse:0.21417\tvalid-rmse:0.48204\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:10:55] [73]\ttrain-rmse:0.21183\tvalid-rmse:0.48182\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.770 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.770 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:10:57] [74]\ttrain-rmse:0.21042\tvalid-rmse:0.48183\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:10:58] [0]\ttrain-rmse:1.11768\tvalid-rmse:1.10466\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:10:58] [1]\ttrain-rmse:1.08089\tvalid-rmse:1.07014\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:10:59] [75]\ttrain-rmse:0.20858\tvalid-rmse:0.48072\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.692 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.692 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.692 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.692 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:11:00] [2]\ttrain-rmse:1.04527\tvalid-rmse:1.03671\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.785 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.785 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:11:02] [76]\ttrain-rmse:0.20639\tvalid-rmse:0.48076\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:11:04] [3]\ttrain-rmse:1.01097\tvalid-rmse:1.00545\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.735 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:11:05] [77]\ttrain-rmse:0.20477\tvalid-rmse:0.48076\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:11:07] [4]\ttrain-rmse:0.97749\tvalid-rmse:0.97470\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:11:09] [78]\ttrain-rmse:0.20335\tvalid-rmse:0.48088\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:11:11] [5]\ttrain-rmse:0.94682\tvalid-rmse:0.94599\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:11:13] [79]\ttrain-rmse:0.20204\tvalid-rmse:0.48038\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:11:14] [6]\ttrain-rmse:0.91837\tvalid-rmse:0.92073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 25 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:11:16. Total running time: 1hr 22min 4s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_19391f24   RUNNING        0.147065                     10                2.44803               0.717856                 0.624617        0.00883146        0.775553        79            5.67821       0.203347       0.480881 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_aadbf50e   RUNNING        0.0488115                     9                0.157131              0.82768                  0.830839        0.254845          3.51524          6           20.0502        0.946819       0.945988 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 20 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.771 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:11:16] [7]\ttrain-rmse:0.88889\tvalid-rmse:0.89360\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:11:18] [80]\ttrain-rmse:0.20067\tvalid-rmse:0.48017\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:11:20] [8]\ttrain-rmse:0.86201\tvalid-rmse:0.86979\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:11:21] [81]\ttrain-rmse:0.19908\tvalid-rmse:0.48008\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:11:23] [9]\ttrain-rmse:0.83570\tvalid-rmse:0.84627\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:11:25] [82]\ttrain-rmse:0.19735\tvalid-rmse:0.47930\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:11:27] [10]\ttrain-rmse:0.81267\tvalid-rmse:0.82594\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:11:28] [83]\ttrain-rmse:0.19616\tvalid-rmse:0.47896\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.742 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:11:30] [11]\ttrain-rmse:0.79040\tvalid-rmse:0.80660\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:11:32] [84]\ttrain-rmse:0.19491\tvalid-rmse:0.47902\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.902 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.902 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.902 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.902 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.739 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:11:34] [12]\ttrain-rmse:0.77135\tvalid-rmse:0.79080\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:11:35] [85]\ttrain-rmse:0.19365\tvalid-rmse:0.47832\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:11:37] [86]\ttrain-rmse:0.19236\tvalid-rmse:0.47829\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.727 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.733 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:11:39] [13]\ttrain-rmse:0.75187\tvalid-rmse:0.77390\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:11:41] [87]\ttrain-rmse:0.19119\tvalid-rmse:0.47848\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:11:42] [14]\ttrain-rmse:0.73184\tvalid-rmse:0.75625\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.720 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.720 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.720 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.720 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:11:44] [88]\ttrain-rmse:0.19008\tvalid-rmse:0.47857\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.733 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:11:46] [15]\ttrain-rmse:0.71259\tvalid-rmse:0.73957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 25 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:11:48. Total running time: 1hr 22min 36s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_19391f24   RUNNING        0.147065                     10                2.44803               0.717856                 0.624617        0.00883146        0.775553        89            5.70642       0.190082       0.478565 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_aadbf50e   RUNNING        0.0488115                     9                0.157131              0.82768                  0.830839        0.254845          3.51524         14           20.0725        0.751866       0.773899 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 20 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.776 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:11:48] [89]\ttrain-rmse:0.18918\tvalid-rmse:0.47826\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:11:49] [16]\ttrain-rmse:0.69469\tvalid-rmse:0.72433\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:11:51] [90]\ttrain-rmse:0.18811\tvalid-rmse:0.47801\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:11:53] [17]\ttrain-rmse:0.68205\tvalid-rmse:0.71366\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.742 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:11:55] [91]\ttrain-rmse:0.18657\tvalid-rmse:0.47774\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.766 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:11:56] [18]\ttrain-rmse:0.66765\tvalid-rmse:0.70217\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:11:58] [19]\ttrain-rmse:0.65192\tvalid-rmse:0.68853\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:12:00] [92]\ttrain-rmse:0.18511\tvalid-rmse:0.47779\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:12:02] [20]\ttrain-rmse:0.63902\tvalid-rmse:0.67773\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.761 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:12:03] [93]\ttrain-rmse:0.18398\tvalid-rmse:0.47783\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.744 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.744 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:12:05] [21]\ttrain-rmse:0.62445\tvalid-rmse:0.66462\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:12:07] [94]\ttrain-rmse:0.18237\tvalid-rmse:0.47792\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.739 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:12:09] [95]\ttrain-rmse:0.18093\tvalid-rmse:0.47787\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.729 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:12:10] [22]\ttrain-rmse:0.61082\tvalid-rmse:0.65266\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:12:12] [96]\ttrain-rmse:0.17986\tvalid-rmse:0.47786\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.726 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:12:14] [23]\ttrain-rmse:0.59992\tvalid-rmse:0.64446\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.736 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:12:16] [97]\ttrain-rmse:0.17910\tvalid-rmse:0.47787\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.742 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:12:17] [24]\ttrain-rmse:0.58727\tvalid-rmse:0.63322\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 25 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:12:19. Total running time: 1hr 23min 7s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_19391f24   RUNNING        0.147065                     10                2.44803               0.717856                 0.624617        0.00883146        0.775553        97            5.72882       0.179858       0.477856 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_aadbf50e   RUNNING        0.0488115                     9                0.157131              0.82768                  0.830839        0.254845          3.51524         24           20.0996        0.59992        0.644456 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 20 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.760 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.760 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:12:19] [25]\ttrain-rmse:0.57761\tvalid-rmse:0.62602\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:12:21] [98]\ttrain-rmse:0.17834\tvalid-rmse:0.47786\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:12:23] [26]\ttrain-rmse:0.56845\tvalid-rmse:0.61892\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:12:24] [99]\ttrain-rmse:0.17767\tvalid-rmse:0.47740\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:12:26] [27]\ttrain-rmse:0.55760\tvalid-rmse:0.60919\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:12:28] [100]\ttrain-rmse:0.17662\tvalid-rmse:0.47753\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:12:30] [28]\ttrain-rmse:0.54940\tvalid-rmse:0.60274\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:12:31] [101]\ttrain-rmse:0.17560\tvalid-rmse:0.47762\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:12:33] [29]\ttrain-rmse:0.53974\tvalid-rmse:0.59426\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.737 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.734 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:12:35] [102]\ttrain-rmse:0.17439\tvalid-rmse:0.47793\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:12:37] [30]\ttrain-rmse:0.53085\tvalid-rmse:0.58707\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.734 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:12:38] [103]\ttrain-rmse:0.17325\tvalid-rmse:0.47798\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.745 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:12:40] [104]\ttrain-rmse:0.17218\tvalid-rmse:0.47783\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.735 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:12:42] [31]\ttrain-rmse:0.52339\tvalid-rmse:0.58153\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:12:44] [105]\ttrain-rmse:0.17144\tvalid-rmse:0.47791\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.742 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:12:45] [32]\ttrain-rmse:0.51684\tvalid-rmse:0.57703\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:12:47] [106]\ttrain-rmse:0.17027\tvalid-rmse:0.47755\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:12:49] [33]\ttrain-rmse:0.50960\tvalid-rmse:0.57185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 25 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:12:51. Total running time: 1hr 23min 39s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_19391f24   RUNNING        0.147065                     10                2.44803               0.717856                 0.624617        0.00883146        0.775553       106            5.75433       0.17144        0.477912 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_aadbf50e   RUNNING        0.0488115                     9                0.157131              0.82768                  0.830839        0.254845          3.51524         33           20.1254        0.516836       0.577029 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 20 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:12:51] [34]\ttrain-rmse:0.50399\tvalid-rmse:0.56798\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:12:52] [107]\ttrain-rmse:0.16891\tvalid-rmse:0.47765\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.773 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.773 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:12:54] [35]\ttrain-rmse:0.49645\tvalid-rmse:0.56181\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:12:56] [108]\ttrain-rmse:0.16807\tvalid-rmse:0.47737\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.936 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.936 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.936 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.936 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.777 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.777 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:12:58] [36]\ttrain-rmse:0.48973\tvalid-rmse:0.55669\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.724 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:13:00] [109]\ttrain-rmse:0.16674\tvalid-rmse:0.47679\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:13:01] [110]\ttrain-rmse:0.16574\tvalid-rmse:0.47688\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.783 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.783 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:13:03] [37]\ttrain-rmse:0.48397\tvalid-rmse:0.55237\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:13:05] [111]\ttrain-rmse:0.16461\tvalid-rmse:0.47698\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.731 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:13:07] [38]\ttrain-rmse:0.47731\tvalid-rmse:0.54712\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.778 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:13:08] [112]\ttrain-rmse:0.16393\tvalid-rmse:0.47712\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:13:10] [39]\ttrain-rmse:0.47282\tvalid-rmse:0.54429\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:13:12] [40]\ttrain-rmse:0.46788\tvalid-rmse:0.54044\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.732 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.732 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:13:14] [113]\ttrain-rmse:0.16329\tvalid-rmse:0.47704\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.729 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:13:15] [41]\ttrain-rmse:0.46379\tvalid-rmse:0.53813\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:13:17] [114]\ttrain-rmse:0.16230\tvalid-rmse:0.47703\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:13:19] [42]\ttrain-rmse:0.46016\tvalid-rmse:0.53570\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:13:21] [115]\ttrain-rmse:0.16144\tvalid-rmse:0.47714\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 25 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:13:21. Total running time: 1hr 24min 9s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_19391f24   RUNNING        0.147065                     10                2.44803               0.717856                 0.624617        0.00883146        0.775553       115            5.77975       0.162303       0.477028 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_aadbf50e   RUNNING        0.0488115                     9                0.157131              0.82768                  0.830839        0.254845          3.51524         41           20.1471        0.467881       0.54044  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 20 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.768 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.768 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:13:22] [116]\ttrain-rmse:0.16039\tvalid-rmse:0.47704\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.715 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.715 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.715 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.716 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:13:24] [43]\ttrain-rmse:0.45670\tvalid-rmse:0.53370\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.711 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.711 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.711 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.711 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:13:26] [117]\ttrain-rmse:0.15972\tvalid-rmse:0.47698\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:13:28] [44]\ttrain-rmse:0.45243\tvalid-rmse:0.53040\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:13:29] [118]\ttrain-rmse:0.15861\tvalid-rmse:0.47665\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.718 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.719 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.719 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.719 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.771 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.772 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.772 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:13:31] [45]\ttrain-rmse:0.44866\tvalid-rmse:0.52795\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:13:33] [119]\ttrain-rmse:0.15766\tvalid-rmse:0.47668\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.737 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.726 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:13:35] [46]\ttrain-rmse:0.44590\tvalid-rmse:0.52631\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:13:36] [120]\ttrain-rmse:0.15669\tvalid-rmse:0.47683\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.759 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.759 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:13:38] [47]\ttrain-rmse:0.44299\tvalid-rmse:0.52483\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:13:40] [121]\ttrain-rmse:0.15569\tvalid-rmse:0.47700\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.728 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:13:42] [48]\ttrain-rmse:0.44004\tvalid-rmse:0.52353\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:13:43] [49]\ttrain-rmse:0.43749\tvalid-rmse:0.52204\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:13:45] [122]\ttrain-rmse:0.15498\tvalid-rmse:0.47691\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:13:47] [50]\ttrain-rmse:0.43508\tvalid-rmse:0.52079\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.725 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:13:49] [123]\ttrain-rmse:0.15409\tvalid-rmse:0.47699\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.723 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.724 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:13:50] [51]\ttrain-rmse:0.43202\tvalid-rmse:0.51863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 25 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:13:52. Total running time: 1hr 24min 40s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_19391f24   RUNNING        0.147065                     10                2.44803               0.717856                 0.624617        0.00883146        0.775553       124            5.80491       0.154091       0.476987 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_aadbf50e   RUNNING        0.0488115                     9                0.157131              0.82768                  0.830839        0.254845          3.51524         50           20.2218        0.437489       0.522044 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 20 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:13:52] [124]\ttrain-rmse:0.15326\tvalid-rmse:0.47704\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:13:54] [125]\ttrain-rmse:0.15248\tvalid-rmse:0.47700\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:13:56] [52]\ttrain-rmse:0.42895\tvalid-rmse:0.51632\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.766 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:13:57] [126]\ttrain-rmse:0.15141\tvalid-rmse:0.47699\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:13:59] [53]\ttrain-rmse:0.42514\tvalid-rmse:0.51326\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:14:01] [127]\ttrain-rmse:0.15071\tvalid-rmse:0.47702\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:14:03] [54]\ttrain-rmse:0.42289\tvalid-rmse:0.51243\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.784 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.784 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.731 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:14:04] [128]\ttrain-rmse:0.15010\tvalid-rmse:0.47715\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:14:06] [55]\ttrain-rmse:0.42078\tvalid-rmse:0.51147\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:14:08] [129]\ttrain-rmse:0.14905\tvalid-rmse:0.47702\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.742 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:14:10] [56]\ttrain-rmse:0.41877\tvalid-rmse:0.51048\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:14:11] [130]\ttrain-rmse:0.14817\tvalid-rmse:0.47682\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:14:13] [57]\ttrain-rmse:0.41701\tvalid-rmse:0.50988\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:14:15] [58]\ttrain-rmse:0.41527\tvalid-rmse:0.50911\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:14:17] [131]\ttrain-rmse:0.14740\tvalid-rmse:0.47680\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.894 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.894 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.894 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.894 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:14:19] [59]\ttrain-rmse:0.41358\tvalid-rmse:0.50841\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:14:20] [132]\ttrain-rmse:0.14682\tvalid-rmse:0.47683\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.725 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4411, ip=100.64.8.234)\u001b[0m [13:14:22] [60]\ttrain-rmse:0.41194\tvalid-rmse:0.50765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 25 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:14:24. Total running time: 1hr 25min 12s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_19391f24   RUNNING        0.147065                     10                2.44803               0.717856                 0.624617        0.00883146        0.775553       133            5.82985       0.146818       0.476826 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_aadbf50e   RUNNING        0.0488115                     9                0.157131              0.82768                  0.830839        0.254845          3.51524         59           20.2464        0.415271       0.509106 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 20 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.730 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:14:24] [133]\ttrain-rmse:0.14627\tvalid-rmse:0.47669\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.731 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🏃 View run XGBoostTrainer_aadbf50e at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265/runs/a06096414a99458c9cd5eb89c99ad576\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🧪 View experiment at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_aadbf50e completed after 60 iterations at 2025-09-01 13:14:26. Total running time: 1hr 25min 14s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_aadbf50e result             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ checkpoint_dir_name                              │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_this_iter_s                         0.00269 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_total_s                             20.2491 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ training_iteration                            60 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ train-rmse                               0.41358 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ valid-rmse                               0.50841 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:14:28] [134]\ttrain-rmse:0.14560\tvalid-rmse:0.47649\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.727 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:14:30] [135]\ttrain-rmse:0.14486\tvalid-rmse:0.47649\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.728 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_ea77a187 started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_ea77a187 config                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/alpha                             0.0013145671659314853 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/colsample_bytree                     0.6716315214285365 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eta                                 0.02397655295233479 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eval_metric                                        rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/lambda                             0.003947748162029513 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/max_depth                                            11 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/min_child_weight                    0.45027890709911733 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/nthread                                               1 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/objective                              reg:squarederror │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/subsample                            0.7291207840335858 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/tree_method                                        hist │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰────────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=3733, ip=100.64.47.109)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=3733, ip=100.64.47.109)\u001b[0m - (node_id=020c605741033b9152b4c9a349b6d58f62114a723ef561972a9adde1, ip=100.64.47.109, pid=3779) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=3733, ip=100.64.47.109)\u001b[0m - (node_id=020c605741033b9152b4c9a349b6d58f62114a723ef561972a9adde1, ip=100.64.47.109, pid=3780) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=3733, ip=100.64.47.109)\u001b[0m - (node_id=020c605741033b9152b4c9a349b6d58f62114a723ef561972a9adde1, ip=100.64.47.109, pid=3781) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=3733, ip=100.64.47.109)\u001b[0m - (node_id=020c605741033b9152b4c9a349b6d58f62114a723ef561972a9adde1, ip=100.64.47.109, pid=3782) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:14:33] [136]\ttrain-rmse:0.14423\tvalid-rmse:0.47646\n",
      "\u001b[36m(RayTrainWorker pid=3780, ip=100.64.47.109)\u001b[0m [13:14:33] Task [xgboost.ray-rank=00000001]:073018958d243126160c13d304000000 got rank 1\n",
      "\u001b[36m(RayTrainWorker pid=3781, ip=100.64.47.109)\u001b[0m [13:14:33] Task [xgboost.ray-rank=00000002]:7836243dfb729c96c2cec16404000000 got rank 2\n",
      "\u001b[36m(RayTrainWorker pid=3779, ip=100.64.47.109)\u001b[0m [13:14:33] Task [xgboost.ray-rank=00000000]:79ce2826a54caccd79f0886f04000000 got rank 0\n",
      "\u001b[36m(RayTrainWorker pid=3782, ip=100.64.47.109)\u001b[0m [13:14:33] Task [xgboost.ray-rank=00000003]:b4a77413deb5de79c104922504000000 got rank 3\n",
      "\u001b[36m(SplitCoordinator pid=3943, ip=100.64.47.109)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=3943, ip=100.64.47.109)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:14:34] [137]\ttrain-rmse:0.14351\tvalid-rmse:0.47650\n",
      "\u001b[36m(SplitCoordinator pid=3946, ip=100.64.47.109)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=3946, ip=100.64.47.109)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.731 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.731 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:14:36] [138]\ttrain-rmse:0.14260\tvalid-rmse:0.47600\n",
      "\u001b[36m(XGBoostTrainer pid=3733, ip=100.64.47.109)\u001b[0m [13:14:36] [0]\ttrain-rmse:1.13485\tvalid-rmse:1.12200\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:14:38] [139]\ttrain-rmse:0.14159\tvalid-rmse:0.47624\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.691 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.691 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.692 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.692 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3733, ip=100.64.47.109)\u001b[0m [13:14:39] [1]\ttrain-rmse:1.11564\tvalid-rmse:1.10655\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:14:41] [140]\ttrain-rmse:0.14085\tvalid-rmse:0.47607\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.734 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3733, ip=100.64.47.109)\u001b[0m [13:14:43] [2]\ttrain-rmse:1.09765\tvalid-rmse:1.09172\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.737 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.737 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:14:45] [141]\ttrain-rmse:0.14012\tvalid-rmse:0.47596\n",
      "\u001b[36m(XGBoostTrainer pid=3733, ip=100.64.47.109)\u001b[0m [13:14:46] [3]\ttrain-rmse:1.07931\tvalid-rmse:1.07664\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:14:48] [142]\ttrain-rmse:0.13952\tvalid-rmse:0.47594\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.729 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3733, ip=100.64.47.109)\u001b[0m [13:14:50] [4]\ttrain-rmse:1.05740\tvalid-rmse:1.05747\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:14:52] [143]\ttrain-rmse:0.13911\tvalid-rmse:0.47588\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3733, ip=100.64.47.109)\u001b[0m [13:14:53] [5]\ttrain-rmse:1.03878\tvalid-rmse:1.04067\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 26 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:14:55. Total running time: 1hr 25min 43s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937        0.0071157                                                            │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_19391f24   RUNNING        0.147065                     10                2.44803               0.717856                 0.624617        0.00883146       0.775553        144            5.8607        0.139107       0.475878 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ea77a187   RUNNING        0.0239766                    11                0.450279              0.729121                 0.671632        0.00394775       0.00131457        5            5.53764       1.0574         1.05747  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306       0.0027673       300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377        0.399132         60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559          0.0462283        20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788         1.04247          20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312         2.95444          20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 21 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.742 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:14:55] [144]\ttrain-rmse:0.13829\tvalid-rmse:0.47598\n",
      "\u001b[36m(XGBoostTrainer pid=3733, ip=100.64.47.109)\u001b[0m [13:14:57] [6]\ttrain-rmse:1.01910\tvalid-rmse:1.02477\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.763 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:14:59] [145]\ttrain-rmse:0.13765\tvalid-rmse:0.47607\n",
      "\u001b[36m(XGBoostTrainer pid=3733, ip=100.64.47.109)\u001b[0m [13:15:00] [7]\ttrain-rmse:1.00138\tvalid-rmse:1.00877\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.747 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.787 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.788 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.788 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:15:02] [146]\ttrain-rmse:0.13681\tvalid-rmse:0.47608\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3733, ip=100.64.47.109)\u001b[0m [13:15:04] [8]\ttrain-rmse:0.98114\tvalid-rmse:0.99087\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:15:06] [147]\ttrain-rmse:0.13617\tvalid-rmse:0.47613\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.733 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.734 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:15:07] [148]\ttrain-rmse:0.13543\tvalid-rmse:0.47620\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.724 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3733, ip=100.64.47.109)\u001b[0m [13:15:09] [9]\ttrain-rmse:0.96413\tvalid-rmse:0.97556\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:15:11] [149]\ttrain-rmse:0.13495\tvalid-rmse:0.47617\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.729 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.729 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3733, ip=100.64.47.109)\u001b[0m [13:15:13] [10]\ttrain-rmse:0.94638\tvalid-rmse:0.96071\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.724 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:15:14] [150]\ttrain-rmse:0.13411\tvalid-rmse:0.47606\n",
      "\u001b[36m(XGBoostTrainer pid=3733, ip=100.64.47.109)\u001b[0m [13:15:16] [11]\ttrain-rmse:0.92759\tvalid-rmse:0.94473\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.750 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3733, ip=100.64.47.109)\u001b[0m [13:15:18] [12]\ttrain-rmse:0.91124\tvalid-rmse:0.93191\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.727 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:15:20] [151]\ttrain-rmse:0.13338\tvalid-rmse:0.47603\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3733, ip=100.64.47.109)\u001b[0m [13:15:21] [13]\ttrain-rmse:0.89457\tvalid-rmse:0.91863\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.739 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:15:23] [152]\ttrain-rmse:0.13282\tvalid-rmse:0.47607\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.736 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.736 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3733, ip=100.64.47.109)\u001b[0m [13:15:25] [14]\ttrain-rmse:0.88077\tvalid-rmse:0.90768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 26 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:15:27. Total running time: 1hr 26min 14s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937        0.0071157                                                            │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_19391f24   RUNNING        0.147065                     10                2.44803               0.717856                 0.624617        0.00883146       0.775553        153            5.88589       0.132822       0.476072 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_ea77a187   RUNNING        0.0239766                    11                0.450279              0.729121                 0.671632        0.00394775       0.00131457       14            5.56278       0.894571       0.918626 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306       0.0027673       300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377        0.399132         60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559          0.0462283        20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788         1.04247          20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312         2.95444          20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 21 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.730 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:15:27] [153]\ttrain-rmse:0.13211\tvalid-rmse:0.47617\n",
      "\u001b[36m(XGBoostTrainer pid=3733, ip=100.64.47.109)\u001b[0m [13:15:28] [15]\ttrain-rmse:0.86369\tvalid-rmse:0.89329\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:15:30] [154]\ttrain-rmse:0.13162\tvalid-rmse:0.47613\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.715 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.715 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.715 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.715 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3733, ip=100.64.47.109)\u001b[0m [13:15:32] [16]\ttrain-rmse:0.84823\tvalid-rmse:0.88101\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.727 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:15:34] [155]\ttrain-rmse:0.13078\tvalid-rmse:0.47611\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.711 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.712 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.712 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.712 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3733, ip=100.64.47.109)\u001b[0m [13:15:35] [17]\ttrain-rmse:0.83725\tvalid-rmse:0.87287\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:15:37] [156]\ttrain-rmse:0.13034\tvalid-rmse:0.47613\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.727 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.728 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:15:39] [157]\ttrain-rmse:0.12955\tvalid-rmse:0.47601\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.726 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3733, ip=100.64.47.109)\u001b[0m [13:15:40] [18]\ttrain-rmse:0.82608\tvalid-rmse:0.86551\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:15:42] [158]\ttrain-rmse:0.12887\tvalid-rmse:0.47613\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.878 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.879 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.879 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.879 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=3733, ip=100.64.47.109)\u001b[0m [13:15:44] [19]\ttrain-rmse:0.81047\tvalid-rmse:0.85219\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.725 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.725 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:15:46] [159]\ttrain-rmse:0.12832\tvalid-rmse:0.47609\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.734 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.734 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🏃 View run XGBoostTrainer_ea77a187 at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265/runs/b4b51b36292a41b089bc76efa815e56c\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🧪 View experiment at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_ea77a187 completed after 20 iterations at 2025-09-01 13:15:48. Total running time: 1hr 26min 36s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_ea77a187 result             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ checkpoint_dir_name                              │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_this_iter_s                         0.00259 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_total_s                             5.57932 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ training_iteration                            20 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ train-rmse                               0.81047 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ valid-rmse                               0.85219 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:15:50] [160]\ttrain-rmse:0.12769\tvalid-rmse:0.47610\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.730 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.730 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.726 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.727 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.727 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:15:52] [161]\ttrain-rmse:0.12717\tvalid-rmse:0.47603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_6d62774a started with configuration:\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_6d62774a config                          │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/alpha                             0.055127684279269194 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/colsample_bytree                    0.7141377697105875 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eta                                0.03472584482879573 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/eval_metric                                       rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/lambda                            0.001793424898595395 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/max_depth                                           10 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/min_child_weight                     0.323413423190462 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/nthread                                              1 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/objective                             reg:squarederror │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/subsample                           0.6918939129252555 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ params/tree_method                                       hist │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=4960, ip=100.64.8.234)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=4960, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=5006) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=4960, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=5007) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=4960, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=5008) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=4960, ip=100.64.8.234)\u001b[0m - (node_id=2d1bcb85060c3b74f1be5382e6f27d6d5a49912e5fb81274fbb3fa70, ip=100.64.8.234, pid=5009) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(RayTrainWorker pid=5008, ip=100.64.8.234)\u001b[0m [13:15:55] Task [xgboost.ray-rank=00000002]:e99892562637423465d6e70e04000000 got rank 2\n",
      "\u001b[36m(RayTrainWorker pid=5006, ip=100.64.8.234)\u001b[0m [13:15:55] Task [xgboost.ray-rank=00000000]:5f34b90b075ed048953384ce04000000 got rank 0\n",
      "\u001b[36m(RayTrainWorker pid=5009, ip=100.64.8.234)\u001b[0m [13:15:55] Task [xgboost.ray-rank=00000003]:02a1d63f572569c62b3529c304000000 got rank 3\n",
      "\u001b[36m(RayTrainWorker pid=5007, ip=100.64.8.234)\u001b[0m [13:15:55] Task [xgboost.ray-rank=00000001]:9133408907e0fb5124d3c9fd04000000 got rank 1\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:15:55] [162]\ttrain-rmse:0.12664\tvalid-rmse:0.47608\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.762 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.762 s, which may be a performance bottleneck.\n",
      "\u001b[36m(SplitCoordinator pid=5170, ip=100.64.8.234)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=5170, ip=100.64.8.234)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:15:56] [163]\ttrain-rmse:0.12598\tvalid-rmse:0.47594\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(SplitCoordinator pid=5171, ip=100.64.8.234)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-09-01_11-12-11_235542_1/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=5171, ip=100.64.8.234)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(select_columns)] -> OutputSplitter[split(4, equal=True)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 27 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:15:58. Total running time: 1hr 26min 46s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_19391f24   RUNNING        0.147065                     10                2.44803               0.717856                 0.624617        0.00883146        0.775553       164            5.91644       0.125983       0.475943 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6d62774a   RUNNING        0.0347258                    10                0.323413              0.691894                 0.714138        0.00179342        0.0551277                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 22 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=4960, ip=100.64.8.234)\u001b[0m [13:15:58] [0]\ttrain-rmse:1.12614\tvalid-rmse:1.11339\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.745 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:15:58] [164]\ttrain-rmse:0.12554\tvalid-rmse:0.47599\n",
      "\u001b[36m(XGBoostTrainer pid=4960, ip=100.64.8.234)\u001b[0m [13:16:00] [1]\ttrain-rmse:1.09989\tvalid-rmse:1.09159\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.702 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.702 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.702 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.702 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.779 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:16:02] [165]\ttrain-rmse:0.12505\tvalid-rmse:0.47593\n",
      "\u001b[36m(XGBoostTrainer pid=4960, ip=100.64.8.234)\u001b[0m [13:16:03] [2]\ttrain-rmse:1.07590\tvalid-rmse:1.07083\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.745 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.745 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:16:05] [166]\ttrain-rmse:0.12470\tvalid-rmse:0.47585\n",
      "\u001b[36m(XGBoostTrainer pid=4960, ip=100.64.8.234)\u001b[0m [13:16:07] [3]\ttrain-rmse:1.05262\tvalid-rmse:1.05106\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.774 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.775 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.767 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.767 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:16:09] [167]\ttrain-rmse:0.12421\tvalid-rmse:0.47580\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:16:10] [168]\ttrain-rmse:0.12364\tvalid-rmse:0.47578\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4960, ip=100.64.8.234)\u001b[0m [13:16:12] [4]\ttrain-rmse:1.02290\tvalid-rmse:1.02431\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.738 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.738 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.755 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:16:14] [169]\ttrain-rmse:0.12327\tvalid-rmse:0.47574\n",
      "\u001b[36m(XGBoostTrainer pid=4960, ip=100.64.8.234)\u001b[0m [13:16:16] [5]\ttrain-rmse:0.99862\tvalid-rmse:1.00169\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.750 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.751 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:16:17] [170]\ttrain-rmse:0.12263\tvalid-rmse:0.47546\n",
      "\u001b[36m(XGBoostTrainer pid=4960, ip=100.64.8.234)\u001b[0m [13:16:19] [6]\ttrain-rmse:0.97307\tvalid-rmse:0.97979\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.763 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.764 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.764 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:16:21] [171]\ttrain-rmse:0.12222\tvalid-rmse:0.47538\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.724 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.724 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4960, ip=100.64.8.234)\u001b[0m [13:16:23] [7]\ttrain-rmse:0.95017\tvalid-rmse:0.95883\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.765 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.765 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:16:24] [172]\ttrain-rmse:0.12188\tvalid-rmse:0.47544\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.739 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4960, ip=100.64.8.234)\u001b[0m [13:16:26] [8]\ttrain-rmse:0.92428\tvalid-rmse:0.93566\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:16:28] [173]\ttrain-rmse:0.12137\tvalid-rmse:0.47546\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.753 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 27 TERMINATED | 3 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:16:30. Total running time: 1hr 27min 17s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 12.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_19391f24   RUNNING        0.147065                     10                2.44803               0.717856                 0.624617        0.00883146        0.775553       173            5.94237       0.121883       0.475439 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6d62774a   RUNNING        0.0347258                    10                0.323413              0.691894                 0.714138        0.00179342        0.0551277        9            5.27          0.924278       0.935664 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 22 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.735 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.735 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4960, ip=100.64.8.234)\u001b[0m [13:16:30] [9]\ttrain-rmse:0.90286\tvalid-rmse:0.91628\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:16:31] [174]\ttrain-rmse:0.12092\tvalid-rmse:0.47536\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.749 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.749 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4960, ip=100.64.8.234)\u001b[0m [13:16:33] [10]\ttrain-rmse:0.88076\tvalid-rmse:0.89803\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:16:35] [175]\ttrain-rmse:0.12039\tvalid-rmse:0.47540\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4960, ip=100.64.8.234)\u001b[0m [13:16:37] [11]\ttrain-rmse:0.85716\tvalid-rmse:0.87736\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.755 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:16:38] [176]\ttrain-rmse:0.11983\tvalid-rmse:0.47551\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.751 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.752 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.752 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.756 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4960, ip=100.64.8.234)\u001b[0m [13:16:40] [12]\ttrain-rmse:0.83728\tvalid-rmse:0.86147\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4960, ip=100.64.8.234)\u001b[0m [13:16:42] [13]\ttrain-rmse:0.81719\tvalid-rmse:0.84492\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.742 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.743 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.743 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:16:44] [177]\ttrain-rmse:0.11932\tvalid-rmse:0.47560\n",
      "\u001b[36m(XGBoostTrainer pid=4960, ip=100.64.8.234)\u001b[0m [13:16:45] [14]\ttrain-rmse:0.80137\tvalid-rmse:0.83154\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.758 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.758 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:16:47] [178]\ttrain-rmse:0.11887\tvalid-rmse:0.47541\n",
      "\u001b[36m(XGBoostTrainer pid=4960, ip=100.64.8.234)\u001b[0m [13:16:49] [15]\ttrain-rmse:0.78072\tvalid-rmse:0.81424\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.746 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.746 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.741 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.741 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4781, ip=100.64.27.77)\u001b[0m [13:16:51] [179]\ttrain-rmse:0.11833\tvalid-rmse:0.47547\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.753 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.754 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.754 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🏃 View run XGBoostTrainer_19391f24 at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265/runs/2750eac9e2a24c4d819fdad2b8a86ff2\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🧪 View experiment at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_19391f24 completed after 180 iterations at 2025-09-01 13:16:53. Total running time: 1hr 27min 41s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_19391f24 result             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ checkpoint_dir_name                              │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_this_iter_s                         0.00283 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_total_s                             5.96184 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ training_iteration                           180 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ train-rmse                               0.11833 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ valid-rmse                               0.47547 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────╯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4960, ip=100.64.8.234)\u001b[0m [13:16:55] [16]\ttrain-rmse:0.76297\tvalid-rmse:0.79986\n",
      "\u001b[36m(XGBoostTrainer pid=4960, ip=100.64.8.234)\u001b[0m [13:16:56] [17]\ttrain-rmse:0.75095\tvalid-rmse:0.79071\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.756 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.757 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.757 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.739 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.740 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.740 s, which may be a performance bottleneck.\n",
      "\u001b[36m(XGBoostTrainer pid=4960, ip=100.64.8.234)\u001b[0m [13:16:58] [18]\ttrain-rmse:0.73864\tvalid-rmse:0.78244\n",
      "\u001b[36m(XGBoostTrainer pid=4960, ip=100.64.8.234)\u001b[0m [13:17:00] [19]\ttrain-rmse:0.72084\tvalid-rmse:0.76779\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.747 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.748 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.748 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 28 TERMINATED | 2 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:17:00. Total running time: 1hr 27min 48s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 8.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_6d62774a   RUNNING        0.0347258                    10                0.323413              0.691894                 0.714138        0.00179342        0.0551277       19            5.29831       0.738643       0.782438 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 23 more TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `callbacks.on_trial_result` operation took 1.779 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Processing trial results took 1.780 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m The `process_trial_result` operation took 1.780 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🏃 View run XGBoostTrainer_6d62774a at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265/runs/932218ff0f6043db892cda8736c667be\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 🧪 View experiment at: http://ray-68b5e1f3b7910b03aaf26bb0-ray-proxy:8765/#/experiments/265\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial XGBoostTrainer_6d62774a completed after 20 iterations at 2025-09-01 13:17:02. Total running time: 1hr 27min 50s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial XGBoostTrainer_6d62774a result             │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ checkpoint_dir_name                              │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_this_iter_s                         0.00281 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ time_total_s                             5.30113 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ training_iteration                            20 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ train-rmse                               0.72084 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ valid-rmse                               0.76779 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m \n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 29 TERMINATED | 1 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:17:30. Total running time: 1hr 28min 18s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 4.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 24 more TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 29 TERMINATED | 1 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:18:00. Total running time: 1hr 28min 48s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 4.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 24 more TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 29 TERMINATED | 1 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:18:30. Total running time: 1hr 29min 18s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 4.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 24 more TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 29 TERMINATED | 1 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:19:00. Total running time: 1hr 29min 48s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 4.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 24 more TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 29 TERMINATED | 1 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:19:30. Total running time: 1hr 30min 18s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 4.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 24 more TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 29 TERMINATED | 1 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:20:00. Total running time: 1hr 30min 48s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 4.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 24 more TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 29 TERMINATED | 1 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:20:30. Total running time: 1hr 31min 18s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 4.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 24 more TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 29 TERMINATED | 1 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:21:00. Total running time: 1hr 31min 48s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 4.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 24 more TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 29 TERMINATED | 1 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:21:30. Total running time: 1hr 32min 18s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 4.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 24 more TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 29 TERMINATED | 1 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:22:00. Total running time: 1hr 32min 48s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 4.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 24 more TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 29 TERMINATED | 1 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:22:30. Total running time: 1hr 33min 18s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 4.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 24 more TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 29 TERMINATED | 1 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:23:00. Total running time: 1hr 33min 48s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 4.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 24 more TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 29 TERMINATED | 1 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:23:30. Total running time: 1hr 34min 18s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 4.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 24 more TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 29 TERMINATED | 1 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:24:00. Total running time: 1hr 34min 48s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 4.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 24 more TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 29 TERMINATED | 1 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:24:30. Total running time: 1hr 35min 18s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 4.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 24 more TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 29 TERMINATED | 1 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:25:00. Total running time: 1hr 35min 48s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 4.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 24 more TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 29 TERMINATED | 1 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:25:30. Total running time: 1hr 36min 18s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 4.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 24 more TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 29 TERMINATED | 1 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:26:00. Total running time: 1hr 36min 48s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 4.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 24 more TERMINATED\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Trial status: 29 TERMINATED | 1 RUNNING\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current time: 2025-09-01 13:26:30. Total running time: 1hr 37min 18s\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Logical resource usage: 4.0/16 CPUs, 0/0 GPUs\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m Current best trial: ca919a62 with valid-rmse=0.44804730023671846 and params={'params': {'objective': 'reg:squarederror', 'tree_method': 'hist', 'eval_metric': 'rmse', 'eta': 0.04092727091511802, 'max_depth': 10, 'min_child_weight': 2.6961269193856783, 'subsample': 0.7423996250457794, 'colsample_bytree': 0.7011982798079494, 'lambda': 0.004974847839491, 'alpha': 1.7026072301402462, 'nthread': 1}}\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ Trial name                status         params/eta     params/max_depth     .../min_child_weight     params/subsample     .../colsample_bytree     params/lambda     params/alpha     iter     total time (s)     train-rmse     valid-rmse │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_56e7b182   RUNNING        0.02133                       7                1.25227               0.810649                 0.896391        0.0225937         0.0071157                                                           │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e6f7faf6   TERMINATED     0.0279228                     8                0.0354396             0.719789                 0.699472        0.00206306        0.0027673      300            7.42061       0.259345       0.462507 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_5f9c4ad7   TERMINATED     0.0118948                     6                0.0351002             0.826737                 0.78165         0.0849377         0.399132        60            4.11066       0.791622       0.801378 │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_e7b672c9   TERMINATED     0.00333048                    4                3.24263               0.683972                 0.76717         1.33559           0.0462283       20            3.80221       1.11827        1.10433  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_b837ab13   TERMINATED     0.00633575                    8                0.306184              0.87381                  0.816089        0.103788          1.04247         20            5.31041       1.05956        1.05086  │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m │ XGBoostTrainer_f3a0bb1b   TERMINATED     0.0102491                     7                1.06843               0.908119                 0.966074        0.143312          2.95444         20            5.34938       1.01147        1.0047   │\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(TunerInternal pid=1377)\u001b[0m 24 more TERMINATED\n"
     ]
    }
   ],
   "source": [
    "RAY_JOB_ENV = {\n",
    "    \"AWS_ROLE_ARN\": os.environ.get(\"AWS_ROLE_ARN\", \"\"),\n",
    "    \"AWS_WEB_IDENTITY_TOKEN_FILE\": os.environ.get(\"AWS_WEB_IDENTITY_TOKEN_FILE\", \"\"),\n",
    "    \"AWS_REGION\": os.environ.get(\"AWS_REGION\", os.environ.get(\"AWS_DEFAULT_REGION\", \"us-east-1\")),\n",
    "    \"AWS_DEFAULT_REGION\": os.environ.get(\"AWS_REGION\", os.environ.get(\"AWS_DEFAULT_REGION\", \"us-east-1\")),\n",
    "    \"TUNE_DISABLE_AUTO_CALLBACK_LOGGERS\":\"1\",\n",
    "    \"TUNE_RESULT_BUFFER_LENGTH\": \"16\",\n",
    "    \"TUNE_RESULT_BUFFER_FLUSH_INTERVAL_S\": \"3\",    \n",
    "    \n",
    "}\n",
    "ray.shutdown()\n",
    "ensure_ray_connected(RAY_JOB_ENV,ray_ns=app_name)\n",
    "\n",
    "main(experiment_name=experiment_name,data_dir=data_dir, num_workers=4, cpus_per_worker=1,DEV_FAST=dev_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6275c8-9ca7-4900-ab60-de5a420e82f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_scaler_client.scale_cluster(cluster_kind=\"rayclusters\",replicas=1)\n",
    "cluster_scaler_client.wait_until_scaling_complete(cluster_kind=\"rayclusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4e00d6-0f97-4180-a994-7cb7fc0e83ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray, sys, pyarrow as pa, pandas as pd\n",
    "print(\"DRIVER:\", sys.version)\n",
    "print(\"DRIVER pyarrow:\", pa.__version__)\n",
    "print(\"DRIVER pandas :\", pd.__version__)\n",
    "\n",
    "@ray.remote\n",
    "def _env_probe():\n",
    "    import sys, pyarrow as pa, pandas as pd\n",
    "    return {\n",
    "        \"python\": sys.version.split()[0],\n",
    "        \"pyarrow\": pa.__version__,\n",
    "        \"pandas\": pd.__version__,\n",
    "    }\n",
    "\n",
    "print(\"WORKER:\", ray.get(_env_probe.remote()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a23211-b6aa-469e-878f-b19ec0943134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dd3a8b-6669-45fa-9368-dc722d74746c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
